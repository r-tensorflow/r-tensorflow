<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Overview on TensorFlow for R</title><link>/guide/</link><description>Recent content in Overview on TensorFlow for R</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="/guide/index.xml" rel="self" type="application/rss+xml"/><item><title>Checkpoints</title><link>/guide/saving/checkpoints/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/saving/checkpoints/</guid><description>The phrase “Saving a TensorFlow model” typically means one of two things:
Checkpoints, OR SavedModel. Checkpoints capture the exact value of all parameters (tf$Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model and thus are typically only useful when source code that will use the saved parameter values is available.
The SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint).</description></item><item><title>Custom Estimators</title><link>/guide/tfestimators/creating_estimators/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/creating_estimators/</guid><description>The tfestimators framework makes it easy to construct and build machine learning models via its high-level Estimator API. Estimator offers classes you can instantiate to quickly configure common model types such as regressors and classifiers.
But what if none of the predefined model types meets your needs? Perhaps you need more granular control over model configuration, such as the ability to customize the loss function used for optimization, or specify different activation functions for each neural network layer.</description></item><item><title>Dataset API</title><link>/guide/tfestimators/dataset_api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/dataset_api/</guid><description>Overview We can access the TensorFlow Dataset API via the tfdatasets package, which enables us to create scalable input pipelines that can be used with tfestimators. In this vignette, we demonstrate the capability to stream datasets stored on disk for training by building a classifier on the iris dataset.
Dataset Preparation Let’s assume we’re given a dataset (which could be arbitrarily large) split into training and validation, and a small sample of the dataset.</description></item><item><title>Eager execution</title><link>/guide/tensorflow/eager_execution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/eager_execution/</guid><description>TensorFlow’s eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this guide, run the code samples below in an interactive R interpreter.
Eager execution is a flexible machine learning platform for research and experimentation, providing:</description></item><item><title>Estimator Basics</title><link>/guide/tfestimators/estimator_basics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/estimator_basics/</guid><description>Warning! TensorFlow Estimators has not received updates by the TensorFlow team in a long time, and it’s no longer recommended. You may find bugs when using tfestimators with recent versions of TensorFlow (&amp;gt;= 1.10).
Overview The basic components of the TensorFlow Estimators API include:
Canned estimators (pre-built implementations of various models).
Custom estimators (custom model implementations).
Estimator methods (core methods like train(), predict(), evaluate(), etc.</description></item><item><title>Feature Columns</title><link>/guide/tfestimators/feature_columns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/feature_columns/</guid><description>Overview Feature columns are used to specify how Tensors received from the input function should be combined and transformed before entering the model. A feature column can be a plain mapping to some input column (e.g. column_numeric() for a column of numerical data), or a transformation of other feature columns (e.g. column_crossed() to define a new column as the cross of two other feature columns).
The following feature columns are available:</description></item><item><title>Feature columns</title><link>/guide/tfdatasets/feature_columns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfdatasets/feature_columns/</guid><description>This document is an adaptation of the official TensorFlow Feature Columns guide.
This document details feature columns and how they can be used as inputs to neural networks using TensorFlow. Feature columns are very rich, enabling you to transform a diverse range of raw data into formats that neural networks can use, allowing easy experimentation.
What kind of data can a deep neural network operate on? The answer is, of course, numbers (for example, tf$float32).</description></item><item><title>Feature Spec interface</title><link>/guide/tfdatasets/feature_spec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfdatasets/feature_spec/</guid><description>Overview In this document we will demonstrate the basic usage of the feature_spec interface in tfdatasets.
The feature_spec interface is a user friendly interface to feature_columns. It allows us to specify column transformations and representations when working with structured data.
We will use the hearts dataset and it can be loaded with data(hearts).
library(tfdatasets) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union data(hearts) head(hearts) ## # A tibble: 6 x 14 ## age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ## &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; ## 1 63 1 1 145 233 1 2 150 0 2.</description></item><item><title>Input Functions</title><link>/guide/tfestimators/input_functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/input_functions/</guid><description>Overview TensorFlow estimators receive data through input functions. Input functions take an arbitrary data source (in-memory data sets, streaming data, custom data format, and so on) and generate Tensors that can be supplied to TensorFlow models.
More concretely, input functions are used to:
Turn raw data sources into Tensors, and Configure how data is drawn during training (shuffling, batch size, epochs, etc.) You can also perform feature engineering within an input function; however, it’s better to use feature columns for this purpose whenever possible, as in that case the tranformations are made part of the TensorFlow graph and so can be executed without an R runtime (e.</description></item><item><title>Key concepts</title><link>/guide/tfhub/key-concepts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfhub/key-concepts/</guid><description>Using a Module Instantiating a Module A TensorFlow Hub module is imported into a TensorFlow program by creating a Module object from a string with its URL or filesystem path, such as:
library(tfhub) m &amp;lt;-hub_load(&#34;path/to/a/module_dir&#34;) This adds the module’s variables to the current TensorFlow graph.
Caching Modules When creating a module from a URL, the module content is downloaded and cached in the local system temporary directory. The location where modules are cached can be overridden using TFHUB_CACHE_DIR environment variable.</description></item><item><title>Overview</title><link>/guide/tfhub/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfhub/intro/</guid><description>The tfhub package provides R wrappers to TensorFlow Hub.
TensorFlow Hub is a library for reusable machine learning modules.
TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning. Transfer learning can:</description></item><item><title>Parsing Utilities</title><link>/guide/tfestimators/parsing_spec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/parsing_spec/</guid><description>Overview Parsing utilities are a set of functions that helps generate parsing spec for tf$parse_example to be used with estimators. If users keep data in tf$Example format, they need to call tf$parse_example with a proper feature spec. There are two main things that these utility functions help:
Users need to combine parsing spec of features with labels and weights (if any) since they are all parsed from same tf$Example instance.</description></item><item><title>R interface to TensorFlow Dataset API</title><link>/guide/tfdatasets/introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfdatasets/introduction/</guid><description>Overview The TensorFlow Dataset API provides various facilities for creating scalable input pipelines for TensorFlow models, including:
Reading data from a variety of formats including CSV files and TFRecords files (the standard binary format for TensorFlow training data).
Transforming datasets in a variety of ways including mapping arbitrary functions against them.
Shuffling, batching, and repeating datasets over a number of epochs.
Streaming interface to data for reading arbitrarily large datasets.</description></item><item><title>Ragged tensors</title><link>/guide/tensorflow/ragged_tensors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/ragged_tensors/</guid><description>Overview Your data comes in many shapes; your tensors should too. Ragged tensors are the TensorFlow equivalent of nested variable-length lists. They make it easy to store and process data with non-uniform shapes, including:
Variable-length features, such as the set of actors in a movie. Batches of variable-length sequential inputs, such as sentences or video clips. Hierarchical inputs, such as text documents that are subdivided into sections, paragraphs, sentences, and words.</description></item><item><title>Run Hooks</title><link>/guide/tfestimators/run_hooks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/run_hooks/</guid><description>Overview SessionRunHooks are useful to track training, report progress, request early stopping and more. Users can attach an arbitrary number of hooks to an estimator. SessionRunHooks use the observer pattern and notify at the following points:
when a session starts being used before a call to the session.run() after a call to the session.run() when the session closed A SessionRunHook encapsulates a piece of reusable/composable computation that can piggyback a call to MonitoredSession.</description></item><item><title>Saved Model</title><link>/guide/saving/saved_model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/saving/saved_model/</guid><description>A SavedModel contains a complete TensorFlow program, including weights and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying (with TFLite, TensorFlow.js, TensorFlow Serving, or TensorFlow Hub).
If you have code for a model in R and merely want to load weights into it, see the guide to training checkpoints.
Creating a SavedModel from Keras For a quick introduction, this section exports a pre-trained Keras model and serves image classification requests with it.</description></item><item><title>TensorBoard Visualization</title><link>/guide/tfestimators/tensorboard/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/tensorboard/</guid><description>Overview TensorBoard is a visualization tool included with TensorFlow that enables you to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it.
Models built using tfestimators automatically contain most of the necessary information to visualize the TensorFlow graph, variables, etc., for you so you can easily launch the TensorBoard without additional manual specifications.
Examples To start the TensorBoard, you trained a model in a similar fashion as follows:</description></item><item><title>TensorFlow Hub with Keras</title><link>/guide/tfhub/hub-with-keras/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfhub/hub-with-keras/</guid><description>TensorFlow Hub is a way to share pretrained model components. See the TensorFlow Module Hub for a searchable listing of pre-trained models. This tutorial demonstrates:
How to use TensorFlow Hub with Keras. How to do image classification using TensorFlow Hub. How to do simple transfer learning. Setup library(keras) library(tfhub) library(magick) #&amp;gt; Linking to ImageMagick 6.9.9.39 #&amp;gt; Enabled features: cairo, fontconfig, freetype, lcms, pango, rsvg, webp #&amp;gt; Disabled features: fftw, ghostscript, x11 An ImageNet classifier Download the classifier Use layer_hub to load a mobilenet and transform it into a Keras layer.</description></item><item><title>TensorFlow Layers</title><link>/guide/tfestimators/tensorflow_layers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfestimators/tensorflow_layers/</guid><description>The TensorFlow tf$layers module provides a high-level API that makes it easy to construct a neural network. It provides methods that facilitate the creation of dense (fully connected) layers and convolutional layers, adding activation functions, and applying dropout regularization. In this tutorial, you’ll learn how to use layers to build a convolutional neural network model to recognize the handwritten digits in the MNIST data set. The complete code for this tutorial can be found here.</description></item><item><title>TensorFlow tensors</title><link>/guide/tensorflow/tensors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/tensors/</guid><description>TensorFlow, as the name indicates, is a framework to define and run computations involving tensors. A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes.
When writing a TensorFlow program, the main object you manipulate and pass around is the tf$Tensor. A tf$Tensor object represents a partially defined computation that will eventually produce a value. TensorFlow programs work by first building a graph of tf$Tensor objects, detailing how each tensor is computed based on the other available tensors and then by running parts of this graph to achieve the desired results.</description></item><item><title>TensorFlow variables</title><link>/guide/tensorflow/variable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/variable/</guid><description>A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.
Variables are manipulated via the tf$Variable class. A tf$Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like Keras use tf$Variable to store model parameters. This guide covers how to create, update, and manage tf$Variables in TensorFlow.</description></item></channel></rss>