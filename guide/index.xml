<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Overview on TensorFlow for R</title><link>/guide/</link><description>Recent content in Overview on TensorFlow for R</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="/guide/index.xml" rel="self" type="application/rss+xml"/><item><title>Checkpoints</title><link>/guide/saving/checkpoints/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/saving/checkpoints/</guid><description>The phrase “Saving a TensorFlow model” typically means one of two things:
Checkpoints, OR SavedModel. Checkpoints capture the exact value of all parameters (tf$Variable objects) used by a model. Checkpoints do not contain any description of the computation defined by the model and thus are typically only useful when source code that will use the saved parameter values is available.
The SavedModel format on the other hand includes a serialized description of the computation defined by the model in addition to the parameter values (checkpoint).</description></item><item><title>Eager execution</title><link>/guide/tensorflow/eager_execution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/eager_execution/</guid><description>TensorFlow’s eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this guide, run the code samples below in an interactive R interpreter.
Eager execution is a flexible machine learning platform for research and experimentation, providing:</description></item><item><title>Feature columns</title><link>/guide/tfdatasets/feature_columns/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfdatasets/feature_columns/</guid><description>This document is an adaptation of the official TensorFlow Feature Columns guide.
This document details feature columns and how they can be used as inputs to neural networks using TensorFlow. Feature columns are very rich, enabling you to transform a diverse range of raw data into formats that neural networks can use, allowing easy experimentation.
What kind of data can a deep neural network operate on? The answer is, of course, numbers (for example, tf$float32).</description></item><item><title>Feature Spec interface</title><link>/guide/tfdatasets/feature_spec/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfdatasets/feature_spec/</guid><description>Overview In this document we will demonstrate the basic usage of the feature_spec interface in tfdatasets.
The feature_spec interface is a user friendly interface to feature_columns. It allows us to specify column transformations and representations when working with structured data.
We will use the hearts dataset and it can be loaded with data(hearts).
library(tfdatasets) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union data(hearts) head(hearts) ## # A tibble: 6 x 14 ## age sex cp trestbps chol fbs restecg thalach exang oldpeak ## &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; ## 1 63 1 1 145 233 1 2 150 0 2.</description></item><item><title>Key concepts</title><link>/guide/tfhub/key-concepts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfhub/key-concepts/</guid><description>Using a Module Instantiating a Module A TensorFlow Hub module is imported into a TensorFlow program by creating a Module object from a string with its URL or filesystem path, such as:
library(tfhub) m &amp;lt;-hub_load(&#34;path/to/a/module_dir&#34;) This adds the module’s variables to the current TensorFlow graph.
Caching Modules When creating a module from a URL, the module content is downloaded and cached in the local system temporary directory. The location where modules are cached can be overridden using TFHUB_CACHE_DIR environment variable.</description></item><item><title>Overview</title><link>/guide/tfhub/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfhub/intro/</guid><description>The tfhub package provides R wrappers to TensorFlow Hub.
TensorFlow Hub is a library for reusable machine learning modules.
TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning. Transfer learning can:</description></item><item><title>R interface to TensorFlow Dataset API</title><link>/guide/tfdatasets/introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfdatasets/introduction/</guid><description>Overview The TensorFlow Dataset API provides various facilities for creating scalable input pipelines for TensorFlow models, including:
Reading data from a variety of formats including CSV files and TFRecords files (the standard binary format for TensorFlow training data).
Transforming datasets in a variety of ways including mapping arbitrary functions against them.
Shuffling, batching, and repeating datasets over a number of epochs.
Streaming interface to data for reading arbitrarily large datasets.</description></item><item><title>Ragged tensors</title><link>/guide/tensorflow/ragged_tensors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/ragged_tensors/</guid><description>Overview Your data comes in many shapes; your tensors should too. Ragged tensors are the TensorFlow equivalent of nested variable-length lists. They make it easy to store and process data with non-uniform shapes, including:
Variable-length features, such as the set of actors in a movie. Batches of variable-length sequential inputs, such as sentences or video clips. Hierarchical inputs, such as text documents that are subdivided into sections, paragraphs, sentences, and words.</description></item><item><title>Saved Model</title><link>/guide/saving/saved_model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/saving/saved_model/</guid><description>A SavedModel contains a complete TensorFlow program, including weights and computation. It does not require the original model building code to run, which makes it useful for sharing or deploying (with TFLite, TensorFlow.js, TensorFlow Serving, or TensorFlow Hub).
If you have code for a model in R and merely want to load weights into it, see the guide to training checkpoints.
Creating a SavedModel from Keras For a quick introduction, this section exports a pre-trained Keras model and serves image classification requests with it.</description></item><item><title>TensorFlow Hub with Keras</title><link>/guide/tfhub/hub-with-keras/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tfhub/hub-with-keras/</guid><description>TensorFlow Hub is a way to share pretrained model components. See the TensorFlow Module Hub for a searchable listing of pre-trained models. This tutorial demonstrates:
How to use TensorFlow Hub with Keras. How to do image classification using TensorFlow Hub. How to do simple transfer learning. Setup library(keras) library(tfhub) library(magick) #&amp;gt; Linking to ImageMagick 6.9.9.39 #&amp;gt; Enabled features: cairo, fontconfig, freetype, lcms, pango, rsvg, webp #&amp;gt; Disabled features: fftw, ghostscript, x11 An ImageNet classifier Download the classifier Use layer_hub to load a mobilenet and transform it into a Keras layer.</description></item><item><title>TensorFlow tensors</title><link>/guide/tensorflow/tensors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/tensors/</guid><description>TensorFlow, as the name indicates, is a framework to define and run computations involving tensors. A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes.
When writing a TensorFlow program, the main object you manipulate and pass around is the tf$Tensor. A tf$Tensor object represents a partially defined computation that will eventually produce a value. TensorFlow programs work by first building a graph of tf$Tensor objects, detailing how each tensor is computed based on the other available tensors and then by running parts of this graph to achieve the desired results.</description></item><item><title>TensorFlow variables</title><link>/guide/tensorflow/variable/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/guide/tensorflow/variable/</guid><description>A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.
Variables are manipulated via the tf$Variable class. A tf$Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like Keras use tf$Variable to store model parameters. This guide covers how to create, update, and manage tf$Variables in TensorFlow.</description></item></channel></rss>