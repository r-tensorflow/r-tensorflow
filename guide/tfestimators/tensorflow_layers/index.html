<!doctype html><html><head><script>theBaseUrl=location.origin+"/";</script><meta charset=utf-8><meta name=viewport content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1"><title>TensorFlow Layers</title><meta name=generator content="Hugo 0.58.3"><meta name=description content="Documentation for the TensorFlow for R interface"><link rel=canonical href=/guide/tfestimators/tensorflow_layers/><meta name=author content="J.J. Allaire"><meta property=og:url content=/guide/tfestimators/tensorflow_layers/><meta property=og:title content="TensorFlow for R"><meta name=apple-mobile-web-app-title content="TensorFlow for R"><meta name=apple-mobile-web-app-capable content=yes><meta name=apple-mobile-web-app-status-bar-style content=black-translucent><style>@font-face{font-family:icon;src:url(fonts/icon.eot?52m981);src:url(fonts/icon.eot?#iefix52m981) format('embedded-opentype'),url(fonts/icon.woff?52m981) format('woff'),url(fonts/icon.ttf?52m981) format('truetype'),url(fonts/icon.svg?52m981#icon) format('svg');font-weight:400;font-style:normal}</style><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/site-styles.css><script src=/js/vendor.js></script><script src=/js/app.js></script><link rel="shortcut icon" href=/images/favicon.png><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body><div class=single-page><nav data-gumshoe-header aria-label=Header id=header class=top-menu><div class=left><a href=/ data-parenturl class="top-menu-item site-title">TensorFlow for R</a>
<span class=logo-from>from</span>
<a href=/><div id=logo class=logo></div></a></div><div class=right><div class=top-menu-items id=top-menu-items><a href=/ data-parenturl=/ class=top-menu-item>Home</a>
<a href=/installation/ data-parenturl=/installation/ class=top-menu-item>Installation</a>
<a href=/tutorials/ data-parenturl=/tutorials/ class=top-menu-item>Tutorials</a>
<a href=/guide/ data-parenturl=/guide/ class=top-menu-item>Guide</a>
<a href=/deploy/ data-parenturl=/deploy/ class=top-menu-item>Deploy</a>
<a href=/tools/ data-parenturl=/tools/ class=top-menu-item>Tools</a>
<a href=/reference/keras data-parenturl=/reference/keras class=top-menu-item>API</a>
<a href=/learn/resources/ data-parenturl=/learn/resources/ class=top-menu-item>Learn</a>
<a href=/blog.html data-parenturl=/blog.html class=top-menu-item>Blog</a></div><a href=https://github.com/rstudio/tensorflow class=github-logo><i class="fa fa-lg fa-github" aria-hidden=true></i></a><div class=search-button><i class="fa fa-lg fa-search"></i></div></div></nav><nav aria-label=Header id=mobile-header><a href=/>TensorFlow for R</a><div class=right><a href=https://github.com/rstudio/tensorflow class=github-logo><i class="fa fa-lg fa-github" aria-hidden=true></i></a><div class=hamburger><i class="fa fa-lg fa-bars" aria-hidden=true></i></div></div></nav><div id=mobile-menu-container><ul id=mobile-menu><li><a href=/>Home</a></li><ul></ul><li><a href=/installation/>Installation</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/installation/>Installing TensorFlow</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/installation/>Quick start</a></li><li><a href=/installation/custom/>Custom Installation</a></li></ul><li><a href=/installation/gpu>Using a GPU</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/installation/gpu/>Overview</a></li><li><a href=/installation/gpu/local_gpu/>Local GPU</a></li><li><a href=/installation/gpu/cloud_server_gpu/>Cloud Server</a></li><li><a href=/installation/gpu/cloud_desktop_gpu/>Cloud Desktop</a></li></ul></ul><li><a href=/tutorials/>Tutorials</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/>Overview</a></li><li><a href>Beginners</a></li><li><a href=/tutorials/beginners/>Quickstart</a></li><li><a href=/tutorials/beginners/basic-ml/>Basic ML with Keras</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/beginners/basic-ml/>Overview</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_classification/>Image Classification</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_regression/>Regression</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_text_classification/>Text Classification</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_text_classification_with_tfhub/>Transfer learning with tfhub</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_overfit_underfit/>Overfitting and Underfitting</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_save_and_restore/>Save and Restore Models</a></li></ul><li><a href=/tutorials/beginners/load/load_csv/>Load and preprocess data</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/beginners/load/load_csv/>Load CSV data</a></li><li><a href=/tutorials/beginners/load/load_image/>Load image data</a></li></ul><li><a href>Advanced</a></li><li><a href=/tutorials/advanced/>Quickstart</a></li><li><a href=/tutorials/advanced/customization/tensors-operations/>Customization</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/customization/tensors-operations/>Tensors and operations</a></li><li><a href=/tutorials/advanced/customization/custom-layers/>Custom layers</a></li><li><a href=/tutorials/advanced/customization/autodiff/>Automatic differentiation</a></li><li><a href=/tutorials/advanced/customization/custom-training/>Custom training</a></li></ul><li><a href=/tutorials/advanced/images/cnn/>Images</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/images/cnn/>Convolutional Neural Network</a></li><li><a href=/tutorials/advanced/images/transfer-learning-hub/>Transfer Learning with tfhub</a></li></ul><li><a href=/tutorials/advanced/structured/classify/>Structured data</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/structured/classify/>Classify structured data</a></li></ul><li><a href=/tutorials/advanced/distributed/distributed_training_with_keras/>Distributed training</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/distributed/distributed_training_with_keras/>Distributed training with Keras</a></li></ul></ul><li><a href=/guide/>Guide</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/>Overview</a></li><li><a href>Keras</a></li><li><a href=/guide/keras/>Getting started</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/keras/>Overview</a></li><li><a href=/guide/keras/guide_keras/>Keras basics</a></li><li><a href=/guide/keras/sequential_model/>Sequential API</a></li><li><a href=/guide/keras/functional_api/>Functional API</a></li><li><a href=/guide/keras/saving_serializing/>Saving and serializing models</a></li><li><a href=/guide/keras/faq/>Frequently Asked Questions</a></li></ul><li><a href=/guide/keras/custom_layers/>Advanced</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/keras/custom_layers/>Custom Layers</a></li><li><a href=/guide/keras/custom_models/>Custom Models</a></li><li><a href=/guide/keras/training_callbacks/>Training Callbacks</a></li><li><a href=/guide/keras/applications/>Pre-Trained Models</a></li><li><a href=/guide/keras/training_visualization/>Training Visualization</a></li></ul><li><a href=/guide/keras/examples/>Examples</a></li><li><a href>TensorFlow Mechanics</a></li><li><a href=/guide/tensorflow/eager_execution>Basics</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tensorflow/eager_execution/>Eager execution</a></li><li><a href=/guide/tensorflow/variable/>Variables</a></li><li><a href=/guide/tensorflow/tensors/>Tensors</a></li></ul><li><a href=/guide/tensorflow/ragged_tensors>Advanced</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tensorflow/ragged_tensors/>Ragged tensors</a></li></ul><li><a href>Data input pipeline</a></li><li><a href=/guide/tfdatasets/introduction>Overview</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfdatasets/introduction/>Using Datasets</a></li></ul><li><a href=/guide/tfdatasets/feature_spec>Feature spec API</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfdatasets/feature_spec/>Feature Spec interface</a></li><li><a href=/guide/tfdatasets/feature_columns/>Feature columns</a></li></ul><li><a href>TensorFlow Hub</a></li><li><a href=/guide/tfhub/intro>Basics</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfhub/intro/>Overview</a></li><li><a href=/guide/tfhub/hub-with-keras/>Using with Keras</a></li></ul><li><a href=/guide/tfhub/key-concepts>Key concepts</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfhub/key-concepts/>Key Concepts</a></li></ul><li><a href=/guide/tfhub/examples/>Examples</a></li><li><a href>Model saving</a></li><li><a href=/guide/saving/checkpoints>Checkpoints</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/saving/checkpoints/>Checkpoints</a></li></ul><li><a href=/guide/saving/saved_model>Saved Model</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/saving/saved_model/>Saved Model</a></li></ul><li><a href>Estimators</a></li><li><a href=/tfestimators>Basics</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfestimators/estimator_basics/>Estimator Basics</a></li><li><a href=/guide/tfestimators/input_functions/>Input Functions</a></li><li><a href=/guide/tfestimators/feature_columns/>Feature Columns</a></li><li><a href=/guide/tfestimators/tensorboard/>TensorBoard</a></li></ul><li><a href=/guide/tfestimators/creating_estimators/>Advanced</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfestimators/run_hooks/>Run Hooks</a></li><li><a href=/guide/tfestimators/creating_estimators/>Custom Estimators</a></li><li><a href=/guide/tfestimators/parsing_spec/>Parsing Utilities</a></li><li><a href=/guide/tfestimators/dataset_api/>Dataset API</a></li></ul><li><a href=/guide/tfestimators/examples>Examples</a></li></ul><li><a href=/deploy/>Deploy</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/deploy/>Overview</a></li><li><a href=/deploy/plumber/>Plumber</a></li><li><a href=/deploy/shiny/>Shiny</a></li><li><a href=/deploy/docker/>TensorFlow Serving</a></li><li><a href=/deploy/rsconnect/>RStudio Connect</a></li></ul><li><a href=/tools/>Tools</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/>Overview</a></li><li><a href=/tools/tfruns/>Training Runs</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/tfruns/overview/>Introduction to tfruns</a></li><li><a href=/tools/tfruns/tuning/>Hyperparameter Tuning</a></li><li><a href=/tools/tfruns/managing/>Managing Training Runs</a></li></ul><li><a href=/tools/cloudml/>Cloud ML</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/cloudml/getting_started/>Getting Started</a></li><li><a href=/tools/cloudml/training/>Training with CloudML</a></li><li><a href=/tools/cloudml/tuning/>Hyperparameter Tuning</a></li><li><a href=/tools/cloudml/storage/>Google Cloud Storage</a></li><li><a href=/tools/cloudml/deployment/>Deploying Models</a></li></ul><li><a href=/tools/tensorboard/>Tensorboard</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/tensorboard/tensorboard/>Getting started</a></li><li><a href=/tools/tensorboard/hparams/>HParams Dashboard</a></li></ul></ul><li><a href=/reference/keras>API</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/reference/cloudml/>cloudml</a></li><li><a href=/reference/keras/>keras</a></li><li><a href=/reference/tensorflow/>tensorflow</a></li><li><a href=/reference/tfdatasets/>tfdatasets</a></li><li><a href=/reference/tfestimators/>tfestimators</a></li><li><a href=/reference/tfruns/>tfruns</a></li></ul><li><a href=/learn/resources/>Learn</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/learn/resources/>Resources</a></li></ul><li><a href=/blog.html>Blog</a></li><ul></ul></ul></div><div id=search-bar class=search-bar><p class=search-bar__icon><i class="fa fa-lg fa-search"></i></p><div class=search-bar__input><input type=text name=search class=st-default-search-input></div><div class=search-bar__exit><i class="fa fa-lg fa-times"></i></div><div class=inline-search-results><ul></ul></div></div></div><div class="page documentation"><div class=side-menu id=side-menu></div><div class=content><h1 class=content-header>TensorFlow Layers</h1><div class=markdowned><p>The TensorFlow <code>tf$layers</code> module provides a high-level API that makes
it easy to construct a neural network. It provides methods that facilitate the
creation of dense (fully connected) layers and convolutional layers, adding
activation functions, and applying dropout regularization. In this tutorial,
you’ll learn how to use <code>layers</code> to build a convolutional neural network model
to recognize the handwritten digits in the MNIST data set. The complete code
for this tutorial can be found <a href=examples/layers_tutorial.R>here</a>.</p><div class=figure><img src=https://www.tensorflow.org/../images/mnist_0-9.png alt><p class=caption>handwritten digits 0–9 from the MNIST data set</p></div><p><strong>The <a href=http://yann.lecun.com/exdb/mnist/>MNIST dataset</a> comprises 60,000
training examples and 10,000 test examples of the handwritten digits 0–9,
formatted as 28x28-pixel monochrome images.</strong></p><div id=getting-started class="section level2"><h2>Getting Started</h2><p>Let’s set up the skeleton for our TensorFlow program by adding the following code to import the necessary libraries and change the logging verbosity:</p><div class=sourceCode id=cb1><pre class="sourceCode r"><code class="sourceCode r"><span id=cb1-1><a href=#cb1-1></a><span class=kw><a href=https://rdrr.io/r/base/library.html>library</a></span>(tensorflow)</span>
<span id=cb1-2><a href=#cb1-2></a><span class=kw><a href=https://rdrr.io/r/base/library.html>library</a></span>(tfestimators)</span>
<span id=cb1-3><a href=#cb1-3></a>tf<span class=op>$</span>logging<span class=op>$</span><span class=kw>set_verbosity</span>(tf<span class=op>$</span>logging<span class=op>$</span>INFO)</span></code></pre></div><p>As you work through the tutorial, you’ll add code to construct, train, and
evaluate the convolutional neural network.</p></div><div id=intro-to-convolutional-neural-networks class="section level2"><h2>Intro to Convolutional Neural Networks</h2><p>Convolutional neural networks (CNNs) are the current state-of-the-art model
architecture for image classification tasks. CNNs apply a series of filters to
the raw pixel data of an image to extract and learn higher-level features, which
the model can then use for classification. CNNs contains three components:</p><ul><li><p><strong>Convolutional layers</strong>, which apply a specified number of convolution
filters to the image. For each subregion, the layer performs a set of
mathematical operations to produce a single value in the output feature map.
Convolutional layers then typically apply a
<a href=https://en.wikipedia.org/wiki/Rectifier_(neural_networks)>ReLU activation function</a> to
the output to introduce nonlinearities into the model.</p></li><li><p><strong>Pooling layers</strong>, which
<a href=https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer>downsample the image data</a>
extracted by the convolutional layers to reduce the dimensionality of the
feature map in order to decrease processing time. A commonly used pooling
algorithm is max pooling, which extracts subregions of the feature map
(e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other
values.</p></li><li><p><strong>Dense (fully connected) layers</strong>, which perform classification on the
features extracted by the convolutional layers and downsampled by the
pooling layers. In a dense layer, every node in the layer is connected to
every node in the preceding layer.</p></li></ul><p>Typically, a CNN is composed of a stack of convolutional modules that perform
feature extraction. Each module consists of a convolutional layer followed by a
pooling layer. The last convolutional module is followed by one or more dense
layers that perform classification. The final dense layer in a CNN contains a
single node for each target class in the model (all the possible classes the
model may predict), with a
<a href=https://en.wikipedia.org/wiki/Softmax_function>softmax</a> activation function to
generate a value between 0–1 for each node (the sum of all these softmax values
is equal to 1). We can interpret the softmax values for a given image as
relative measurements of how likely it is that the image falls into each target
class.</p><blockquote>Note: For a more comprehensive walkthrough of CNN architecture, see Stanford
University’s <a href=http://cs231n.github.io/convolutional-networks/>Convolutional Neural Networks for Visual Recognition course materials</a>.</blockquote></div><div id=building_the_cnn_mnist_classifier class="section level2"><h2>Building the CNN MNIST Classifier</h2><p>Let’s build a model to classify the images in the MNIST dataset using the
following CNN architecture:</p><ol style=list-style-type:decimal><li><strong>Convolutional Layer #1</strong>: Applies 32 5x5 filters (extracting 5x5-pixel
subregions), with ReLU activation function</li><li><strong>Pooling Layer #1</strong>: Performs max pooling with a 2x2 filter and stride of 2
(which specifies that pooled regions do not overlap)</li><li><strong>Convolutional Layer #2</strong>: Applies 64 5x5 filters, with ReLU activation
function</li><li><strong>Pooling Layer #2</strong>: Again, performs max pooling with a 2x2 filter and
stride of 2</li><li><strong>Dense Layer #1</strong>: 1,024 neurons, with dropout regularization rate of 0.4
(probability of 0.4 that any given element will be dropped during training)</li><li><strong>Dense Layer #2 (Logits Layer)</strong>: 10 neurons, one for each digit target
class (0–9).</li></ol><p>The <code>tf$layers</code> module contains methods to create each of the three layer types
above:</p><ul><li><code>conv2d()</code>. Constructs a two-dimensional convolutional layer. Takes number
of filters, filter kernel size, padding, and activation function as
arguments.</li><li><code>max_pooling2d()</code>. Constructs a two-dimensional pooling layer using the
max-pooling algorithm. Takes pooling filter size and stride as arguments.</li><li><code>dense()</code>. Constructs a dense layer. Takes number of neurons and activation
function as arguments.</li></ul><p>Each of these methods accepts a tensor as input and returns a transformed tensor
as output. This makes it easy to connect one layer to another: just take the
output from one layer-creation method and supply it as input to another.</p><p>The following <code>cnn_model_fn</code> function conforms to the interface expected by TensorFlow’s Estimator API (more on this later in <a href=#create-the-estimator>Create the Estimator</a>). This example takes
MNIST feature data, labels, and <code><a href=../../tfestimators/reference/mode_keys.html>mode_keys()</a></code> (e.g. <code>"train"</code>, <code>"eval"</code>, <code>"infer"</code>) as arguments;
configures the CNN; and returns predictions, loss, and a training operation:</p><div class=sourceCode id=cb2><pre class="sourceCode r"><code class="sourceCode r"><span id=cb2-1><a href=#cb2-1></a>cnn_model_fn &lt;-<span class=st> </span><span class=cf>function</span>(features, labels, mode, params, config) {</span>
<span id=cb2-2><a href=#cb2-2></a>  </span>
<span id=cb2-3><a href=#cb2-3></a>  <span class=co># Input Layer</span></span>
<span id=cb2-4><a href=#cb2-4></a>  <span class=co># Reshape X to 4-D tensor: [batch_size, width, height, channels]</span></span>
<span id=cb2-5><a href=#cb2-5></a>  <span class=co># MNIST images are 28x28 pixels, and have one color channel</span></span>
<span id=cb2-6><a href=#cb2-6></a>  input_layer &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/stats/reshape.html>reshape</a></span>(features<span class=op>$</span>x, <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=op>-</span>1L, 28L, 28L, 1L))</span>
<span id=cb2-7><a href=#cb2-7></a>  </span>
<span id=cb2-8><a href=#cb2-8></a>  <span class=co># Convolutional Layer #1</span></span>
<span id=cb2-9><a href=#cb2-9></a>  <span class=co># Computes 32 features using a 5x5 filter with ReLU activation.</span></span>
<span id=cb2-10><a href=#cb2-10></a>  <span class=co># Padding is added to preserve width and height.</span></span>
<span id=cb2-11><a href=#cb2-11></a>  <span class=co># Input Tensor Shape: [batch_size, 28, 28, 1]</span></span>
<span id=cb2-12><a href=#cb2-12></a>  <span class=co># Output Tensor Shape: [batch_size, 28, 28, 32]</span></span>
<span id=cb2-13><a href=#cb2-13></a>  conv1 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>conv2d</span>(</span>
<span id=cb2-14><a href=#cb2-14></a>    <span class=dt>inputs =</span> input_layer,</span>
<span id=cb2-15><a href=#cb2-15></a>    <span class=dt>filters =</span> 32L,</span>
<span id=cb2-16><a href=#cb2-16></a>    <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(5L, 5L),</span>
<span id=cb2-17><a href=#cb2-17></a>    <span class=dt>padding =</span> <span class=st>"same"</span>,</span>
<span id=cb2-18><a href=#cb2-18></a>    <span class=dt>activation =</span> tf<span class=op>$</span>nn<span class=op>$</span>relu)</span>
<span id=cb2-19><a href=#cb2-19></a>  </span>
<span id=cb2-20><a href=#cb2-20></a>  <span class=co># Pooling Layer #1</span></span>
<span id=cb2-21><a href=#cb2-21></a>  <span class=co># First max pooling layer with a 2x2 filter and stride of 2</span></span>
<span id=cb2-22><a href=#cb2-22></a>  <span class=co># Input Tensor Shape: [batch_size, 28, 28, 32]</span></span>
<span id=cb2-23><a href=#cb2-23></a>  <span class=co># Output Tensor Shape: [batch_size, 14, 14, 32]</span></span>
<span id=cb2-24><a href=#cb2-24></a>  pool1 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>max_pooling2d</span>(<span class=dt>inputs =</span> conv1, <span class=dt>pool_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(2L, 2L), <span class=dt>strides =</span> 2L)</span>
<span id=cb2-25><a href=#cb2-25></a>  </span>
<span id=cb2-26><a href=#cb2-26></a>  <span class=co># Convolutional Layer #2</span></span>
<span id=cb2-27><a href=#cb2-27></a>  <span class=co># Computes 64 features using a 5x5 filter.</span></span>
<span id=cb2-28><a href=#cb2-28></a>  <span class=co># Padding is added to preserve width and height.</span></span>
<span id=cb2-29><a href=#cb2-29></a>  <span class=co># Input Tensor Shape: [batch_size, 14, 14, 32]</span></span>
<span id=cb2-30><a href=#cb2-30></a>  <span class=co># Output Tensor Shape: [batch_size, 14, 14, 64]</span></span>
<span id=cb2-31><a href=#cb2-31></a>  conv2 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>conv2d</span>(</span>
<span id=cb2-32><a href=#cb2-32></a>    <span class=dt>inputs =</span> pool1,</span>
<span id=cb2-33><a href=#cb2-33></a>    <span class=dt>filters =</span> 64L,</span>
<span id=cb2-34><a href=#cb2-34></a>    <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(5L, 5L),</span>
<span id=cb2-35><a href=#cb2-35></a>    <span class=dt>padding =</span> <span class=st>"same"</span>,</span>
<span id=cb2-36><a href=#cb2-36></a>    <span class=dt>activation =</span> tf<span class=op>$</span>nn<span class=op>$</span>relu)</span>
<span id=cb2-37><a href=#cb2-37></a>  </span>
<span id=cb2-38><a href=#cb2-38></a>  <span class=co># Pooling Layer #2</span></span>
<span id=cb2-39><a href=#cb2-39></a>  <span class=co># Second max pooling layer with a 2x2 filter and stride of 2</span></span>
<span id=cb2-40><a href=#cb2-40></a>  <span class=co># Input Tensor Shape: [batch_size, 14, 14, 64]</span></span>
<span id=cb2-41><a href=#cb2-41></a>  <span class=co># Output Tensor Shape: [batch_size, 7, 7, 64]</span></span>
<span id=cb2-42><a href=#cb2-42></a>  pool2 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>max_pooling2d</span>(<span class=dt>inputs =</span> conv2, <span class=dt>pool_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(2L, 2L), <span class=dt>strides =</span> 2L)</span>
<span id=cb2-43><a href=#cb2-43></a>  </span>
<span id=cb2-44><a href=#cb2-44></a>  <span class=co># Flatten tensor into a batch of vectors</span></span>
<span id=cb2-45><a href=#cb2-45></a>  <span class=co># Input Tensor Shape: [batch_size, 7, 7, 64]</span></span>
<span id=cb2-46><a href=#cb2-46></a>  <span class=co># Output Tensor Shape: [batch_size, 7 * 7 * 64]</span></span>
<span id=cb2-47><a href=#cb2-47></a>  pool2_flat &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/stats/reshape.html>reshape</a></span>(pool2, <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=op>-</span>1L, 7L <span class=op>*</span><span class=st> </span>7L <span class=op>*</span><span class=st> </span>64L))</span>
<span id=cb2-48><a href=#cb2-48></a>  </span>
<span id=cb2-49><a href=#cb2-49></a>  <span class=co># Dense Layer</span></span>
<span id=cb2-50><a href=#cb2-50></a>  <span class=co># Densely connected layer with 1024 neurons</span></span>
<span id=cb2-51><a href=#cb2-51></a>  <span class=co># Input Tensor Shape: [batch_size, 7 * 7 * 64]</span></span>
<span id=cb2-52><a href=#cb2-52></a>  <span class=co># Output Tensor Shape: [batch_size, 1024]</span></span>
<span id=cb2-53><a href=#cb2-53></a>  dense &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>dense</span>(<span class=dt>inputs =</span> pool2_flat, <span class=dt>units =</span> 1024L, <span class=dt>activation =</span> tf<span class=op>$</span>nn<span class=op>$</span>relu)</span>
<span id=cb2-54><a href=#cb2-54></a>  </span>
<span id=cb2-55><a href=#cb2-55></a>  <span class=co># Add dropout operation; 0.6 probability that element will be kept</span></span>
<span id=cb2-56><a href=#cb2-56></a>  dropout &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>dropout</span>(</span>
<span id=cb2-57><a href=#cb2-57></a>    <span class=dt>inputs =</span> dense, <span class=dt>rate =</span> <span class=fl>0.4</span>, <span class=dt>training =</span> (mode <span class=op>==</span><span class=st> "train"</span>))</span>
<span id=cb2-58><a href=#cb2-58></a>  </span>
<span id=cb2-59><a href=#cb2-59></a>  <span class=co># Logits layer</span></span>
<span id=cb2-60><a href=#cb2-60></a>  <span class=co># Input Tensor Shape: [batch_size, 1024]</span></span>
<span id=cb2-61><a href=#cb2-61></a>  <span class=co># Output Tensor Shape: [batch_size, 10]</span></span>
<span id=cb2-62><a href=#cb2-62></a>  logits &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>dense</span>(<span class=dt>inputs =</span> dropout, <span class=dt>units =</span> 10L)</span>
<span id=cb2-63><a href=#cb2-63></a>  </span>
<span id=cb2-64><a href=#cb2-64></a>  <span class=co># Generate Predictions (for prediction mode)</span></span>
<span id=cb2-65><a href=#cb2-65></a>  predicted_classes &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>argmax</span>(<span class=dt>input =</span> logits, <span class=dt>axis =</span> 1L, <span class=dt>name =</span> <span class=st>"predicted_classes"</span>)</span>
<span id=cb2-66><a href=#cb2-66></a>  <span class=cf>if</span> (mode <span class=op>==</span><span class=st> "infer"</span>) {</span>
<span id=cb2-67><a href=#cb2-67></a>    predictions &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(</span>
<span id=cb2-68><a href=#cb2-68></a>      <span class=dt>classes =</span> predicted_classes,</span>
<span id=cb2-69><a href=#cb2-69></a>      <span class=dt>probabilities =</span> tf<span class=op>$</span>nn<span class=op>$</span><span class=kw>softmax</span>(logits, <span class=dt>name =</span> <span class=st>"softmax_tensor"</span>)</span>
<span id=cb2-70><a href=#cb2-70></a>    )</span>
<span id=cb2-71><a href=#cb2-71></a>    <span class=kw><a href=https://rdrr.io/r/base/function.html>return</a></span>(<span class=kw><a href=../../tfestimators/reference/estimator_spec.html>estimator_spec</a></span>(<span class=dt>mode =</span> mode, <span class=dt>predictions =</span> predictions))</span>
<span id=cb2-72><a href=#cb2-72></a>  }</span>
<span id=cb2-73><a href=#cb2-73></a>  </span>
<span id=cb2-74><a href=#cb2-74></a>  <span class=co># Calculate Loss (for both "train" and "eval" modes)</span></span>
<span id=cb2-75><a href=#cb2-75></a>  onehot_labels &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>one_hot</span>(<span class=dt>indices =</span> tf<span class=op>$</span><span class=kw>cast</span>(labels, tf<span class=op>$</span>int32), <span class=dt>depth =</span> 10L)</span>
<span id=cb2-76><a href=#cb2-76></a>  loss &lt;-<span class=st> </span>tf<span class=op>$</span>losses<span class=op>$</span><span class=kw>softmax_cross_entropy</span>(</span>
<span id=cb2-77><a href=#cb2-77></a>    <span class=dt>onehot_labels =</span> onehot_labels, <span class=dt>logits =</span> logits)</span>
<span id=cb2-78><a href=#cb2-78></a>  </span>
<span id=cb2-79><a href=#cb2-79></a>  <span class=co># Configure the Training Op (for "train" mode)</span></span>
<span id=cb2-80><a href=#cb2-80></a>  <span class=cf>if</span> (mode <span class=op>==</span><span class=st> "train"</span>) {</span>
<span id=cb2-81><a href=#cb2-81></a>    optimizer &lt;-<span class=st> </span>tf<span class=op>$</span>train<span class=op>$</span><span class=kw>GradientDescentOptimizer</span>(<span class=dt>learning_rate =</span> <span class=fl>0.001</span>)</span>
<span id=cb2-82><a href=#cb2-82></a>    train_op &lt;-<span class=st> </span>optimizer<span class=op>$</span><span class=kw>minimize</span>(</span>
<span id=cb2-83><a href=#cb2-83></a>      <span class=dt>loss =</span> loss,</span>
<span id=cb2-84><a href=#cb2-84></a>      <span class=dt>global_step =</span> tf<span class=op>$</span>train<span class=op>$</span><span class=kw>get_global_step</span>())</span>
<span id=cb2-85><a href=#cb2-85></a>    <span class=kw><a href=https://rdrr.io/r/base/function.html>return</a></span>(<span class=kw><a href=../../tfestimators/reference/estimator_spec.html>estimator_spec</a></span>(<span class=dt>mode =</span> mode, <span class=dt>loss =</span> loss, <span class=dt>train_op =</span> train_op))</span>
<span id=cb2-86><a href=#cb2-86></a>  }</span>
<span id=cb2-87><a href=#cb2-87></a>    </span>
<span id=cb2-88><a href=#cb2-88></a>  <span class=co># Add evaluation metrics (for EVAL mode)</span></span>
<span id=cb2-89><a href=#cb2-89></a>  eval_metric_ops &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(<span class=dt>accuracy =</span> tf<span class=op>$</span>metrics<span class=op>$</span><span class=kw>accuracy</span>(</span>
<span id=cb2-90><a href=#cb2-90></a>    <span class=dt>labels =</span> labels, <span class=dt>predictions =</span> predicted_classes))</span>
<span id=cb2-91><a href=#cb2-91></a></span>
<span id=cb2-92><a href=#cb2-92></a>  <span class=kw><a href=https://rdrr.io/r/base/function.html>return</a></span>(<span class=kw><a href=../../tfestimators/reference/estimator_spec.html>estimator_spec</a></span>(</span>
<span id=cb2-93><a href=#cb2-93></a>    <span class=dt>mode =</span> mode, <span class=dt>loss =</span> loss, <span class=dt>eval_metric_ops =</span> eval_metric_ops))</span>
<span id=cb2-94><a href=#cb2-94></a>}</span></code></pre></div><p>The following sections (with headings corresponding to each code block above)
dive deeper into the <code>tf$layers</code> code used to create each layer, as well as how
to calculate loss, configure the training op, and generate predictions. If
you’re already experienced with CNNs and creatings estimators in tfestimators,
and find the above code intuitive, you may want to skim these sections or just
skip ahead to <a href=#training-and-evaluating-the-cnn-mnist-classifier>“Training and Evaluating the CNN MNIST
Classifier”</a>.</p><div id=input-layer class="section level3"><h3>Input Layer</h3><p>The methods in the <code>layers</code> module for creating convolutional and pooling layers
for two-dimensional image data expect input tensors to have a shape of
<code>[<em>batch_size</em>, <em>image_width</em>, <em>image_height</em>,
<em>channels</em>]</code>, defined as follows:</p><ul><li><em><code>batch_size</code></em>. Size of the subset of examples to use when performing
gradient descent during training.</li><li><em><code>image_width</code></em>. Width of the example images.</li><li><em><code>image_height</code></em>. Height of the example images.</li><li><em><code>channels</code></em>. Number of color channels in the example images. For color
images, the number of channels is 3 (red, green, blue). For monochrome
images, there is just 1 channel (black).</li></ul><p>Here, our MNIST dataset is composed of monochrome 28x28 pixel images, so the
desired shape for our input layer is <code>[<em>batch_size</em>, 28, 28,
1]</code>.</p><p>To convert our input feature map (<code>features</code>) to this shape, we can perform the
following <code>reshape</code> operation:</p><div class=sourceCode id=cb3><pre class="sourceCode r"><code class="sourceCode r"><span id=cb3-1><a href=#cb3-1></a>input_layer &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/stats/reshape.html>reshape</a></span>(features<span class=op>$</span>x, <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=op>-</span>1L, 28L, 28L, 1L))</span></code></pre></div><p>Note that we’ve indicated <code>-1</code> for batch size, which specifies that this
dimension should be dynamically computed based on the number of input values in
<code>features$x</code>, holding the size of all other dimensions constant. This allows
us to treat <code>batch_size</code> as a hyperparameter that we can tune. For example, if
we feed examples into our model in batches of 5, <code>features$x</code> will contain
3,920 values (one value for each pixel in each image), and <code>input_layer</code> will
have a shape of <code>[5, 28, 28, 1]</code>. Similarly, if we feed examples in batches of
100, <code>features$x</code> will contain 78,400 values, and <code>input_layer</code> will have a
shape of <code>[100, 28, 28, 1]</code>.</p></div><div id=convolutional-layer-1 class="section level3"><h3>Convolutional Layer #1</h3><p>In our first convolutional layer, we want to apply 32 5x5 filters to the input
layer, with a ReLU activation function. We can use the <code>conv2d()</code> method in the
<code>layers</code> module to create this layer as follows:</p><div class=sourceCode id=cb4><pre class="sourceCode r"><code class="sourceCode r"><span id=cb4-1><a href=#cb4-1></a>conv1 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>conv2d</span>(</span>
<span id=cb4-2><a href=#cb4-2></a>    <span class=dt>inputs =</span> input_layer,</span>
<span id=cb4-3><a href=#cb4-3></a>    <span class=dt>filters =</span> 32L,</span>
<span id=cb4-4><a href=#cb4-4></a>    <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(5L, 5L),</span>
<span id=cb4-5><a href=#cb4-5></a>    <span class=dt>padding =</span> <span class=st>"same"</span>,</span>
<span id=cb4-6><a href=#cb4-6></a>    <span class=dt>activation =</span> tf<span class=op>$</span>nn<span class=op>$</span>relu)</span></code></pre></div><p>The <code>inputs</code> argument specifies our input tensor, which must have the shape
<code>[<em>batch_size</em>, <em>image_width</em>, <em>image_height</em>,
<em>channels</em>]</code>. Here, we’re connecting our first convolutional layer
to <code>input_layer</code>, which has the shape <code>[<em>batch_size</em>, 28, 28,
1]</code>.</p><blockquote><p>Note: <code>conv2d()</code> will instead accept a shape of
<code>[<em>channels</em>, <em>batch_size</em>, <em>image_width</em>,
<em>image_height</em>]</code> when passed the argument
<code>data_format=channels_first</code>.</p></blockquote><p>The <code>filters</code> argument specifies the number of filters to apply (here, 32), and
<code>kernel_size</code> specifies the dimensions of the filters as <code>[<em>width</em>,
<em>height</em>]</code> (here, <code>[5, 5]</code>).</p><p class=tip><b>TIP:</b> If filter width and height have the same value, you can instead specify a
single integer for <code>kernel_size</code>—e.g., <code>kernel_size=5</code>.</p><p>The <code>padding</code> argument specifies one of two enumerated values
(case-insensitive): <code>valid</code> (default value) or <code>same</code>. To specify that the
output tensor should have the same width and height values as the input tensor,
we set <code>padding=same</code> here, which instructs TensorFlow to add 0 values to the
edges of the output tensor to preserve width and height of 28. (Without padding,
a 5x5 convolution over a 28x28 tensor will produce a 24x24 tensor, as there are
24x24 locations to extract a 5x5 tile from a 28x28 grid.)</p><p>The <code>activation</code> argument specifies the activation function to apply to the
output of the convolution. Here, we specify ReLU activation with
@{tf.nn.relu}.</p><p>Our output tensor produced by <code>conv2d()</code> has a shape of
<code>[<em>batch_size</em>, 28, 28, 32]</code>: the same width and height
dimensions as the input, but now with 32 channels holding the output from each
of the filters.</p></div><div id=pooling-layer-1 class="section level3"><h3>Pooling Layer #1</h3><p>Next, we connect our first pooling layer to the convolutional layer we just
created. We can use the <code>max_pooling2d()</code> method in <code>layers</code> to construct a
layer that performs max pooling with a 2x2 filter and stride of 2:</p><div class=sourceCode id=cb5><pre class="sourceCode r"><code class="sourceCode r"><span id=cb5-1><a href=#cb5-1></a>pool1 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>max_pooling2d</span>(<span class=dt>inputs =</span> conv1, <span class=dt>pool_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(2L, 2L), <span class=dt>strides =</span> 2L)</span></code></pre></div><p>Again, <code>inputs</code> specifies the input tensor, with a shape of
<code>[<em>batch_size</em>, <em>image_width</em>, <em>image_height</em>,
<em>channels</em>]</code>. Here, our input tensor is <code>conv1</code>, the output from
the first convolutional layer, which has a shape of <code>[<em>batch_size</em>,
28, 28, 32]</code>.</p><blockquote><p>Note: As with <code>conv2d()</code>, <code>max_pooling2d()</code> will instead
accept a shape of <code>[<em>channels</em>, <em>batch_size</em>,
<em>image_width</em>, <em>image_height</em>]</code> when passed the argument
<code>data_format=channels_first</code>.</p></blockquote><p>The <code>pool_size</code> argument specifies the size of the max pooling filter as
<code>[<em>width</em>, <em>height</em>]</code> (here, <code>[2, 2]</code>). If both
dimensions have the same value, you can instead specify a single integer (e.g.,
<code>pool_size = 2</code>).</p><p>The <code>strides</code> argument specifies the size of the stride. Here, we set a stride
of 2, which indicates that the subregions extracted by the filter should be
separated by 2 pixels in both the width and height dimensions (for a 2x2 filter,
this means that none of the regions extracted will overlap). If you want to set
different stride values for width and height, you can instead specify a tuple or
list (e.g., <code>stride = c(3, 6)</code>).</p><p>Our output tensor produced by <code>max_pooling2d()</code> (<code>pool1</code>) has a shape of
<code>[<em>batch_size</em>, 14, 14, 32]</code>: the 2x2 filter reduces width and
height by 50% each.</p></div><div id=convolutional-layer-2-and-pooling-layer-2 class="section level3"><h3>Convolutional Layer #2 and Pooling Layer #2</h3><p>We can connect a second convolutional and pooling layer to our CNN using
<code>conv2d()</code> and <code>max_pooling2d()</code> as before. For convolutional layer #2, we
configure 64 5x5 filters with ReLU activation, and for pooling layer #2, we use
the same specs as pooling layer #1 (a 2x2 max pooling filter with stride of 2):</p><div class=sourceCode id=cb6><pre class="sourceCode r"><code class="sourceCode r"><span id=cb6-1><a href=#cb6-1></a>conv2 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>conv2d</span>(</span>
<span id=cb6-2><a href=#cb6-2></a>    <span class=dt>inputs =</span> pool1,</span>
<span id=cb6-3><a href=#cb6-3></a>    <span class=dt>filters =</span> 64L,</span>
<span id=cb6-4><a href=#cb6-4></a>    <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(5L, 5L),</span>
<span id=cb6-5><a href=#cb6-5></a>    <span class=dt>padding =</span> <span class=st>"same"</span>,</span>
<span id=cb6-6><a href=#cb6-6></a>    <span class=dt>activation =</span> tf<span class=op>$</span>nn<span class=op>$</span>relu)</span>
<span id=cb6-7><a href=#cb6-7></a></span>
<span id=cb6-8><a href=#cb6-8></a>pool2 &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>max_pooling2d</span>(<span class=dt>inputs =</span> conv2, <span class=dt>pool_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(2L, 2L), <span class=dt>strides =</span> 2L)</span></code></pre></div><p>Note that convolutional layer #2 takes the output tensor of our first pooling
layer (<code>pool1</code>) as input, and produces the tensor <code>conv2</code> as output. <code>conv2</code>
has a shape of <code>[<em>batch_size</em>, 14, 14, 64]</code>, the same width
and height as <code>pool1</code> (due to <code>padding="same"</code>), and 64 channels for the 64
filters applied.</p><p>Pooling layer #2 takes <code>conv2</code> as input, producing <code>pool2</code> as output. <code>pool2</code>
has shape <code>[<em>batch_size</em>, 7, 7, 64]</code> (50% reduction of width
and height from <code>conv2</code>).</p></div><div id=dense-layer class="section level3"><h3>Dense Layer</h3><p>Next, we want to add a dense layer (with 1,024 neurons and ReLU activation) to
our CNN to perform classification on the features extracted by the
convolution/pooling layers. Before we connect the layer, however, we’ll flatten
our feature map (<code>pool2</code>) to shape <code>[<em>batch_size</em>,
<em>features</em>]</code>, so that our tensor has only two dimensions:</p><div class=sourceCode id=cb7><pre class="sourceCode r"><code class="sourceCode r"><span id=cb7-1><a href=#cb7-1></a>pool2_flat &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/stats/reshape.html>reshape</a></span>(pool2, <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=op>-</span>1L, 7L <span class=op>*</span><span class=st> </span>7L <span class=op>*</span><span class=st> </span>64L))</span></code></pre></div><p>In the <code><a href=https://rdrr.io/r/stats/reshape.html>reshape()</a></code> operation above, the <code>-1</code> signifies that the <em><code>batch_size</code></em>
dimension will be dynamically calculated based on the number of examples in our
input data. Each example has 7 (<code>pool2</code> width) * 7 (<code>pool2</code> height) * 64
(<code>pool2</code> channels) features, so we want the <code>features</code> dimension to have a value
of 7 * 7 * 64 (3136 in total). The output tensor, <code>pool2_flat</code>, has shape
<code>[<em>batch_size</em>, 3136]</code>.</p><p>Now, we can use the <code>dense()</code> method in <code>layers</code> to connect our dense layer as
follows:</p><div class=sourceCode id=cb8><pre class="sourceCode r"><code class="sourceCode r"><span id=cb8-1><a href=#cb8-1></a>dense &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>dense</span>(<span class=dt>inputs =</span> pool2_flat, <span class=dt>units =</span> 1024L, <span class=dt>activation =</span> tf<span class=op>$</span>nn<span class=op>$</span>relu)</span></code></pre></div><p>The <code>inputs</code> argument specifies the input tensor: our flattened feature map,
<code>pool2_flat</code>. The <code>units</code> argument specifies the number of neurons in the dense
layer (1,024). The <code>activation</code> argument takes the activation function; again,
we’ll use <code>tf.nn.relu</code> to add ReLU activation.</p><p>To help improve the results of our model, we also apply dropout regularization
to our dense layer, using the <code>dropout</code> method in <code>layers</code>:</p><div class=sourceCode id=cb9><pre class="sourceCode r"><code class="sourceCode r"><span id=cb9-1><a href=#cb9-1></a>dropout &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>dropout</span>(</span>
<span id=cb9-2><a href=#cb9-2></a>    <span class=dt>inputs =</span> dense, <span class=dt>rate =</span> <span class=fl>0.4</span>, <span class=dt>training =</span> (mode <span class=op>==</span><span class=st> "train"</span>))</span></code></pre></div><p>Again, <code>inputs</code> specifies the input tensor, which is the output tensor from our
dense layer (<code>dense</code>).</p><p>The <code>rate</code> argument specifies the dropout rate; here, we use <code>0.4</code>, which means
40% of the elements will be randomly dropped out during training.</p><p>The <code>training</code> argument takes a boolean specifying whether or not the model is
currently being run in training mode; dropout will only be performed if
<code>training</code> is <code>True</code>. Here, we check if the <code>mode</code> passed to our model function
<code>cnn_model_fn</code> is <code>"train</code> mode.</p><p>Our output tensor <code>dropout</code> has shape <code>[<em>batch_size</em>, 1024]</code>.</p></div><div id=logits-layer class="section level3"><h3>Logits Layer</h3><p>The final layer in our neural network is the logits layer, which will return the
raw values for our predictions. We create a dense layer with 10 neurons (one for
each target class 0–9), with linear activation (the default):</p><div class=sourceCode id=cb10><pre class="sourceCode r"><code class="sourceCode r"><span id=cb10-1><a href=#cb10-1></a>logits &lt;-<span class=st> </span>tf<span class=op>$</span>layers<span class=op>$</span><span class=kw>dense</span>(<span class=dt>inputs =</span> dropout, <span class=dt>units =</span> 10L)</span></code></pre></div><p>Our final output tensor of the CNN, <code>logits</code>, has shape
<code>[<em>batch_size</em>, 10]</code>.</p></div><div id=generate_predictions class="section level3"><h3>Generate Predictions</h3><p>The logits layer of our model returns our predictions as raw values in a
<code>[<em>batch_size</em>, 10]</code>-dimensional tensor. Let’s convert these
raw values into two different formats that our model function can return:</p><ul><li>The <strong>predicted class</strong> for each example: a digit from 0–9.</li><li>The <strong>probabilities</strong> for each possible target class for each example: the
probability that the example is a 0, is a 1, is a 2, etc.</li></ul><p>For a given example, our predicted class is the element in the corresponding row
of the logits tensor with the highest raw value. We can find the index of this
element using the @{tf.argmax}
function:</p><div class=sourceCode id=cb11><pre class="sourceCode r"><code class="sourceCode r"><span id=cb11-1><a href=#cb11-1></a>tf<span class=op>$</span><span class=kw>argmax</span>(<span class=dt>input =</span> logits, <span class=dt>axis =</span> 1L)</span></code></pre></div><p>The <code>input</code> argument specifies the tensor from which to extract maximum
values—here <code>logits</code>. The <code>axis</code> argument specifies the axis of the <code>input</code>
tensor along which to find the greatest value. Here, we want to find the largest
value along the dimension with index of 1, which corresponds to our predictions
(recall that our logits tensor has shape <code>[<em>batch_size</em>,
10]</code>).</p><p>We can derive probabilities from our logits layer by applying softmax activation
using @{tf.nn.softmax}:</p><div class=sourceCode id=cb12><pre class="sourceCode r"><code class="sourceCode r"><span id=cb12-1><a href=#cb12-1></a>tf<span class=op>$</span>nn<span class=op>$</span><span class=kw>softmax</span>(logits, <span class=dt>name =</span> <span class=st>"softmax_tensor"</span>)</span></code></pre></div><blockquote><p>Note: We use the <code>name</code> argument to explicitly name this operation
<code>softmax_tensor</code>, so we can reference it later.</p></blockquote><p>We compile our predictions in a dict, and return an <code>estimator_spec</code> object:</p><div class=sourceCode id=cb13><pre class="sourceCode r"><code class="sourceCode r"><span id=cb13-1><a href=#cb13-1></a>predicted_classes &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>argmax</span>(<span class=dt>input =</span> logits, <span class=dt>axis =</span> 1L)</span>
<span id=cb13-2><a href=#cb13-2></a><span class=cf>if</span> (mode <span class=op>==</span><span class=st> "infer"</span>) {</span>
<span id=cb13-3><a href=#cb13-3></a>  predictions &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(</span>
<span id=cb13-4><a href=#cb13-4></a>    <span class=dt>classes =</span> predicted_classes,</span>
<span id=cb13-5><a href=#cb13-5></a>    <span class=dt>probabilities =</span> tf<span class=op>$</span>nn<span class=op>$</span><span class=kw>softmax</span>(logits, <span class=dt>name =</span> <span class=st>"softmax_tensor"</span>)</span>
<span id=cb13-6><a href=#cb13-6></a>  )</span>
<span id=cb13-7><a href=#cb13-7></a>  <span class=kw><a href=https://rdrr.io/r/base/function.html>return</a></span>(<span class=kw><a href=../../tfestimators/reference/estimator_spec.html>estimator_spec</a></span>(<span class=dt>mode =</span> mode, <span class=dt>predictions =</span> predictions))</span>
<span id=cb13-8><a href=#cb13-8></a>}</span></code></pre></div></div><div id=calculating-loss class="section level3"><h3>Calculate Loss</h3><p>For both training and evaluation, we need to define a
<a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a>
that measures how closely the model’s predictions match the target classes. For
multiclass classification problems like MNIST,
<a href=https://en.wikipedia.org/wiki/Cross_entropy>cross entropy</a> is typically used
as the loss metric. The following code calculates cross entropy when the model
runs in either <code>TRAIN</code> or <code>EVAL</code> mode:</p><div class=sourceCode id=cb14><pre class="sourceCode r"><code class="sourceCode r"><span id=cb14-1><a href=#cb14-1></a>onehot_labels &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>one_hot</span>(<span class=dt>indices =</span> tf<span class=op>$</span><span class=kw>cast</span>(labels, tf<span class=op>$</span>int32), <span class=dt>depth =</span> 10L)</span>
<span id=cb14-2><a href=#cb14-2></a>loss &lt;-<span class=st> </span>tf<span class=op>$</span>losses<span class=op>$</span><span class=kw>softmax_cross_entropy</span>(</span>
<span id=cb14-3><a href=#cb14-3></a>  <span class=dt>onehot_labels =</span> onehot_labels, <span class=dt>logits =</span> logits)</span></code></pre></div><p>Let’s take a closer look at what’s happening above.</p><p>Our <code>labels</code> tensor contains a list of predictions for our examples, e.g. <code>[1, 9, ...]</code>. In order to calculate cross-entropy, first we need to convert <code>labels</code>
to the corresponding
<a href=https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science>one-hot encoding</a>:</p><pre class=none><code>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
 ...]</code></pre><p>We use the <code>tf$one_hot</code> function
to perform this conversion. <code>tf$one_hot</code> has two required arguments:</p><ul><li><code>indices</code>. The locations in the one-hot tensor that will have “on
values”—i.e., the locations of <code>1</code> values in the tensor shown above.</li><li><code>depth</code>. The depth of the one-hot tensor—i.e., the number of target classes.
Here, the depth is <code>10</code>.</li></ul><p>The following code creates the one-hot tensor for our labels, <code>onehot_labels</code>:</p><div class=sourceCode id=cb16><pre class="sourceCode r"><code class="sourceCode r"><span id=cb16-1><a href=#cb16-1></a>onehot_labels &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>one_hot</span>(<span class=dt>indices =</span> tf<span class=op>$</span><span class=kw>cast</span>(labels, tf<span class=op>$</span>int32), <span class=dt>depth =</span> 10L)</span></code></pre></div><p>Because <code>labels</code> contains a series of values from 0–9, <code>indices</code> is just our
<code>labels</code> tensor, with values cast to integers. The <code>depth</code> is <code>10</code> because we
have 10 possible target classes, one for each digit.</p><p>Next, we compute cross-entropy of <code>onehot_labels</code> and the softmax of the
predictions from our logits layer. <code>tf$losses$softmax_cross_entropy()</code> takes
<code>onehot_labels</code> and <code>logits</code> as arguments, performs softmax activation on
<code>logits</code>, calculates cross-entropy, and returns our <code>loss</code> as a scalar <code>Tensor</code>:</p><div class=sourceCode id=cb17><pre class="sourceCode r"><code class="sourceCode r"><span id=cb17-1><a href=#cb17-1></a>loss &lt;-<span class=st> </span>tf<span class=op>$</span>losses<span class=op>$</span><span class=kw>softmax_cross_entropy</span>(</span>
<span id=cb17-2><a href=#cb17-2></a>    <span class=dt>onehot_labels =</span> onehot_labels, <span class=dt>logits =</span> logits)</span></code></pre></div></div><div id=configure-the-training-op class="section level3"><h3>Configure the Training Op</h3><p>In the previous section, we defined loss for our CNN as the softmax
cross-entropy of the logits layer and our labels. Let’s configure our model to
optimize this loss value during training. We’ll use a learning rate of 0.001 and
<a href=https://en.wikipedia.org/wiki/Stochastic_gradient_descent>stochastic gradient descent</a>
as the optimization algorithm:</p><div class=sourceCode id=cb18><pre class="sourceCode r"><code class="sourceCode r"><span id=cb18-1><a href=#cb18-1></a><span class=cf>if</span> (mode <span class=op>==</span><span class=st> "train"</span>) {</span>
<span id=cb18-2><a href=#cb18-2></a>  optimizer &lt;-<span class=st> </span>tf<span class=op>$</span>train<span class=op>$</span><span class=kw>GradientDescentOptimizer</span>(<span class=dt>learning_rate =</span> <span class=fl>0.001</span>)</span>
<span id=cb18-3><a href=#cb18-3></a>  train_op &lt;-<span class=st> </span>optimizer<span class=op>$</span><span class=kw>minimize</span>(</span>
<span id=cb18-4><a href=#cb18-4></a>    <span class=dt>loss =</span> loss,</span>
<span id=cb18-5><a href=#cb18-5></a>    <span class=dt>global_step =</span> tf<span class=op>$</span>train<span class=op>$</span><span class=kw>get_global_step</span>())</span>
<span id=cb18-6><a href=#cb18-6></a>  <span class=kw><a href=https://rdrr.io/r/base/function.html>return</a></span>(<span class=kw><a href=../../tfestimators/reference/estimator_spec.html>estimator_spec</a></span>(<span class=dt>mode =</span> mode, <span class=dt>loss =</span> loss, <span class=dt>train_op =</span> train_op))</span>
<span id=cb18-7><a href=#cb18-7></a>}</span></code></pre></div></div><div id=add-evaluation-metrics class="section level3"><h3>Add evaluation metrics</h3><p>To add accuracy metric in our model, we define <code>eval_metric_ops</code> dict in EVAL
mode as follows:</p><div class=sourceCode id=cb19><pre class="sourceCode r"><code class="sourceCode r"><span id=cb19-1><a href=#cb19-1></a>eval_metric_ops &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(<span class=dt>accuracy =</span> tf<span class=op>$</span>metrics<span class=op>$</span><span class=kw>accuracy</span>(</span>
<span id=cb19-2><a href=#cb19-2></a>  <span class=dt>labels =</span> labels, <span class=dt>predictions =</span> predicted_classes))</span>
<span id=cb19-3><a href=#cb19-3></a></span>
<span id=cb19-4><a href=#cb19-4></a><span class=kw><a href=https://rdrr.io/r/base/function.html>return</a></span>(<span class=kw><a href=../../tfestimators/reference/estimator_spec.html>estimator_spec</a></span>(</span>
<span id=cb19-5><a href=#cb19-5></a>  <span class=dt>mode =</span> mode, <span class=dt>loss =</span> loss, <span class=dt>eval_metric_ops =</span> eval_metric_ops))</span></code></pre></div></div></div><div id=training_and_evaluating_the_cnn_mnist_classifier class="section level2"><h2>Training and Evaluating the CNN MNIST Classifier</h2><p>We’ve coded our MNIST CNN model function; now we’re ready to train and evaluate
it.</p><div id=load-training-and-test-data class="section level3"><h3>Load Training and Test Data</h3><p>First, let’s load our training and test data:</p><div class=sourceCode id=cb20><pre class="sourceCode r"><code class="sourceCode r"><span id=cb20-1><a href=#cb20-1></a>np &lt;-<span class=st> </span><span class=kw><a href=../../tensorflow/reference/reexports.html>import</a></span>(<span class=st>"numpy"</span>, <span class=dt>convert =</span> <span class=ot>FALSE</span>)</span>
<span id=cb20-2><a href=#cb20-2></a><span class=co># Load training and eval data</span></span>
<span id=cb20-3><a href=#cb20-3></a>mnist &lt;-<span class=st> </span>tf<span class=op>$</span>contrib<span class=op>$</span>learn<span class=op>$</span>datasets<span class=op>$</span><span class=kw>load_dataset</span>(<span class=st>"mnist"</span>)</span>
<span id=cb20-4><a href=#cb20-4></a>train_data &lt;-<span class=st> </span>np<span class=op>$</span><span class=kw>asmatrix</span>(mnist<span class=op>$</span>train<span class=op>$</span>images, <span class=dt>dtype =</span> np<span class=op>$</span>float32)</span>
<span id=cb20-5><a href=#cb20-5></a>train_labels &lt;-<span class=st> </span>np<span class=op>$</span><span class=kw>asarray</span>(mnist<span class=op>$</span>train<span class=op>$</span>labels, <span class=dt>dtype =</span> np<span class=op>$</span>int32)</span>
<span id=cb20-6><a href=#cb20-6></a>eval_data &lt;-<span class=st> </span>np<span class=op>$</span><span class=kw>asmatrix</span>(mnist<span class=op>$</span>test<span class=op>$</span>images, <span class=dt>dtype =</span> np<span class=op>$</span>float32)</span>
<span id=cb20-7><a href=#cb20-7></a>eval_labels &lt;-<span class=st> </span>np<span class=op>$</span><span class=kw>asarray</span>(mnist<span class=op>$</span>test<span class=op>$</span>labels, <span class=dt>dtype =</span> np<span class=op>$</span>int32)</span></code></pre></div><p>We store the training feature data (the raw pixel values for 55,000 images of
hand-drawn digits) and training labels (the corresponding value from 0–9 for
each image) as <a href=https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html>numpy
arrays</a>
in <code>train_data</code> and <code>train_labels</code>, respectively. Similarly, we store the
evaluation feature data (10,000 images) and evaluation labels in <code>eval_data</code>
and <code>eval_labels</code>, respectively.</p></div><div id=create-the-estimator class="section level3"><h3>Create the Estimator</h3><p>Next, let’s create an <code>estimator</code> (a TensorFlow class for performing high-level
model training, evaluation, and inference) for our model.</p><div class=sourceCode id=cb21><pre class="sourceCode r"><code class="sourceCode r"><span id=cb21-1><a href=#cb21-1></a><span class=co># Create the Estimator</span></span>
<span id=cb21-2><a href=#cb21-2></a>mnist_classifier &lt;-<span class=st> </span><span class=kw><a href=../../tfestimators/reference/estimator.html>estimator</a></span>(</span>
<span id=cb21-3><a href=#cb21-3></a>  <span class=dt>model_fn =</span> cnn_model_fn, <span class=dt>model_dir =</span> <span class=st>"/tmp/mnist_convnet_model"</span>)</span></code></pre></div><p>The <code>model_fn</code> argument specifies the model function to use for training,
evaluation, and prediction; we pass it the <code>cnn_model_fn</code> we created in
<a href=#building-the-cnn-mnist-classifier>“Building the CNN MNIST Classifier.”</a> The
<code>model_dir</code> argument specifies the directory where model data (checkpoints) will
be saved (here, we specify the temp directory <code>/tmp/mnist_convnet_model</code>, but
feel free to change to another directory of your choice).</p><blockquote><p>Note: For an in-depth walkthrough of the TensorFlow <code>Estimator</code> API, see the
<a href=../creating_estimators/>tutorial for custom estimator</a>.</p></blockquote></div><div id=set_up_a_logging_hook class="section level3"><h3>Set Up a Logging Hook</h3><p>Since CNNs can take a while to train, let’s set up some logging so we can track
progress during training. We can use TensorFlow’s <code>SessionRunHook</code> to create a
<code>hook_logging_tensor</code> that will log the predicted classes from the <code>argmax</code> operation.</p><div class=sourceCode id=cb22><pre class="sourceCode r"><code class="sourceCode r"><span id=cb22-1><a href=#cb22-1></a><span class=co># Set up logging for predicted classes</span></span>
<span id=cb22-2><a href=#cb22-2></a>tensors_to_log &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(<span class=dt>predicted_classes =</span> <span class=st>"predicted_classes"</span>)</span>
<span id=cb22-3><a href=#cb22-3></a>logging_hook &lt;-<span class=st> </span><span class=kw><a href=../../tfestimators/reference/hook_logging_tensor.html>hook_logging_tensor</a></span>(</span>
<span id=cb22-4><a href=#cb22-4></a>  <span class=dt>tensors =</span> tensors_to_log, <span class=dt>every_n_iter =</span> <span class=dv>50</span>)</span></code></pre></div><p>We store a dict of the tensors we want to log in <code>tensors_to_log</code>. Each key is a
label of our choice that will be printed in the log output, and the
corresponding label is the name of a <code>Tensor</code> in the TensorFlow graph. Here, our
<code>predicted classes</code> can be found in <code>predicted_classes</code>, the name we gave our argmax
operation earlier when we generated the predicted classes in <code>cnn_model_fn</code>.</p><p>Next, we create the <code>hook_logging_tensor</code>, passing <code>tensors_to_log</code> to the
<code>tensors</code> argument. We set <code>every_n_iter = 50</code>, which specifies that probabilities
should be logged after every 50 steps of training.</p></div><div id=train-the-model class="section level3"><h3>Train the Model</h3><p>Now we’re ready to train our model, which we can do by creating <code>train_input_fn</code>
ans calling <code><a href=../../tensorflow/reference/train.html>train()</a></code> on <code>mnist_classifier</code>.</p><div class=sourceCode id=cb23><pre class="sourceCode r"><code class="sourceCode r"><span id=cb23-1><a href=#cb23-1></a><span class=co># Train the model</span></span>
<span id=cb23-2><a href=#cb23-2></a>train_input_fn &lt;-<span class=st> </span><span class=cf>function</span>(features_as_named_list) {</span>
<span id=cb23-3><a href=#cb23-3></a>  tf<span class=op>$</span>estimator<span class=op>$</span>inputs<span class=op>$</span><span class=kw><a href=../../tfestimators/reference/numpy_input_fn.html>numpy_input_fn</a></span>(</span>
<span id=cb23-4><a href=#cb23-4></a>    <span class=dt>x =</span> <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(<span class=dt>x =</span> train_data),</span>
<span id=cb23-5><a href=#cb23-5></a>    <span class=dt>y =</span> train_labels,</span>
<span id=cb23-6><a href=#cb23-6></a>    <span class=dt>batch_size =</span> 100L,</span>
<span id=cb23-7><a href=#cb23-7></a>    <span class=dt>num_epochs =</span> <span class=ot>NULL</span>,</span>
<span id=cb23-8><a href=#cb23-8></a>    <span class=dt>shuffle =</span> <span class=ot>TRUE</span>)</span>
<span id=cb23-9><a href=#cb23-9></a>}</span>
<span id=cb23-10><a href=#cb23-10></a><span class=kw><a href=../../tensorflow/reference/train.html>train</a></span>(</span>
<span id=cb23-11><a href=#cb23-11></a>  mnist_classifier,</span>
<span id=cb23-12><a href=#cb23-12></a>  <span class=dt>input_fn =</span> train_input_fn,</span>
<span id=cb23-13><a href=#cb23-13></a>  <span class=dt>steps =</span> <span class=dv>20</span>,</span>
<span id=cb23-14><a href=#cb23-14></a>  <span class=dt>hooks =</span> logging_hook)</span></code></pre></div><p>In the <code>numpy_input_fn</code> call, we pass the training feature data and labels to
<code>x</code> (as a dict) and <code>y</code>, respectively. We set a <code>batch_size</code> of <code>100</code> (which
means that the model will train on minibatches of 100 examples at each step).
<code>num_epochs = NULL</code> means that the model will train until the specified number of
steps is reached. We also set <code>shuffle = TRUE</code> to shuffle the training data.
In the <code>train</code> call, we set <code>steps = 2</code>
(which means the model will train for 10 steps total).</p></div><div id=evaluate-the-model class="section level3"><h3>Evaluate the Model</h3><p>Once training is complete, we want to evaluate our model to determine its
accuracy on the MNIST test set. We call the <code>evaluate</code> method, which evaluates
the metrics we specified in <code>eval_metric_ops</code> argument in the <code>model_fn</code>.</p><div class=sourceCode id=cb24><pre class="sourceCode r"><code class="sourceCode r"><span id=cb24-1><a href=#cb24-1></a><span class=co># Evaluate the model and print results</span></span>
<span id=cb24-2><a href=#cb24-2></a>eval_input_fn &lt;-<span class=st> </span><span class=cf>function</span>(features_as_named_list) {</span>
<span id=cb24-3><a href=#cb24-3></a>  tf<span class=op>$</span>estimator<span class=op>$</span>inputs<span class=op>$</span><span class=kw><a href=../../tfestimators/reference/numpy_input_fn.html>numpy_input_fn</a></span>(</span>
<span id=cb24-4><a href=#cb24-4></a>    <span class=dt>x =</span> <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(<span class=dt>x =</span> eval_data),</span>
<span id=cb24-5><a href=#cb24-5></a>    <span class=dt>y =</span> eval_labels,</span>
<span id=cb24-6><a href=#cb24-6></a>    <span class=dt>batch_size =</span> 100L,</span>
<span id=cb24-7><a href=#cb24-7></a>    <span class=dt>num_epochs =</span> <span class=ot>NULL</span>,</span>
<span id=cb24-8><a href=#cb24-8></a>    <span class=dt>shuffle =</span> <span class=ot>TRUE</span>)</span>
<span id=cb24-9><a href=#cb24-9></a>}</span>
<span id=cb24-10><a href=#cb24-10></a><span class=kw><a href=../../tensorflow/reference/evaluate.html>evaluate</a></span>(</span>
<span id=cb24-11><a href=#cb24-11></a>  mnist_classifier,</span>
<span id=cb24-12><a href=#cb24-12></a>  <span class=dt>input_fn =</span> eval_input_fn,</span>
<span id=cb24-13><a href=#cb24-13></a>  <span class=dt>steps =</span> <span class=dv>10</span>,</span>
<span id=cb24-14><a href=#cb24-14></a>  <span class=dt>hooks =</span> logging_hook)</span></code></pre></div><p>To create <code>eval_input_fn</code>, we set <code>num_epochs = 1</code>, so that the model evaluates
the metrics over one epoch of data and returns the result. We also set
<code>shuffle = FALSE</code> to iterate through the data sequentially.</p><p>We pass our <code>logging_hook</code> to the <code>hooks</code> argument, so that it will be triggered during
evaluation.</p></div><div id=run-the-model class="section level3"><h3>Run the Model</h3><p>We’ve coded the CNN model function, <code>Estimator</code>, and the training/evaluation
logic; now let’s see the results.</p><p>As the model trains, you’ll see log output like the following:</p><div class=sourceCode id=cb25><pre class="sourceCode r"><code class="sourceCode r"><span id=cb25-1><a href=#cb25-1></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Create CheckpointSaverHook.</span>
<span id=cb25-2><a href=#cb25-2></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Restoring parameters from <span class=op>/</span>tmp<span class=op>/</span>mnist_convnet_model<span class=op>/</span>model.ckpt<span class=dv>-5</span></span>
<span id=cb25-3><a href=#cb25-3></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Saving checkpoints <span class=cf>for</span> <span class=dv>6</span> into <span class=op>/</span>tmp<span class=op>/</span>mnist_convnet_model<span class=op>/</span>model.ckpt.</span>
<span id=cb25-4><a href=#cb25-4></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>loss =<span class=st> </span><span class=fl>2.29727</span>, step =<span class=st> </span><span class=dv>6</span></span>
<span id=cb25-5><a href=#cb25-5></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Saving checkpoints <span class=cf>for</span> <span class=dv>7</span> into <span class=op>/</span>tmp<span class=op>/</span>mnist_convnet_model<span class=op>/</span>model.ckpt.</span>
<span id=cb25-6><a href=#cb25-6></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Loss <span class=cf>for</span> final step<span class=op>:</span><span class=st> </span><span class=dv>2</span>.<span class=fl>30916.</span></span></code></pre></div><p>You’ll see log output like the following during model evaluation with the <code>predicted_classes</code> that we included in the <code>logging_hook</code>:</p><div class=sourceCode id=cb26><pre class="sourceCode r"><code class="sourceCode r"><span id=cb26-1><a href=#cb26-1></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Starting evaluation at <span class=dv>2017-07-04-17</span><span class=op>:</span><span class=dv>05</span><span class=op>:</span><span class=dv>28</span></span>
<span id=cb26-2><a href=#cb26-2></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Restoring parameters from <span class=op>/</span>tmp<span class=op>/</span>mnist_convnet_model<span class=op>/</span>model.ckpt<span class=dv>-19</span></span>
<span id=cb26-3><a href=#cb26-3></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>predicted_classes =<span class=st> </span>[<span class=dv>6</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>6</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>3</span> <span class=dv>1</span> <span class=dv>1</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>6</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span></span>
<span id=cb26-4><a href=#cb26-4></a> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>4</span> <span class=dv>4</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>6</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>6</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span></span>
<span id=cb26-5><a href=#cb26-5></a> <span class=dv>9</span> <span class=dv>3</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>3</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span>]</span>
<span id=cb26-6><a href=#cb26-6></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Evaluation [<span class=dv>1</span><span class=op>/</span><span class=dv>10</span>]</span>
<span id=cb26-7><a href=#cb26-7></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Evaluation [<span class=dv>2</span><span class=op>/</span><span class=dv>10</span>]</span>
<span id=cb26-8><a href=#cb26-8></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>predicted_classes =<span class=st> </span>[<span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>4</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>4</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>1</span> <span class=dv>9</span></span>
<span id=cb26-9><a href=#cb26-9></a> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>4</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>4</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span></span>
<span id=cb26-10><a href=#cb26-10></a> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>1</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span> <span class=dv>9</span>] (<span class=fl>0.204</span> sec)</span>
<span id=cb26-11><a href=#cb26-11></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Evaluation [<span class=dv>3</span><span class=op>/</span><span class=dv>10</span>]</span>
<span id=cb26-12><a href=#cb26-12></a>INFO<span class=op>:</span>tensorflow<span class=op>:</span>Evaluation [<span class=dv>4</span><span class=op>/</span><span class=dv>10</span>]</span>
<span id=cb26-13><a href=#cb26-13></a>...</span></code></pre></div></div></div></div><footer>Copyright © 2015-2020 The TensorFlow Authors and RStudio, PBC.
<script type=text/javascript>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');_st('install','Ne8tbLfE121Pkj3xMr_G','2.0.0');</script></footer></div></div></body></html>