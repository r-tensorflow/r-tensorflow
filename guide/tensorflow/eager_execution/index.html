<!doctype html><html><head><script>theBaseUrl=location.origin+"/";</script><meta charset=utf-8><meta name=viewport content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1"><title>Eager execution</title><meta name=generator content="Hugo 0.58.3"><meta name=description content="Documentation for the TensorFlow for R interface"><link rel=canonical href=/guide/tensorflow/eager_execution/><meta name=author content="J.J. Allaire"><meta property=og:url content=/guide/tensorflow/eager_execution/><meta property=og:title content="TensorFlow for R"><meta name=apple-mobile-web-app-title content="TensorFlow for R"><meta name=apple-mobile-web-app-capable content=yes><meta name=apple-mobile-web-app-status-bar-style content=black-translucent><style>@font-face{font-family:icon;src:url(fonts/icon.eot?52m981);src:url(fonts/icon.eot?#iefix52m981) format('embedded-opentype'),url(fonts/icon.woff?52m981) format('woff'),url(fonts/icon.ttf?52m981) format('truetype'),url(fonts/icon.svg?52m981#icon) format('svg');font-weight:400;font-style:normal}</style><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/site-styles.css><script src=/js/vendor.js></script><script src=/js/app.js></script><link rel="shortcut icon" href=/images/favicon.png><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body><div class=single-page><nav data-gumshoe-header aria-label=Header id=header class=top-menu><div class=left><a href=/ data-parenturl class="top-menu-item site-title">TensorFlow for R</a>
<span class=logo-from>from</span>
<a href=/><div id=logo class=logo></div></a></div><div class=right><div class=top-menu-items id=top-menu-items><a href=/ data-parenturl=/ class=top-menu-item>Home</a>
<a href=/installation/ data-parenturl=/installation/ class=top-menu-item>Installation</a>
<a href=/tutorials/ data-parenturl=/tutorials/ class=top-menu-item>Tutorials</a>
<a href=/guide/ data-parenturl=/guide/ class=top-menu-item>Guide</a>
<a href=/deploy/ data-parenturl=/deploy/ class=top-menu-item>Deploy</a>
<a href=/tools/ data-parenturl=/tools/ class=top-menu-item>Tools</a>
<a href=/reference/keras data-parenturl=/reference/keras class=top-menu-item>API</a>
<a href=/learn/resources/ data-parenturl=/learn/resources/ class=top-menu-item>Learn</a>
<a href=/blog.html data-parenturl=/blog.html class=top-menu-item>Blog</a></div><a href=https://github.com/rstudio/tensorflow class=github-logo><i class="fa fa-lg fa-github" aria-hidden=true></i></a><div class=search-button><i class="fa fa-lg fa-search"></i></div></div></nav><nav aria-label=Header id=mobile-header><a href=/>TensorFlow for R</a><div class=right><a href=https://github.com/rstudio/tensorflow class=github-logo><i class="fa fa-lg fa-github" aria-hidden=true></i></a><div class=hamburger><i class="fa fa-lg fa-bars" aria-hidden=true></i></div></div></nav><div id=mobile-menu-container><ul id=mobile-menu><li><a href=/>Home</a></li><ul></ul><li><a href=/installation/>Installation</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/installation/>Installing TensorFlow</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/installation/>Quick start</a></li><li><a href=/installation/custom/>Custom Installation</a></li></ul><li><a href=/installation/gpu>Using a GPU</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/installation/gpu/>Overview</a></li><li><a href=/installation/gpu/local_gpu/>Local GPU</a></li><li><a href=/installation/gpu/cloud_server_gpu/>Cloud Server</a></li><li><a href=/installation/gpu/cloud_desktop_gpu/>Cloud Desktop</a></li></ul></ul><li><a href=/tutorials/>Tutorials</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/>Overview</a></li><li><a href>Beginners</a></li><li><a href=/tutorials/beginners/>Quickstart</a></li><li><a href=/tutorials/beginners/basic-ml/>Basic ML with Keras</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/beginners/basic-ml/>Overview</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_classification/>Image Classification</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_regression/>Regression</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_text_classification/>Text Classification</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_basic_text_classification_with_tfhub/>Transfer learning with tfhub</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_overfit_underfit/>Overfitting and Underfitting</a></li><li><a href=/tutorials/beginners/basic-ml/tutorial_save_and_restore/>Save and Restore Models</a></li></ul><li><a href=/tutorials/beginners/load/load_csv/>Load and preprocess data</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/beginners/load/load_csv/>Load CSV data</a></li><li><a href=/tutorials/beginners/load/load_image/>Load image data</a></li></ul><li><a href>Advanced</a></li><li><a href=/tutorials/advanced/>Quickstart</a></li><li><a href=/tutorials/advanced/customization/tensors-operations/>Customization</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/customization/tensors-operations/>Tensors and operations</a></li><li><a href=/tutorials/advanced/customization/custom-layers/>Custom layers</a></li><li><a href=/tutorials/advanced/customization/autodiff/>Automatic differentiation</a></li><li><a href=/tutorials/advanced/customization/custom-training/>Custom training</a></li></ul><li><a href=/tutorials/advanced/images/cnn/>Images</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/images/cnn/>Convolutional Neural Network</a></li><li><a href=/tutorials/advanced/images/transfer-learning-hub/>Transfer Learning with tfhub</a></li></ul><li><a href=/tutorials/advanced/structured/classify/>Structured data</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/structured/classify/>Classify structured data</a></li></ul><li><a href=/tutorials/advanced/distributed/distributed_training_with_keras/>Distributed training</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tutorials/advanced/distributed/distributed_training_with_keras/>Distributed training with Keras</a></li></ul></ul><li><a href=/guide/>Guide</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/>Overview</a></li><li><a href>Keras</a></li><li><a href=/guide/keras/>Getting started</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/keras/>Overview</a></li><li><a href=/guide/keras/guide_keras/>Keras basics</a></li><li><a href=/guide/keras/sequential_model/>Sequential API</a></li><li><a href=/guide/keras/functional_api/>Functional API</a></li><li><a href=/guide/keras/saving_serializing/>Saving and serializing models</a></li><li><a href=/guide/keras/faq/>Frequently Asked Questions</a></li></ul><li><a href=/guide/keras/custom_layers/>Advanced</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/keras/custom_layers/>Custom Layers</a></li><li><a href=/guide/keras/custom_models/>Custom Models</a></li><li><a href=/guide/keras/training_callbacks/>Training Callbacks</a></li><li><a href=/guide/keras/applications/>Pre-Trained Models</a></li><li><a href=/guide/keras/training_visualization/>Training Visualization</a></li></ul><li><a href=/guide/keras/examples/>Examples</a></li><li><a href>TensorFlow Mechanics</a></li><li><a href=/guide/tensorflow/eager_execution>Basics</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tensorflow/eager_execution/>Eager execution</a></li><li><a href=/guide/tensorflow/variable/>Variables</a></li><li><a href=/guide/tensorflow/tensors/>Tensors</a></li></ul><li><a href=/guide/tensorflow/ragged_tensors>Advanced</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tensorflow/ragged_tensors/>Ragged tensors</a></li></ul><li><a href>Data input pipeline</a></li><li><a href=/guide/tfdatasets/introduction>Overview</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfdatasets/introduction/>Using Datasets</a></li></ul><li><a href=/guide/tfdatasets/feature_spec>Feature spec API</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfdatasets/feature_spec/>Feature Spec interface</a></li><li><a href=/guide/tfdatasets/feature_columns/>Feature columns</a></li></ul><li><a href>TensorFlow Hub</a></li><li><a href=/guide/tfhub/intro>Basics</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfhub/intro/>Overview</a></li><li><a href=/guide/tfhub/hub-with-keras/>Using with Keras</a></li></ul><li><a href=/guide/tfhub/key-concepts>Key concepts</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/tfhub/key-concepts/>Key Concepts</a></li></ul><li><a href=/guide/tfhub/examples/>Examples</a></li><li><a href>Model saving</a></li><li><a href=/guide/saving/checkpoints>Checkpoints</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/saving/checkpoints/>Checkpoints</a></li></ul><li><a href=/guide/saving/saved_model>Saved Model</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/guide/saving/saved_model/>Saved Model</a></li></ul></ul><li><a href=/deploy/>Deploy</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/deploy/>Overview</a></li><li><a href=/deploy/plumber/>Plumber</a></li><li><a href=/deploy/shiny/>Shiny</a></li><li><a href=/deploy/docker/>TensorFlow Serving</a></li><li><a href=/deploy/rsconnect/>RStudio Connect</a></li></ul><li><a href=/tools/>Tools</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/>Overview</a></li><li><a href=/tools/tfruns/>Training Runs</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/tfruns/overview/>Introduction to tfruns</a></li><li><a href=/tools/tfruns/tuning/>Hyperparameter Tuning</a></li><li><a href=/tools/tfruns/managing/>Managing Training Runs</a></li></ul><li><a href=/tools/cloudml/>Cloud ML</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/tools/cloudml/getting_started/>Getting Started</a></li><li><a href=/tools/cloudml/training/>Training with CloudML</a></li><li><a href=/tools/cloudml/tuning/>Hyperparameter Tuning</a></li><li><a href=/tools/cloudml/storage/>Google Cloud Storage</a></li><li><a href=/tools/cloudml/deployment/>Deploying Models</a></li></ul><li><a href=/tools/tensorboard/tensorboard/>TensorBoard</a></li></ul><li><a href=/reference/keras>API</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/reference/keras/>keras</a></li><li><a href=/reference/tensorflow/>tensorflow</a></li><li><a href=/reference/tfdatasets/>tfdatasets</a></li><li><a href=/reference/tfruns/>tfruns</a></li></ul><li><a href=/learn/resources/>Learn</a>
<i class="fa fa-chevron-right" aria-hidden=true></i></li><ul><li><a href=/learn/resources/>Resources</a></li></ul><li><a href=/blog.html>Blog</a></li><ul></ul></ul></div><div id=search-bar class=search-bar><p class=search-bar__icon><i class="fa fa-lg fa-search"></i></p><div class=search-bar__input><input type=text name=search class=st-default-search-input></div><div class=search-bar__exit><i class="fa fa-lg fa-times"></i></div><div class=inline-search-results><ul></ul></div></div></div><div class="page documentation"><div class=side-menu id=side-menu><ul class=side-menu-list data-parenturl=/ style=display:none></ul><ul class=side-menu-list data-parenturl=/installation/ style=display:none><li class=side-menu__item><a href=/installation/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Installing TensorFlow</p></a></li><li class=side-menu__item><a href=/installation/gpu class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Using a GPU</p></a></li></ul><ul class=side-menu-list data-parenturl=/tutorials/ style=display:none><li class=side-menu__item><a href=/tutorials/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Overview</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">Beginners</p></span></li><li class=side-menu__item><a href=/tutorials/beginners/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Quickstart</p></a></li><li class=side-menu__item><a href=/tutorials/beginners/basic-ml/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Basic ML with Keras</p></a></li><li class=side-menu__item><a href=/tutorials/beginners/load/load_csv/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Load and preprocess data</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">Advanced</p></span></li><li class=side-menu__item><a href=/tutorials/advanced/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Quickstart</p></a></li><li class=side-menu__item><a href=/tutorials/advanced/customization/tensors-operations/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Customization</p></a></li><li class=side-menu__item><a href=/tutorials/advanced/images/cnn/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Images</p></a></li><li class=side-menu__item><a href=/tutorials/advanced/structured/classify/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Structured data</p></a></li><li class=side-menu__item><a href=/tutorials/advanced/distributed/distributed_training_with_keras/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Distributed training</p></a></li></ul><ul class=side-menu-list data-parenturl=/guide/ style=display:none><li class=side-menu__item><a href=/guide/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Overview</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">Keras</p></span></li><li class=side-menu__item><a href=/guide/keras/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Getting started</p></a></li><li class=side-menu__item><a href=/guide/keras/custom_layers/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Advanced</p></a></li><li class=side-menu__item><a href=/guide/keras/examples/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Examples</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">TensorFlow Mechanics</p></span></li><li class="side-menu__item active"><a href=/guide/tensorflow/eager_execution class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Basics</p></a><ul class=side-menu__sub><span style=display:none>guide</span><li class="side-menu__sub__item active"><a id=menu-link-/guide/tensorflow/eager_execution/ class=side-menu__sub__item__text href=/guide/tensorflow/eager_execution/ data-url=/guide/tensorflow/eager_execution/>Eager execution</a></li><span style=display:none>guide</span><li class=side-menu__sub__item><a id=menu-link-/guide/tensorflow/variable/ class=side-menu__sub__item__text href=/guide/tensorflow/variable/ data-url=/guide/tensorflow/variable/>Variables</a></li><span style=display:none>guide</span><li class=side-menu__sub__item><a id=menu-link-/guide/tensorflow/tensors/ class=side-menu__sub__item__text href=/guide/tensorflow/tensors/ data-url=/guide/tensorflow/tensors/>Tensors</a></li></ul></li><li class=side-menu__item><a href=/guide/tensorflow/ragged_tensors class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Advanced</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">Data input pipeline</p></span></li><li class=side-menu__item><a href=/guide/tfdatasets/introduction class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Overview</p></a></li><li class=side-menu__item><a href=/guide/tfdatasets/feature_spec class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Feature spec API</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">TensorFlow Hub</p></span></li><li class=side-menu__item><a href=/guide/tfhub/intro class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Basics</p></a></li><li class=side-menu__item><a href=/guide/tfhub/key-concepts class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Key concepts</p></a></li><li class=side-menu__item><a href=/guide/tfhub/examples/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Examples</p></a></li><li class=side-menu__item><span class=side-menu__item__link><p class="side-menu__item__link__text side-menu__item__link__text__block">Model saving</p></span></li><li class=side-menu__item><a href=/guide/saving/checkpoints class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Checkpoints</p></a></li><li class=side-menu__item><a href=/guide/saving/saved_model class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Saved Model</p></a></li></ul><ul class=side-menu-list data-parenturl=/deploy/ style=display:none><li class=side-menu__item><a href=/deploy/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Overview</p></a></li><li class=side-menu__item><a href=/deploy/plumber/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Plumber</p></a></li><li class=side-menu__item><a href=/deploy/shiny/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Shiny</p></a></li><li class=side-menu__item><a href=/deploy/docker/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>TensorFlow Serving</p></a></li><li class=side-menu__item><a href=/deploy/rsconnect/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>RStudio Connect</p></a></li></ul><ul class=side-menu-list data-parenturl=/tools/ style=display:none><li class=side-menu__item><a href=/tools/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Overview</p></a></li><li class=side-menu__item><a href=/tools/tfruns/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Training Runs</p></a></li><li class=side-menu__item><a href=/tools/cloudml/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Cloud ML</p></a></li><li class=side-menu__item><a href=/tools/tensorboard/tensorboard/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>TensorBoard</p></a></li></ul><ul class=side-menu-list data-parenturl=/reference/keras style=display:none><li class=side-menu__item><a href=/reference/keras/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>keras</p></a></li><li class=side-menu__item><a href=/reference/tensorflow/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>tensorflow</p></a></li><li class=side-menu__item><a href=/reference/tfdatasets/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>tfdatasets</p></a></li><li class=side-menu__item><a href=/reference/tfruns/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>tfruns</p></a></li></ul><ul class=side-menu-list data-parenturl=/learn/resources/ style=display:none><li class=side-menu__item><a href=/learn/resources/ class=side-menu__item__link><img class=side-menu__item__link__icon src=/images/icons/block-retina.png alt><p class=side-menu__item__link__text>Resources</p></a></li></ul><ul class=side-menu-list data-parenturl=/blog.html style=display:none></ul></div><div class=content><h1 class=content-header>Eager execution</h1><div class=markdowned><div class=doc-page><div class=doc-page-index><ul id=gumshoe-container data-gumshoe></ul></div><div class=doc-page-body><p>TensorFlow’s eager execution is an imperative programming environment that
evaluates operations immediately, without building graphs: operations return
concrete values instead of constructing a computational graph to run later. This
makes it easy to get started with TensorFlow and debug models, and it
reduces boilerplate as well. To follow along with this guide, run the code
samples below in an interactive <code>R</code> interpreter.</p><p>Eager execution is a flexible machine learning platform for research and
experimentation, providing:</p><ul><li><em>An intuitive interface</em>—Structure your code naturally and use R data
structures. Quickly iterate on small models and small data.</li><li><em>Easier debugging</em>—Call ops directly to inspect running models and test
changes. Use standard R debugging tools for immediate error reporting.</li><li><em>Natural control flow</em>—Use R control flow instead of graph control
flow, simplifying the specification of dynamic models.</li></ul><p>Eager execution supports most TensorFlow operations and GPU acceleration.</p><p>Note: Some models may experience increased overhead with eager execution
enabled. Performance improvements are ongoing, but please
<a href=https://github.com/tensorflow/tensorflow/issues>file a bug</a> if you find a
problem and share your benchmarks.</p><div id=setup-and-basic-usage class="section level2"><h2>Setup and basic usage</h2><div class=sourceCode id=cb1><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb1-1 data-line-number=1><span class=kw><a href=https://rdrr.io/r/base/library.html>library</a></span>(tensorflow)</a>
<a class=sourceLine id=cb1-2 data-line-number=2><span class=kw><a href=https://rdrr.io/r/base/library.html>library</a></span>(tfautograph)</a>
<a class=sourceLine id=cb1-3 data-line-number=3><span class=kw><a href=https://rdrr.io/r/base/library.html>library</a></span>(keras)</a>
<a class=sourceLine id=cb1-4 data-line-number=4><span class=kw><a href=https://rdrr.io/r/base/library.html>library</a></span>(tfdatasets)</a></code></pre></div><p>In Tensorflow 2.0, eager execution is enabled by default.</p><div class=sourceCode id=cb2><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb2-1 data-line-number=1>tf<span class=op>$</span><span class=kw>executing_eagerly</span>()</a></code></pre></div><pre><code>## [1] TRUE</code></pre><p>Now you can run TensorFlow operations and the results will return immediately:</p><div class=sourceCode id=cb4><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb4-1 data-line-number=1>x &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/matrix.html>matrix</a></span>(<span class=dv>2</span>, <span class=dt>ncol =</span> <span class=dv>1</span>, <span class=dt>nrow =</span> <span class=dv>1</span>)</a>
<a class=sourceLine id=cb4-2 data-line-number=2>m &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>matmul</span>(x, x)</a>
<a class=sourceLine id=cb4-3 data-line-number=3>m</a></code></pre></div><pre><code>## tf.Tensor([[4.]], shape=(1, 1), dtype=float64)</code></pre><p>Enabling eager execution changes how TensorFlow operations behave—now they
immediately evaluate and return their values to R <code>tf$Tensor</code> objects
reference concrete values instead of symbolic handles to nodes in a computational
graph. Since there isn’t a computational graph to build and run later in a
session, it’s easy to inspect results using <code><a href=https://rdrr.io/r/base/print.html>print()</a></code> or a debugger. Evaluating,
printing, and checking tensor values does not break the flow for computing
gradients.</p><p>Eager execution works nicely with R. TensorFlow
<a href=https://www.tensorflow.org/api_guides/python/math_ops>math operations</a> convert
R objects and R arrays to <code>tf$Tensor</code> objects. The
<code>as.array</code> method returns the object’s value as an R <code>array</code>.</p><div class=sourceCode id=cb6><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb6-1 data-line-number=1>a &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>constant</span>(<span class=kw><a href=https://rdrr.io/r/base/matrix.html>matrix</a></span>(<span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=dv>1</span>,<span class=dv>2</span>,<span class=dv>3</span>,<span class=dv>4</span>), <span class=dt>ncol =</span> <span class=dv>2</span>))</a>
<a class=sourceLine id=cb6-2 data-line-number=2>a</a></code></pre></div><pre><code>## tf.Tensor(
## [[1. 3.]
##  [2. 4.]], shape=(2, 2), dtype=float64)</code></pre><div class=sourceCode id=cb8><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb8-1 data-line-number=1><span class=co># Broadcasting support</span></a>
<a class=sourceLine id=cb8-2 data-line-number=2>b &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>add</span>(a, <span class=dv>1</span>)</a>
<a class=sourceLine id=cb8-3 data-line-number=3>b</a></code></pre></div><pre><code>## tf.Tensor(
## [[2. 4.]
##  [3. 5.]], shape=(2, 2), dtype=float64)</code></pre><div class=sourceCode id=cb10><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb10-1 data-line-number=1><span class=co># Operator overloading is supported</span></a>
<a class=sourceLine id=cb10-2 data-line-number=2>a <span class=op>*</span><span class=st> </span>b</a></code></pre></div><pre><code>## tf.Tensor(
## [[ 2. 12.]
##  [ 6. 20.]], shape=(2, 2), dtype=float64)</code></pre><div class=sourceCode id=cb12><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb12-1 data-line-number=1><span class=co># Obtain an R value from a Tensor</span></a>
<a class=sourceLine id=cb12-2 data-line-number=2><span class=kw><a href=https://rdrr.io/r/base/array.html>as.array</a></span>(a)</a></code></pre></div><pre><code>##      [,1] [,2]
## [1,]    1    3
## [2,]    2    4</code></pre></div><div id=dynamic-control-flow class="section level2"><h2>Dynamic control flow</h2><p>A major benefit of eager execution is that all the functionality of the host
language is available while your model is executing. So, for example,
it is easy to write <a href=https://en.wikipedia.org/wiki/Fizz_buzz>fizzbuzz</a>:</p><div class=sourceCode id=cb14><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb14-1 data-line-number=1>fizzbuzz &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/pkg/tfautograph/man/autograph.html>autograph</a></span>(<span class=cf>function</span>(max_num) {</a>
<a class=sourceLine id=cb14-2 data-line-number=2>  counter &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>constant</span>(<span class=dv>0</span>)</a>
<a class=sourceLine id=cb14-3 data-line-number=3>  max_num &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>convert_to_tensor</span>(max_num)</a>
<a class=sourceLine id=cb14-4 data-line-number=4>  <span class=cf>for</span> (num <span class=cf>in</span> (tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/range.html>range</a></span>(max_num) <span class=op>+</span><span class=st> </span><span class=dv>1</span>)) {</a>
<a class=sourceLine id=cb14-5 data-line-number=5>    <span class=cf>if</span> ((num <span class=op>%%</span><span class=st> </span><span class=dv>3</span> <span class=op>==</span><span class=st> </span><span class=dv>0</span>) <span class=op>&amp;</span><span class=st> </span>(num <span class=op>%%</span><span class=st> </span><span class=dv>5</span> <span class=op>==</span><span class=st> </span><span class=dv>0</span>)) {</a>
<a class=sourceLine id=cb14-6 data-line-number=6>      tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/print.html>print</a></span>(<span class=st>"FizzBuzz"</span>)</a>
<a class=sourceLine id=cb14-7 data-line-number=7>    } <span class=cf>else</span> <span class=cf>if</span> (num <span class=op>%%</span><span class=st> </span><span class=dv>3</span> <span class=op>==</span><span class=st> </span><span class=dv>0</span>) {</a>
<a class=sourceLine id=cb14-8 data-line-number=8>      tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/print.html>print</a></span>(<span class=st>"Fizz"</span>)</a>
<a class=sourceLine id=cb14-9 data-line-number=9>    } <span class=cf>else</span> <span class=cf>if</span> (num <span class=op>%%</span><span class=st> </span><span class=dv>5</span> <span class=op>==</span><span class=st> </span><span class=dv>0</span>) {</a>
<a class=sourceLine id=cb14-10 data-line-number=10>      tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/print.html>print</a></span>(<span class=st>"Buzz"</span>)</a>
<a class=sourceLine id=cb14-11 data-line-number=11>    } <span class=cf>else</span> {</a>
<a class=sourceLine id=cb14-12 data-line-number=12>      tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/print.html>print</a></span>(num)</a>
<a class=sourceLine id=cb14-13 data-line-number=13>    }</a>
<a class=sourceLine id=cb14-14 data-line-number=14>    counter &lt;-<span class=st> </span>counter <span class=op>+</span><span class=st> </span><span class=dv>1</span></a>
<a class=sourceLine id=cb14-15 data-line-number=15>  }</a>
<a class=sourceLine id=cb14-16 data-line-number=16>})</a>
<a class=sourceLine id=cb14-17 data-line-number=17><span class=kw>fizzbuzz</span>(<span class=dv>15</span>)</a></code></pre></div><p>This has conditionals that depend on tensor values and it prints these values
at runtime.</p></div><div id=eager-training class="section level2"><h2>Eager training</h2><div id=computing-gradients class="section level3"><h3>Computing gradients</h3><p><a href=https://en.wikipedia.org/wiki/Automatic_differentiation>Automatic differentiation</a>
is useful for implementing machine learning algorithms such as
<a href=https://en.wikipedia.org/wiki/Backpropagation>backpropagation</a> for training
neural networks. During eager execution, use <code>tf$GradientTape</code> to trace
operations for computing gradients later.</p><p>You can use <code>tf$GradientTape</code> to train and/or compute gradients in eager. It is especially useful for complicated training loops.</p><p>Since different operations can occur during each call, all
forward-pass operations get recorded to a “tape”. To compute the gradient, play
the tape backwards and then discard. A particular <code>tf$GradientTape</code> can only
compute one gradient; subsequent calls throw a runtime error.</p><div class=sourceCode id=cb15><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb15-1 data-line-number=1>w &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>Variable</span>(<span class=dv>1</span>)</a>
<a class=sourceLine id=cb15-2 data-line-number=2><span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw>GradientTape</span>() <span class=op>%as%</span><span class=st> </span>tape, {</a>
<a class=sourceLine id=cb15-3 data-line-number=3>  loss &lt;-<span class=st> </span>w <span class=op>*</span><span class=st> </span>w</a>
<a class=sourceLine id=cb15-4 data-line-number=4>})</a>
<a class=sourceLine id=cb15-5 data-line-number=5>grad &lt;-<span class=st> </span>tape<span class=op>$</span><span class=kw>gradient</span>(loss, w)</a>
<a class=sourceLine id=cb15-6 data-line-number=6>grad</a></code></pre></div><pre><code>## tf.Tensor(2.0, shape=(), dtype=float32)</code></pre></div><div id=train-a-model class="section level3"><h3>Train a model</h3><p>The following example creates a multi-layer model that classifies the standard
MNIST handwritten digits. It demonstrates the optimizer and layer APIs to build
trainable graphs in an eager execution environment.</p><div class=sourceCode id=cb17><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb17-1 data-line-number=1><span class=co># Fetch and format the mnist data</span></a>
<a class=sourceLine id=cb17-2 data-line-number=2>mnist &lt;-<span class=st> </span><span class=kw><a href=../../keras/reference/dataset_mnist.html>dataset_mnist</a></span>()</a>
<a class=sourceLine id=cb17-3 data-line-number=3>dataset &lt;-<span class=st> </span><span class=kw><a href=../../tools/tfdatasets/reference/tensor_slices_dataset.html>tensor_slices_dataset</a></span>(mnist<span class=op>$</span>train) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb17-4 data-line-number=4><span class=st>  </span><span class=kw><a href=../../tools/tfdatasets/reference/dataset_map.html>dataset_map</a></span>(<span class=cf>function</span>(x) {</a>
<a class=sourceLine id=cb17-5 data-line-number=5>    x<span class=op>$</span>x &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>cast</span>(x<span class=op>$</span>x, tf<span class=op>$</span>float32)<span class=op>/</span><span class=dv>255</span></a>
<a class=sourceLine id=cb17-6 data-line-number=6>    x<span class=op>$</span>x &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>expand_dims</span>(x<span class=op>$</span>x, <span class=dt>axis =</span> <span class=op>-</span>1L)</a>
<a class=sourceLine id=cb17-7 data-line-number=7>    <span class=kw><a href=https://rdrr.io/r/base/unname.html>unname</a></span>(x)</a>
<a class=sourceLine id=cb17-8 data-line-number=8>  }) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb17-9 data-line-number=9><span class=st>  </span><span class=kw><a href=../../tools/tfdatasets/reference/dataset_shuffle.html>dataset_shuffle</a></span>(<span class=dv>1000</span>) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb17-10 data-line-number=10><span class=st>  </span><span class=kw><a href=../../tools/tfdatasets/reference/dataset_batch.html>dataset_batch</a></span>(<span class=dv>32</span>)</a>
<a class=sourceLine id=cb17-11 data-line-number=11></a>
<a class=sourceLine id=cb17-12 data-line-number=12>dataset</a></code></pre></div><pre><code>## &lt;BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt;</code></pre><div class=sourceCode id=cb19><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb19-1 data-line-number=1>mnist_model &lt;-<span class=st> </span><span class=kw><a href=../../keras/reference/keras_model_sequential.html>keras_model_sequential</a></span>() <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb19-2 data-line-number=2><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_conv_2d.html>layer_conv_2d</a></span>(<span class=dt>filters =</span> <span class=dv>16</span>, <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=dv>3</span>,<span class=dv>3</span>), <span class=dt>activation=</span> <span class=st>"relu"</span>,</a>
<a class=sourceLine id=cb19-3 data-line-number=3>                <span class=dt>input_shape =</span> <span class=kw><a href=../../tensorflow/reference/shape.html>shape</a></span>(<span class=ot>NULL</span>, <span class=ot>NULL</span>, <span class=dv>1</span>)) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb19-4 data-line-number=4><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_conv_2d.html>layer_conv_2d</a></span>(<span class=dt>filters =</span> <span class=dv>16</span>, <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=dv>3</span>,<span class=dv>3</span>), <span class=dt>activation =</span> <span class=st>"relu"</span>) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb19-5 data-line-number=5><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_global_average_pooling_2d.html>layer_global_average_pooling_2d</a></span>() <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb19-6 data-line-number=6><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_dense.html>layer_dense</a></span>(<span class=dt>units =</span> <span class=dv>10</span>)</a></code></pre></div><p>Even without training, call the model and inspect the output in eager execution:</p><div class=sourceCode id=cb20><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb20-1 data-line-number=1>el &lt;-<span class=st> </span>dataset <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb20-2 data-line-number=2><span class=st>  </span><span class=kw><a href=../../tools/tfdatasets/reference/dataset_take.html>dataset_take</a></span>(<span class=dv>1</span>) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb20-3 data-line-number=3><span class=st>  </span><span class=kw><a href=../../tools/tfdatasets/reference/dataset_collect.html>dataset_collect</a></span>()</a>
<a class=sourceLine id=cb20-4 data-line-number=4><span class=kw>mnist_model</span>(el[[<span class=dv>1</span>]])</a></code></pre></div><pre><code>## tf.Tensor(
## [[-8.50985199e-03  9.76161857e-04 -2.50255484e-02 -5.79575971e-02
##   -3.91511843e-02 -2.02112067e-02  1.19331172e-02  2.99258605e-02
##    7.55230756e-03  3.86199094e-02]
##  [-5.54877939e-03  1.90716446e-03 -1.70769673e-02 -3.62131633e-02
##   -2.53974535e-02 -1.38209835e-02  7.40819378e-03  1.79758631e-02
##    5.72366873e-03  2.54252721e-02]
##  [-2.37655244e-03  1.36287510e-03 -1.33525934e-02 -3.33486199e-02
##   -2.12530848e-02 -1.39125455e-02  5.86056244e-03  1.53014306e-02
##    5.15997969e-03  2.24790853e-02]
##  [-8.92254990e-04  2.28004996e-03 -1.07957972e-02 -3.00190244e-02
##   -1.75903179e-02 -1.35528101e-02  4.88691870e-03  1.25359586e-02
##    5.23545966e-03  1.93263516e-02]
##  [-4.21859929e-03  3.05507542e-03 -1.49999214e-02 -3.11945472e-02
##   -2.06255876e-02 -1.27387317e-02  6.34148577e-03  1.41533548e-02
##    5.45461895e-03  2.25168187e-02]
##  [-3.46548553e-03  1.24341354e-03 -1.45013975e-02 -4.30306159e-02
##   -3.16537209e-02 -1.74248051e-02  6.47401158e-03  2.26319134e-02
##    5.64713310e-03  2.93269195e-02]
##  [-6.41194824e-03  1.38130516e-03 -1.84288751e-02 -4.14446481e-02
##   -3.08680199e-02 -1.57348588e-02  7.77957682e-03  2.17617080e-02
##    4.86520818e-03  2.92749219e-02]
##  [-8.39145947e-03 -2.43743139e-04 -2.18558982e-02 -5.35714217e-02
##   -3.83904204e-02 -1.82459299e-02  1.09588886e-02  3.00901663e-02
##    3.97703936e-03  3.47796679e-02]
##  [-6.90627703e-03 -2.02620332e-03 -1.62484460e-02 -4.23779786e-02
##   -3.48815881e-02 -1.46378912e-02  7.04134628e-03  2.60561779e-02
##    2.87065259e-03  3.00167799e-02]
##  [-3.46036465e-03  3.34005570e-03 -1.42491609e-02 -2.86302492e-02
##   -1.86991822e-02 -1.21941017e-02  5.76612214e-03  1.24817807e-02
##    5.39597031e-03  2.08636373e-02]
##  [-6.75824890e-03  1.80363667e-03 -1.81528479e-02 -3.73662151e-02
##   -2.79965084e-02 -1.33580044e-02  7.09015829e-03  1.83111280e-02
##    6.74578175e-03  2.72248089e-02]
##  [-3.44557199e-03  1.44218188e-03 -1.55201033e-02 -3.91926579e-02
##   -3.03197410e-02 -1.78610198e-02  6.71680411e-03  2.06990894e-02
##    5.46659622e-03  2.73653362e-02]
##  [-2.98760762e-03  6.68506909e-05 -1.03480723e-02 -2.65669450e-02
##   -2.34568883e-02 -1.09654916e-02  3.45098414e-03  1.51341530e-02
##    4.49841795e-03  2.06842236e-02]
##  [-6.59199711e-03  1.85408711e-03 -1.94277260e-02 -4.28726152e-02
##   -2.99611464e-02 -1.58806108e-02  9.21235979e-03  2.24604607e-02
##    5.33315912e-03  2.91829202e-02]
##  [-7.55199324e-03 -9.93973459e-04 -2.15730183e-02 -5.56724407e-02
##   -4.60459515e-02 -2.07579192e-02  9.57913976e-03  3.33841294e-02
##    4.62856423e-03  3.92136984e-02]
##  [-2.03214702e-03  4.08457185e-04 -1.21998340e-02 -3.37962173e-02
##   -2.65589673e-02 -1.54427039e-02  4.19362914e-03  1.70531943e-02
##    5.84620563e-03  2.43132822e-02]
##  [-3.81546142e-03  1.21751742e-04 -1.36933727e-02 -3.54161970e-02
##   -2.85060816e-02 -1.41160497e-02  5.15741529e-03  1.88995544e-02
##    5.81339980e-03  2.64615659e-02]
##  [-4.51849913e-03  1.79681068e-04 -1.25195542e-02 -2.85590179e-02
##   -2.36752722e-02 -1.03663774e-02  4.86267731e-03  1.64620187e-02
##    4.00224933e-03  2.16186680e-02]
##  [-6.88880868e-03  2.30632047e-03 -2.50062961e-02 -6.10050745e-02
##   -4.42578457e-02 -2.45542563e-02  1.10575147e-02  3.20139751e-02
##    7.40471063e-03  4.25111316e-02]
##  [-8.04840680e-03 -1.73170422e-03 -2.13432573e-02 -5.59643619e-02
##   -4.14501876e-02 -1.88157260e-02  1.08416816e-02  3.29777822e-02
##    3.58740776e-03  3.77420597e-02]
##  [-2.12463085e-03  1.40806718e-03 -1.62827484e-02 -4.21891250e-02
##   -2.92056706e-02 -1.80202033e-02  6.18648017e-03  1.89643912e-02
##    7.54634384e-03  2.85427365e-02]
##  [-6.24155253e-03  3.68376786e-04 -1.89247429e-02 -4.59269919e-02
##   -3.55105102e-02 -1.77306253e-02  7.98209663e-03  2.48527452e-02
##    5.78143680e-03  3.23706158e-02]
##  [-1.42555241e-03  4.77403111e-04 -1.20030018e-02 -3.56824584e-02
##   -2.53661703e-02 -1.50882667e-02  5.09238290e-03  1.77882873e-02
##    5.66911884e-03  2.43990738e-02]
##  [-1.21319480e-02 -3.38456419e-04 -3.04601416e-02 -6.95648193e-02
##   -5.14865555e-02 -2.32764110e-02  1.34642534e-02  3.88753153e-02
##    5.17100841e-03  4.83683124e-02]
##  [-7.99048692e-03  1.30610866e-03 -2.30237599e-02 -5.47382683e-02
##   -3.83893251e-02 -2.00371165e-02  1.12129143e-02  2.90373228e-02
##    5.98406652e-03  3.79212201e-02]
##  [-6.75235782e-03  9.91679379e-04 -1.80075001e-02 -3.80989239e-02
##   -2.85798106e-02 -1.37160970e-02  7.86706619e-03  2.10245345e-02
##    3.95417260e-03  2.71354374e-02]
##  [-7.98894465e-03  4.55419155e-04 -2.53729578e-02 -6.31851330e-02
##   -4.31225747e-02 -2.33430732e-02  1.32131195e-02  3.43508609e-02
##    5.29513042e-03  4.14416529e-02]
##  [-3.49725038e-03 -2.39763220e-04 -1.08997943e-02 -2.69409642e-02
##   -2.45306063e-02 -1.08287791e-02  3.64527735e-03  1.59635600e-02
##    3.91276646e-03  2.12638490e-02]
##  [-6.46782434e-03 -7.04026374e-04 -1.56770907e-02 -3.86993401e-02
##   -3.16020884e-02 -1.30451052e-02  6.17024768e-03  2.19560675e-02
##    4.18775994e-03  2.79887151e-02]
##  [-5.55107370e-03  2.06118939e-03 -1.58842616e-02 -3.25190350e-02
##   -2.33283471e-02 -1.21178171e-02  6.47215592e-03  1.56531073e-02
##    5.25392406e-03  2.41678189e-02]
##  [-8.96292087e-03 -5.41977119e-04 -2.13856287e-02 -4.84847501e-02
##   -3.47109959e-02 -1.52589623e-02  1.07035376e-02  2.74108090e-02
##    4.38953377e-03  3.33805010e-02]
##  [-5.13768382e-03 -8.29380937e-04 -1.55788297e-02 -4.19435799e-02
##   -3.52306105e-02 -1.68032013e-02  6.36776956e-03  2.41187550e-02
##    5.30361803e-03  3.00990045e-02]], shape=(32, 10), dtype=float32)</code></pre><p>While keras models have a builtin training loop (using the fit method), sometimes you need more customization. Here’s an example, of a training loop implemented with eager:</p><div class=sourceCode id=cb22><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb22-1 data-line-number=1>optimizer &lt;-<span class=st> </span><span class=kw><a href=../../keras/reference/optimizer_adam.html>optimizer_adam</a></span>()</a>
<a class=sourceLine id=cb22-2 data-line-number=2>loss_object &lt;-<span class=st> </span>tf<span class=op>$</span>keras<span class=op>$</span>losses<span class=op>$</span><span class=kw>SparseCategoricalCrossentropy</span>(<span class=dt>from_logits =</span> <span class=ot>TRUE</span>)</a>
<a class=sourceLine id=cb22-3 data-line-number=3></a>
<a class=sourceLine id=cb22-4 data-line-number=4>loss_history &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>()</a></code></pre></div><p>Note: Use the assert functions in <code>tf$debugging</code> to check if a condition holds up. This works in eager and graph execution.</p><div class=sourceCode id=cb23><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb23-1 data-line-number=1>train_step &lt;-<span class=st> </span><span class=cf>function</span>(images, labels) {</a>
<a class=sourceLine id=cb23-2 data-line-number=2>  <span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw>GradientTape</span>() <span class=op>%as%</span><span class=st> </span>tape, {</a>
<a class=sourceLine id=cb23-3 data-line-number=3>    logits &lt;-<span class=st> </span><span class=kw>mnist_model</span>(images, <span class=dt>training =</span> <span class=ot>TRUE</span>)</a>
<a class=sourceLine id=cb23-4 data-line-number=4>    tf<span class=op>$</span>debugging<span class=op>$</span><span class=kw>assert_equal</span>(logits<span class=op>$</span>shape, <span class=kw><a href=../../tensorflow/reference/shape.html>shape</a></span>(<span class=dv>32</span>, <span class=dv>10</span>))</a>
<a class=sourceLine id=cb23-5 data-line-number=5>    loss_value &lt;-<span class=st> </span><span class=kw>loss_object</span>(labels, logits)</a>
<a class=sourceLine id=cb23-6 data-line-number=6>  })</a>
<a class=sourceLine id=cb23-7 data-line-number=7>  loss_history &lt;&lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/append.html>append</a></span>(loss_history, loss_value)</a>
<a class=sourceLine id=cb23-8 data-line-number=8>  grads &lt;-<span class=st> </span>tape<span class=op>$</span><span class=kw>gradient</span>(loss_value, mnist_model<span class=op>$</span>trainable_variables)</a>
<a class=sourceLine id=cb23-9 data-line-number=9>  optimizer<span class=op>$</span><span class=kw>apply_gradients</span>(</a>
<a class=sourceLine id=cb23-10 data-line-number=10>    purrr<span class=op>::</span><span class=kw><a href=https://purrr.tidyverse.org/reference/transpose.html>transpose</a></span>(<span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(grads, mnist_model<span class=op>$</span>trainable_variables))</a>
<a class=sourceLine id=cb23-11 data-line-number=11>  )</a>
<a class=sourceLine id=cb23-12 data-line-number=12>}</a>
<a class=sourceLine id=cb23-13 data-line-number=13></a>
<a class=sourceLine id=cb23-14 data-line-number=14>train &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/pkg/tfautograph/man/autograph.html>autograph</a></span>(<span class=cf>function</span>() {</a>
<a class=sourceLine id=cb23-15 data-line-number=15>  <span class=cf>for</span> (epoch <span class=cf>in</span> <span class=kw><a href=https://rdrr.io/r/base/seq.html>seq_len</a></span>(<span class=dv>3</span>)) {</a>
<a class=sourceLine id=cb23-16 data-line-number=16>    <span class=cf>for</span> (batch <span class=cf>in</span> dataset) {</a>
<a class=sourceLine id=cb23-17 data-line-number=17>      <span class=kw>train_step</span>(batch[[<span class=dv>1</span>]], batch[[<span class=dv>2</span>]])</a>
<a class=sourceLine id=cb23-18 data-line-number=18>    }</a>
<a class=sourceLine id=cb23-19 data-line-number=19>    tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/print.html>print</a></span>(<span class=st>"Epoch"</span>, epoch, <span class=st>"finished."</span>)</a>
<a class=sourceLine id=cb23-20 data-line-number=20>  }</a>
<a class=sourceLine id=cb23-21 data-line-number=21>})</a>
<a class=sourceLine id=cb23-22 data-line-number=22></a>
<a class=sourceLine id=cb23-23 data-line-number=23><span class=kw><a href=../../tensorflow/reference/train.html>train</a></span>()</a></code></pre></div><div class=sourceCode id=cb24><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb24-1 data-line-number=1>history &lt;-<span class=st> </span>loss_history <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb24-2 data-line-number=2><span class=st>  </span>purrr<span class=op>::</span><span class=kw><a href=https://purrr.tidyverse.org/reference/map.html>map</a></span>(as.numeric) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb24-3 data-line-number=3><span class=st>  </span>purrr<span class=op>::</span><span class=kw><a href=https://purrr.tidyverse.org/reference/flatten.html>flatten_dbl</a></span>()</a>
<a class=sourceLine id=cb24-4 data-line-number=4>ggplot2<span class=op>::</span><span class=kw><a href=https://ggplot2.tidyverse.org/reference/qplot.html>qplot</a></span>(<span class=dt>x =</span> <span class=kw><a href=https://rdrr.io/r/base/seq.html>seq_along</a></span>(history), <span class=dt>y =</span> history, <span class=dt>geom =</span> <span class=st>"line"</span>)</a></code></pre></div><p><img src=/guide/tensorflow/eager_execution_files/figure-html/unnamed-chunk-15-1.png width=672></p></div><div id=variables-and-optimizers class="section level3"><h3>Variables and optimizers</h3><p><code>tf$Variable</code> objects store mutable <code>tf$Tensor</code>-like values accessed during
training to make automatic differentiation easier.</p><p>The collections of variables can be encapsulated into layers or models, along with methods that operate on them. See <a href=../../keras/custom_layers/>Custom Keras layers and models</a> for details. The main difference between layers and models is that models add methods like <code>fit</code>, <code>evaluate</code>, and <code>save</code>.</p><p>For example, the automatic differentiation example above
can be rewritten:</p><div class=sourceCode id=cb25><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb25-1 data-line-number=1>Linear &lt;-<span class=st> </span><span class=cf>function</span>() {</a>
<a class=sourceLine id=cb25-2 data-line-number=2>  <span class=kw><a href=../../keras/reference/keras_model_custom.html>keras_model_custom</a></span>(<span class=dt>model_fn =</span> <span class=cf>function</span>(self) {</a>
<a class=sourceLine id=cb25-3 data-line-number=3>    self<span class=op>$</span>w &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>Variable</span>(<span class=dv>5</span>, <span class=dt>name =</span> <span class=st>"weight"</span>)</a>
<a class=sourceLine id=cb25-4 data-line-number=4>    self<span class=op>$</span>b &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>Variable</span>(<span class=dv>10</span>, <span class=dt>name =</span> <span class=st>"bias"</span>)</a>
<a class=sourceLine id=cb25-5 data-line-number=5>    <span class=cf>function</span>(inputs, <span class=dt>mask =</span> <span class=ot>NULL</span>, <span class=dt>training =</span> <span class=ot>TRUE</span>) {</a>
<a class=sourceLine id=cb25-6 data-line-number=6>      inputs<span class=op>*</span>self<span class=op>$</span>w <span class=op>+</span><span class=st> </span>self<span class=op>$</span>b</a>
<a class=sourceLine id=cb25-7 data-line-number=7>    }</a>
<a class=sourceLine id=cb25-8 data-line-number=8>  }) </a>
<a class=sourceLine id=cb25-9 data-line-number=9>}</a></code></pre></div><div class=sourceCode id=cb26><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb26-1 data-line-number=1><span class=co># A toy dataset of points around 3 * x + 2</span></a>
<a class=sourceLine id=cb26-2 data-line-number=2>NUM_EXAMPLES &lt;-<span class=st> </span><span class=dv>2000</span></a>
<a class=sourceLine id=cb26-3 data-line-number=3>training_inputs &lt;-<span class=st> </span>tf<span class=op>$</span>random<span class=op>$</span><span class=kw>normal</span>(<span class=dt>shape =</span> <span class=kw><a href=../../tensorflow/reference/shape.html>shape</a></span>(NUM_EXAMPLES))</a>
<a class=sourceLine id=cb26-4 data-line-number=4>noise &lt;-<span class=st> </span>tf<span class=op>$</span>random<span class=op>$</span><span class=kw>normal</span>(<span class=dt>shape =</span> <span class=kw><a href=../../tensorflow/reference/shape.html>shape</a></span>(NUM_EXAMPLES))</a>
<a class=sourceLine id=cb26-5 data-line-number=5>training_outputs &lt;-<span class=st> </span>training_inputs <span class=op>*</span><span class=st> </span><span class=dv>3</span> <span class=op>+</span><span class=st> </span><span class=dv>2</span> <span class=op>+</span><span class=st> </span>noise</a>
<a class=sourceLine id=cb26-6 data-line-number=6></a>
<a class=sourceLine id=cb26-7 data-line-number=7><span class=co># The loss function to be optimized</span></a>
<a class=sourceLine id=cb26-8 data-line-number=8>loss &lt;-<span class=st> </span><span class=cf>function</span>(model, inputs, targets) {</a>
<a class=sourceLine id=cb26-9 data-line-number=9>  error &lt;-<span class=st> </span><span class=kw>model</span>(inputs) <span class=op>-</span><span class=st> </span>targets</a>
<a class=sourceLine id=cb26-10 data-line-number=10>  tf<span class=op>$</span><span class=kw>reduce_mean</span>(tf<span class=op>$</span><span class=kw>square</span>(error))</a>
<a class=sourceLine id=cb26-11 data-line-number=11>}</a>
<a class=sourceLine id=cb26-12 data-line-number=12></a>
<a class=sourceLine id=cb26-13 data-line-number=13>grad &lt;-<span class=st> </span><span class=cf>function</span>(model, inputs, targets) {</a>
<a class=sourceLine id=cb26-14 data-line-number=14>  <span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw>GradientTape</span>() <span class=op>%as%</span><span class=st> </span>tape, {</a>
<a class=sourceLine id=cb26-15 data-line-number=15>    loss_value &lt;-<span class=st> </span><span class=kw>loss</span>(model, inputs, targets)</a>
<a class=sourceLine id=cb26-16 data-line-number=16>  })</a>
<a class=sourceLine id=cb26-17 data-line-number=17>  tape<span class=op>$</span><span class=kw>gradient</span>(loss_value, <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(model<span class=op>$</span>w, model<span class=op>$</span>b))</a>
<a class=sourceLine id=cb26-18 data-line-number=18>}</a></code></pre></div><p>Next:</p><ol style=list-style-type:decimal><li>Create the model.</li><li>The Derivatives of a loss function with respect to model parameters.</li><li>A strategy for updating the variables based on the derivatives.</li></ol><div class=sourceCode id=cb27><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb27-1 data-line-number=1>model &lt;-<span class=st> </span><span class=kw>Linear</span>()</a>
<a class=sourceLine id=cb27-2 data-line-number=2>optimizer &lt;-<span class=st> </span><span class=kw><a href=../../keras/reference/optimizer_sgd.html>optimizer_sgd</a></span>(<span class=dt>lr =</span> <span class=fl>0.01</span>)</a>
<a class=sourceLine id=cb27-3 data-line-number=3></a>
<a class=sourceLine id=cb27-4 data-line-number=4><span class=kw><a href=https://rdrr.io/r/base/cat.html>cat</a></span>(<span class=st>"Initial loss: "</span>, <span class=kw><a href=https://rdrr.io/r/base/numeric.html>as.numeric</a></span>(<span class=kw>loss</span>(model, training_inputs, training_outputs), <span class=st>"</span><span class=ch>\n</span><span class=st>"</span>))</a></code></pre></div><pre><code>## Initial loss:  68.66985</code></pre><div class=sourceCode id=cb29><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb29-1 data-line-number=1><span class=cf>for</span> (i <span class=cf>in</span> <span class=kw><a href=https://rdrr.io/r/base/seq.html>seq_len</a></span>(<span class=dv>300</span>)) {</a>
<a class=sourceLine id=cb29-2 data-line-number=2>  grads &lt;-<span class=st> </span><span class=kw>grad</span>(model, training_inputs, training_outputs)</a>
<a class=sourceLine id=cb29-3 data-line-number=3>  optimizer<span class=op>$</span><span class=kw>apply_gradients</span>(purrr<span class=op>::</span><span class=kw><a href=https://purrr.tidyverse.org/reference/transpose.html>transpose</a></span>(</a>
<a class=sourceLine id=cb29-4 data-line-number=4>    <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(grads, <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(model<span class=op>$</span>w, model<span class=op>$</span>b))</a>
<a class=sourceLine id=cb29-5 data-line-number=5>  ))</a>
<a class=sourceLine id=cb29-6 data-line-number=6>  <span class=cf>if</span> (i <span class=op>%%</span><span class=st> </span><span class=dv>20</span> <span class=op>==</span><span class=st> </span><span class=dv>0</span>)</a>
<a class=sourceLine id=cb29-7 data-line-number=7>    <span class=kw><a href=https://rdrr.io/r/base/cat.html>cat</a></span>(<span class=st>"Loss at step "</span>, i, <span class=st>": "</span>, <span class=kw><a href=https://rdrr.io/r/base/numeric.html>as.numeric</a></span>(<span class=kw>loss</span>(model, training_inputs, training_outputs)), <span class=st>"</span><span class=ch>\n</span><span class=st>"</span>)</a>
<a class=sourceLine id=cb29-8 data-line-number=8>}</a></code></pre></div><pre><code>## Loss at step  20 :  31.23723 
## Loss at step  40 :  14.52059 
## Loss at step  60 :  7.055109 
## Loss at step  80 :  3.721035 
## Loss at step  100 :  2.23201 
## Loss at step  120 :  1.566984 
## Loss at step  140 :  1.269965 
## Loss at step  160 :  1.137304 
## Loss at step  180 :  1.078052 
## Loss at step  200 :  1.051587 
## Loss at step  220 :  1.039765 
## Loss at step  240 :  1.034485 
## Loss at step  260 :  1.032126 
## Loss at step  280 :  1.031073 
## Loss at step  300 :  1.030602</code></pre><div class=sourceCode id=cb31><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb31-1 data-line-number=1>model<span class=op>$</span>w</a></code></pre></div><pre><code>## &lt;tf.Variable 'weight:0' shape=() dtype=float32, numpy=3.0587368&gt;</code></pre><div class=sourceCode id=cb33><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb33-1 data-line-number=1>model<span class=op>$</span>b</a></code></pre></div><pre><code>## &lt;tf.Variable 'bias:0' shape=() dtype=float32, numpy=2.0177262&gt;</code></pre><p>Note: Variables persist until the last reference to the object
is removed, and is the variable is deleted.</p></div><div id=object-based-saving class="section level3"><h3>Object-based saving</h3><p>A Keras model includes a convinient <code>save_weights</code> method allowing you to easily create a checkpoint:</p><div class=sourceCode id=cb35><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb35-1 data-line-number=1><span class=kw><a href=../../keras/reference/save_model_weights_tf.html>save_model_weights_tf</a></span>(model, <span class=st>"weights"</span>)</a>
<a class=sourceLine id=cb35-2 data-line-number=2><span class=kw><a href=../../keras/reference/save_model_weights_tf.html>load_model_weights_tf</a></span>(model, <span class=dt>filepath =</span> <span class=st>"weights"</span>)</a></code></pre></div><p>Using <code>tf$train$Checkpoint</code> you can take full control over this process.</p><p>This section is an abbreviated version of the <a href=./checkpoint/>guide to training checkpoints</a>.</p><div class=sourceCode id=cb36><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb36-1 data-line-number=1>x &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>Variable</span>(<span class=dv>10</span>)</a>
<a class=sourceLine id=cb36-2 data-line-number=2>checkpoint &lt;-<span class=st> </span>tf<span class=op>$</span>train<span class=op>$</span><span class=kw>Checkpoint</span>(<span class=dt>x =</span> x)</a></code></pre></div><div class=sourceCode id=cb37><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb37-1 data-line-number=1>x<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/assign.html>assign</a></span>(<span class=dv>2</span>) <span class=co># Assign a new value to the variables and save.</span></a></code></pre></div><pre><code>## &lt;tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=2.0&gt;</code></pre><div class=sourceCode id=cb39><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb39-1 data-line-number=1>checkpoint_path &lt;-<span class=st> "ckpt/"</span></a>
<a class=sourceLine id=cb39-2 data-line-number=2>checkpoint<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/save.html>save</a></span>(checkpoint_path)</a></code></pre></div><pre><code>## [1] "ckpt/-1"</code></pre><div class=sourceCode id=cb41><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb41-1 data-line-number=1>x<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/assign.html>assign</a></span>(<span class=dv>11</span>) <span class=co># Change the variable after saving.</span></a></code></pre></div><pre><code>## &lt;tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=11.0&gt;</code></pre><div class=sourceCode id=cb43><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb43-1 data-line-number=1>checkpoint<span class=op>$</span><span class=kw>restore</span>(tf<span class=op>$</span>train<span class=op>$</span><span class=kw>latest_checkpoint</span>(checkpoint_path))</a></code></pre></div><pre><code>## &lt;tensorflow.python.training.tracking.util.CheckpointLoadStatus&gt;</code></pre><div class=sourceCode id=cb45><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb45-1 data-line-number=1>x</a></code></pre></div><pre><code>## &lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0&gt;</code></pre><p>To save and load models, <code>tf$train$Checkpoint</code> stores the internal state of objects,
without requiring hidden variables. To record the state of a <code>model</code>,
an <code>optimizer</code>, and a global step, pass them to a <code>tf$train$Checkpoint</code>:</p><div class=sourceCode id=cb47><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb47-1 data-line-number=1>model &lt;-<span class=st> </span><span class=kw><a href=../../keras/reference/keras_model_sequential.html>keras_model_sequential</a></span>() <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb47-2 data-line-number=2><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_conv_2d.html>layer_conv_2d</a></span>(<span class=dt>filters =</span> <span class=dv>16</span>, <span class=dt>kernel_size =</span> <span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=dv>3</span>,<span class=dv>3</span>), <span class=dt>activation =</span> <span class=st>"relu"</span>) <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb47-3 data-line-number=3><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_global_average_pooling_2d.html>layer_global_average_pooling_2d</a></span>() <span class=op>%&gt;%</span><span class=st> </span></a>
<a class=sourceLine id=cb47-4 data-line-number=4><span class=st>  </span><span class=kw><a href=../../keras/reference/layer_dense.html>layer_dense</a></span>(<span class=dt>units =</span> <span class=dv>10</span>)</a>
<a class=sourceLine id=cb47-5 data-line-number=5></a>
<a class=sourceLine id=cb47-6 data-line-number=6>optimizer &lt;-<span class=st> </span><span class=kw><a href=../../keras/reference/optimizer_adam.html>optimizer_adam</a></span>(<span class=dt>lr =</span> <span class=fl>0.001</span>)</a>
<a class=sourceLine id=cb47-7 data-line-number=7></a>
<a class=sourceLine id=cb47-8 data-line-number=8>checkpoint_dir &lt;-<span class=st> 'path/to/model_dir'</span></a>
<a class=sourceLine id=cb47-9 data-line-number=9><span class=cf>if</span> (<span class=op>!</span><span class=kw><a href=https://rdrr.io/r/base/files2.html>dir.exists</a></span>(checkpoint_dir))</a>
<a class=sourceLine id=cb47-10 data-line-number=10>  <span class=kw><a href=https://rdrr.io/r/base/files2.html>dir.create</a></span>(checkpoint_dir, <span class=dt>recursive =</span> <span class=ot>TRUE</span>)</a>
<a class=sourceLine id=cb47-11 data-line-number=11></a>
<a class=sourceLine id=cb47-12 data-line-number=12>checkpoint_prefix &lt;-<span class=st> </span><span class=kw><a href=https://rdrr.io/r/base/file.path.html>file.path</a></span>(checkpoint_dir, <span class=st>"ckpt"</span>)</a>
<a class=sourceLine id=cb47-13 data-line-number=13></a>
<a class=sourceLine id=cb47-14 data-line-number=14>root &lt;-<span class=st> </span>tf<span class=op>$</span>train<span class=op>$</span><span class=kw>Checkpoint</span>(<span class=dt>optimizer =</span> optimizer, <span class=dt>model =</span> model)</a>
<a class=sourceLine id=cb47-15 data-line-number=15></a>
<a class=sourceLine id=cb47-16 data-line-number=16>root<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/save.html>save</a></span>(checkpoint_prefix)</a></code></pre></div><pre><code>## [1] "path/to/model_dir/ckpt-1"</code></pre><div class=sourceCode id=cb49><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb49-1 data-line-number=1>root<span class=op>$</span><span class=kw>restore</span>(tf<span class=op>$</span>train<span class=op>$</span><span class=kw>latest_checkpoint</span>(checkpoint_dir))</a></code></pre></div><pre><code>## &lt;tensorflow.python.training.tracking.util.CheckpointLoadStatus&gt;</code></pre><p>Note: In many training loops, variables are created after tf<span class="math inline">\(train\)</span>Checkpoint.restore is called. These variables will be restored as soon as they are created, and assertions are available to ensure that a checkpoint has been fully loaded. See the guide to training checkpoints for details.</p></div><div id=object-oriented-metrics class="section level3"><h3>Object-oriented metrics</h3><p><code>tf$keras$metrics</code> are stored as objects. Update a metric by passing the new data to
the callable, and retrieve the result using the <code>tf$keras$metrics$result</code> method,
for example:</p><div class=sourceCode id=cb51><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb51-1 data-line-number=1>m &lt;-<span class=st> </span>tf<span class=op>$</span>keras<span class=op>$</span>metrics<span class=op>$</span><span class=kw>Mean</span>(<span class=st>"loss"</span>)</a>
<a class=sourceLine id=cb51-2 data-line-number=2><span class=kw>m</span>(<span class=dv>0</span>)</a></code></pre></div><pre><code>## tf.Tensor(0.0, shape=(), dtype=float32)</code></pre><div class=sourceCode id=cb53><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb53-1 data-line-number=1><span class=kw>m</span>(<span class=dv>5</span>)</a></code></pre></div><pre><code>## tf.Tensor(2.5, shape=(), dtype=float32)</code></pre><div class=sourceCode id=cb55><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb55-1 data-line-number=1>m<span class=op>$</span><span class=kw>result</span>()</a></code></pre></div><pre><code>## tf.Tensor(2.5, shape=(), dtype=float32)</code></pre><div class=sourceCode id=cb57><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb57-1 data-line-number=1><span class=kw>m</span>(<span class=kw><a href=https://rdrr.io/r/base/c.html>c</a></span>(<span class=dv>8</span>, <span class=dv>9</span>))</a></code></pre></div><pre><code>## tf.Tensor(5.5, shape=(), dtype=float32)</code></pre><div class=sourceCode id=cb59><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb59-1 data-line-number=1>m<span class=op>$</span><span class=kw>result</span>()</a></code></pre></div><pre><code>## tf.Tensor(5.5, shape=(), dtype=float32)</code></pre></div><div id=summaries-and-tensorboard class="section level3"><h3>Summaries and TensorBoard</h3><p><a href=https://tensorflow.org/tensorboard>TensorBoard</a> is a visualization tool for
understanding, debugging and optimizing the model training process. It uses
summary events that are written while executing the program.</p><p>You can use <code>tf$summary</code> to record summaries of variable in eager execution.
For example, to record summaries of <code>loss</code> once every 100 training steps:</p><div class=sourceCode id=cb61><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb61-1 data-line-number=1>logdir &lt;-<span class=st> "./tb/"</span></a>
<a class=sourceLine id=cb61-2 data-line-number=2>writer =<span class=st> </span>tf<span class=op>$</span>summary<span class=op>$</span><span class=kw>create_file_writer</span>(logdir)</a>
<a class=sourceLine id=cb61-3 data-line-number=3><span class=kw><a href=../../tensorflow/reference/tensorboard.html>tensorboard</a></span>(<span class=dt>log_dir =</span> logdir) <span class=co># This will open a browser window pointing to Tensorboard</span></a>
<a class=sourceLine id=cb61-4 data-line-number=4></a>
<a class=sourceLine id=cb61-5 data-line-number=5><span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(writer<span class=op>$</span><span class=kw>as_default</span>(), {</a>
<a class=sourceLine id=cb61-6 data-line-number=6>  <span class=cf>for</span> (step <span class=cf>in</span> <span class=kw><a href=https://rdrr.io/r/base/seq.html>seq_len</a></span>(<span class=dv>1000</span>)) {</a>
<a class=sourceLine id=cb61-7 data-line-number=7>    <span class=co># Calculate loss with your real train function.</span></a>
<a class=sourceLine id=cb61-8 data-line-number=8>    loss =<span class=st> </span><span class=dv>1</span> <span class=op>-</span><span class=st> </span><span class=fl>0.001</span> <span class=op>*</span><span class=st> </span>step</a>
<a class=sourceLine id=cb61-9 data-line-number=9>    <span class=cf>if</span> (step <span class=op>%%</span><span class=st> </span><span class=dv>100</span> <span class=op>==</span><span class=st> </span><span class=dv>0</span>)</a>
<a class=sourceLine id=cb61-10 data-line-number=10>      tf<span class=op>$</span>summary<span class=op>$</span><span class=kw>scalar</span>(<span class=st>'loss'</span>, loss, <span class=dt>step=</span>step)</a>
<a class=sourceLine id=cb61-11 data-line-number=11>  }</a>
<a class=sourceLine id=cb61-12 data-line-number=12>})</a></code></pre></div></div></div><div id=advanced-automatic-differentiation-topics class="section level2"><h2>Advanced automatic differentiation topics</h2><div id=dynamic-models class="section level3"><h3>Dynamic models</h3><p><code>tf$GradientTape</code> can also be used in dynamic models. This example for a
<a href=https://wikipedia.org/wiki/Backtracking_line_search>backtracking line search</a>
algorithm looks like normal R code, except there are gradients and is
differentiable, despite the complex control flow:</p><div class=sourceCode id=cb62><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb62-1 data-line-number=1>line_search_step &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>custom_gradient</span>(<span class=kw><a href=https://rdrr.io/pkg/tfautograph/man/autograph.html>autograph</a></span>(<span class=cf>function</span>(fn, init_x, <span class=dt>rate =</span> <span class=dv>1</span>) {</a>
<a class=sourceLine id=cb62-2 data-line-number=2>  <span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw>GradientTape</span>() <span class=op>%as%</span><span class=st> </span>tape, {</a>
<a class=sourceLine id=cb62-3 data-line-number=3>    tape<span class=op>$</span><span class=kw>watch</span>(init_x)</a>
<a class=sourceLine id=cb62-4 data-line-number=4>    value &lt;-<span class=st> </span><span class=kw>fn</span>(init_x)</a>
<a class=sourceLine id=cb62-5 data-line-number=5>  })</a>
<a class=sourceLine id=cb62-6 data-line-number=6>  grad &lt;-<span class=st> </span>tape<span class=op>$</span><span class=kw>gradient</span>(value, init_x)</a>
<a class=sourceLine id=cb62-7 data-line-number=7>  grad_norm &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>reduce_sum</span>(grad <span class=op>*</span><span class=st> </span>grad)</a>
<a class=sourceLine id=cb62-8 data-line-number=8>  init_value &lt;-<span class=st> </span>value</a>
<a class=sourceLine id=cb62-9 data-line-number=9>  <span class=cf>while</span>(value <span class=op>&gt;</span><span class=st> </span>(init_value <span class=op>-</span><span class=st> </span>rate <span class=op>*</span><span class=st> </span>grad_norm)) {</a>
<a class=sourceLine id=cb62-10 data-line-number=10>    x &lt;-<span class=st> </span>init_x <span class=op>-</span><span class=st> </span>rate <span class=op>*</span><span class=st> </span>grad</a>
<a class=sourceLine id=cb62-11 data-line-number=11>    value &lt;-<span class=st> </span><span class=kw>fn</span>(x)</a>
<a class=sourceLine id=cb62-12 data-line-number=12>    rate =<span class=st> </span>rate<span class=op>/</span><span class=dv>2</span></a>
<a class=sourceLine id=cb62-13 data-line-number=13>  }</a>
<a class=sourceLine id=cb62-14 data-line-number=14>  <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(x, value)</a>
<a class=sourceLine id=cb62-15 data-line-number=15>}))</a></code></pre></div></div><div id=custom-gradients class="section level3"><h3>Custom gradients</h3><p>Custom gradients are an easy way to override gradients. Within the forward function, define the gradient with respect to the
inputs, outputs, or intermediate results. For example, here’s an easy way to clip
the norm of the gradients in the backward pass:</p><div class=sourceCode id=cb63><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb63-1 data-line-number=1>clip_gradient_by_norm &lt;-<span class=st> </span><span class=cf>function</span>(x, norm) {</a>
<a class=sourceLine id=cb63-2 data-line-number=2>  y &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/identity.html>identity</a></span>(x)</a>
<a class=sourceLine id=cb63-3 data-line-number=3>  grad_fn &lt;-<span class=st> </span><span class=cf>function</span>(dresult) {</a>
<a class=sourceLine id=cb63-4 data-line-number=4>    <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(tf<span class=op>$</span><span class=kw>clip_by_norm</span>(dresult, norm), <span class=ot>NULL</span>)</a>
<a class=sourceLine id=cb63-5 data-line-number=5>  }</a>
<a class=sourceLine id=cb63-6 data-line-number=6>  <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(y, grad_fn)</a>
<a class=sourceLine id=cb63-7 data-line-number=7>}</a></code></pre></div><p>Custom gradients are commonly used to provide a numerically stable gradient for a
sequence of operations:</p><div class=sourceCode id=cb64><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb64-1 data-line-number=1>log1pexp &lt;-<span class=st> </span><span class=cf>function</span>(x) {</a>
<a class=sourceLine id=cb64-2 data-line-number=2>  tf<span class=op>$</span>math<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/Log.html>log</a></span>(<span class=dv>1</span> <span class=op>+</span><span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/Log.html>exp</a></span>(x))</a>
<a class=sourceLine id=cb64-3 data-line-number=3>}</a>
<a class=sourceLine id=cb64-4 data-line-number=4></a>
<a class=sourceLine id=cb64-5 data-line-number=5>grad_log1pexp &lt;-<span class=st> </span><span class=cf>function</span>(x) {</a>
<a class=sourceLine id=cb64-6 data-line-number=6>  <span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw>GradientTape</span>() <span class=op>%as%</span><span class=st> </span>tape, {</a>
<a class=sourceLine id=cb64-7 data-line-number=7>    tape<span class=op>$</span><span class=kw>watch</span>(x)</a>
<a class=sourceLine id=cb64-8 data-line-number=8>    value &lt;-<span class=st> </span><span class=kw>log1pexp</span>(x)</a>
<a class=sourceLine id=cb64-9 data-line-number=9>  })</a>
<a class=sourceLine id=cb64-10 data-line-number=10>  tape<span class=op>$</span><span class=kw>gradient</span>(value, x)</a>
<a class=sourceLine id=cb64-11 data-line-number=11>}</a></code></pre></div><div class=sourceCode id=cb65><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb65-1 data-line-number=1><span class=co># The gradient computation works fine at x = 0.</span></a>
<a class=sourceLine id=cb65-2 data-line-number=2><span class=kw>grad_log1pexp</span>(tf<span class=op>$</span><span class=kw>constant</span>(<span class=dv>0</span>))</a></code></pre></div><pre><code>## tf.Tensor(0.5, shape=(), dtype=float32)</code></pre><div class=sourceCode id=cb67><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb67-1 data-line-number=1><span class=co># However, x = 100 fails because of numerical instability.</span></a>
<a class=sourceLine id=cb67-2 data-line-number=2><span class=kw>grad_log1pexp</span>(tf<span class=op>$</span><span class=kw>constant</span>(<span class=dv>100</span>))</a></code></pre></div><pre><code>## tf.Tensor(nan, shape=(), dtype=float32)</code></pre><p>Here, the <code>log1pexp</code> function can be analytically simplified with a custom
gradient. The implementation below reuses the value for <code>tf$exp(x)</code> that is
computed during the forward pass—making it more efficient by eliminating
redundant calculations:</p><div class=sourceCode id=cb69><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb69-1 data-line-number=1>log1pexp &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw>custom_gradient</span>(<span class=dt>f =</span> <span class=cf>function</span>(x) {</a>
<a class=sourceLine id=cb69-2 data-line-number=2>  e &lt;-<span class=st> </span>tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/Log.html>exp</a></span>(x)</a>
<a class=sourceLine id=cb69-3 data-line-number=3>  grad_fn &lt;-<span class=st> </span><span class=cf>function</span>(dy) {</a>
<a class=sourceLine id=cb69-4 data-line-number=4>    dy <span class=op>*</span><span class=st> </span>(<span class=dv>1</span> <span class=op>-</span><span class=st> </span><span class=dv>1</span><span class=op>/</span>(e <span class=op>+</span><span class=st> </span>e))</a>
<a class=sourceLine id=cb69-5 data-line-number=5>  }</a>
<a class=sourceLine id=cb69-6 data-line-number=6>  <span class=kw><a href=https://rdrr.io/r/base/list.html>list</a></span>(tf<span class=op>$</span>math<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/base/Log.html>log</a></span>(<span class=dv>1</span> <span class=op>+</span><span class=st> </span>e), grad_fn)</a>
<a class=sourceLine id=cb69-7 data-line-number=7>})</a>
<a class=sourceLine id=cb69-8 data-line-number=8></a>
<a class=sourceLine id=cb69-9 data-line-number=9>grad_log1pexp &lt;-<span class=st> </span><span class=cf>function</span>(x) {</a>
<a class=sourceLine id=cb69-10 data-line-number=10>  <span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw>GradientTape</span>() <span class=op>%as%</span><span class=st> </span>tape, {</a>
<a class=sourceLine id=cb69-11 data-line-number=11>    tape<span class=op>$</span><span class=kw>watch</span>(x)</a>
<a class=sourceLine id=cb69-12 data-line-number=12>    value &lt;-<span class=st> </span><span class=kw>log1pexp</span>(x)</a>
<a class=sourceLine id=cb69-13 data-line-number=13>  })</a>
<a class=sourceLine id=cb69-14 data-line-number=14>  tape<span class=op>$</span><span class=kw>gradient</span>(value, x)</a>
<a class=sourceLine id=cb69-15 data-line-number=15>}</a></code></pre></div><div class=sourceCode id=cb70><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb70-1 data-line-number=1><span class=co># As before, the gradient computation works fine at x = 0.</span></a>
<a class=sourceLine id=cb70-2 data-line-number=2><span class=kw>grad_log1pexp</span>(tf<span class=op>$</span><span class=kw>constant</span>(<span class=dv>0</span>))</a></code></pre></div><pre><code>## tf.Tensor(0.5, shape=(), dtype=float32)</code></pre><div class=sourceCode id=cb72><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb72-1 data-line-number=1><span class=co># And the gradient computation also works at x = 100.</span></a>
<a class=sourceLine id=cb72-2 data-line-number=2><span class=kw>grad_log1pexp</span>(tf<span class=op>$</span><span class=kw>constant</span>(<span class=dv>100</span>))</a></code></pre></div><pre><code>## tf.Tensor(1.0, shape=(), dtype=float32)</code></pre></div></div><div id=performance class="section level2"><h2>Performance</h2><p>Computation is automatically offloaded to GPUs during eager execution. If you
want control over where a computation runs you can enclose it in a
<code>tf$device('/gpu:0')</code> block (or the CPU equivalent):</p><div class=sourceCode id=cb74><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb74-1 data-line-number=1>fun &lt;-<span class=st> </span><span class=cf>function</span>(device, <span class=dt>steps =</span> <span class=dv>200</span>) {</a>
<a class=sourceLine id=cb74-2 data-line-number=2>  <span class=kw><a href=https://rdrr.io/r/base/with.html>with</a></span>(tf<span class=op>$</span><span class=kw><a href=https://rdrr.io/r/grDevices/Devices.html>device</a></span>(device), {</a>
<a class=sourceLine id=cb74-3 data-line-number=3>    x &lt;-<span class=st> </span>tf<span class=op>$</span>random<span class=op>$</span><span class=kw>normal</span>(<span class=dt>shape =</span> shape)</a>
<a class=sourceLine id=cb74-4 data-line-number=4>    <span class=cf>for</span> (i <span class=cf>in</span> <span class=kw><a href=https://rdrr.io/r/base/seq.html>seq_len</a></span>(steps)) {</a>
<a class=sourceLine id=cb74-5 data-line-number=5>      tf<span class=op>$</span><span class=kw>matmul</span>(x, x)  </a>
<a class=sourceLine id=cb74-6 data-line-number=6>    }  </a>
<a class=sourceLine id=cb74-7 data-line-number=7>  })</a>
<a class=sourceLine id=cb74-8 data-line-number=8>}</a>
<a class=sourceLine id=cb74-9 data-line-number=9>microbenchmark<span class=op>::</span><span class=kw><a href=https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html>microbenchmark</a></span>(</a>
<a class=sourceLine id=cb74-10 data-line-number=10>  <span class=kw>fun</span>(<span class=st>"/cpu:0"</span>),</a>
<a class=sourceLine id=cb74-11 data-line-number=11>  <span class=kw>fun</span>(<span class=st>"/gpu:0"</span>)</a>
<a class=sourceLine id=cb74-12 data-line-number=12>)</a></code></pre></div><div class=sourceCode id=cb75><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb75-1 data-line-number=1><span class=co># Unit: milliseconds</span></a>
<a class=sourceLine id=cb75-2 data-line-number=2><span class=co>#           expr      min        lq      mean    median        uq       max neval</span></a>
<a class=sourceLine id=cb75-3 data-line-number=3><span class=co>#  fun("/cpu:0") 1117.596 1135.5450 1165.6269 1157.2208 1195.1529 1300.2236   100</span></a>
<a class=sourceLine id=cb75-4 data-line-number=4><span class=co>#  fun("/gpu:0")  112.888  121.7164  127.8525  126.6708  132.0415  228.1009   100</span></a></code></pre></div><p>A <code>tf$Tensor</code> object can be copied to a different device to execute its
operations:</p><div class=sourceCode id=cb76><pre class="sourceCode r"><code class="sourceCode r"><a class=sourceLine id=cb76-1 data-line-number=1>x &lt;-<span class=st> </span>tf<span class=op>$</span>random<span class=op>$</span><span class=kw>normal</span>(<span class=dt>shape =</span> <span class=kw><a href=../../tensorflow/reference/shape.html>shape</a></span>(<span class=dv>10</span>,<span class=dv>10</span>))</a>
<a class=sourceLine id=cb76-2 data-line-number=2></a>
<a class=sourceLine id=cb76-3 data-line-number=3>x_gpu0 &lt;-<span class=st> </span>x<span class=op>$</span><span class=kw>gpu</span>()</a>
<a class=sourceLine id=cb76-4 data-line-number=4>x_cpu &lt;-<span class=st> </span>x<span class=op>$</span><span class=kw>cpu</span>()</a>
<a class=sourceLine id=cb76-5 data-line-number=5></a>
<a class=sourceLine id=cb76-6 data-line-number=6>tf<span class=op>$</span><span class=kw>matmul</span>(x_cpu, x_cpu)    <span class=co># Runs on CPU</span></a>
<a class=sourceLine id=cb76-7 data-line-number=7>tf<span class=op>$</span><span class=kw>matmul</span>(x_gpu0, x_gpu0)  <span class=co># Runs on GPU:0</span></a></code></pre></div><div id=benchmarks class="section level3"><h3>Benchmarks</h3><p>For compute-heavy models, such as
<a href=https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50>ResNet50</a>
training on a GPU, eager execution performance is comparable to <code>tf_function</code> execution.
But this gap grows larger for models with less computation and there is work to
be done for optimizing hot code paths for models with lots of small operations.</p></div></div><div id=work-with-functions class="section level2"><h2>Work with functions</h2><p>While eager execution makes development and debugging more interactive,
TensorFlow 1.x style graph execution has advantages for distributed training, performance
optimizations, and production deployment. To bridge this gap, TensorFlow 2.0 introduces <code>function</code>s via the <code>tf_function</code> API. For more information, see the <a href=./function>tf_function</a> guide.</p></div></div></div></div><footer>Copyright © 2015-2019 The TensorFlow Authors and RStudio, Inc.
<script type=text/javascript>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');_st('install','Ne8tbLfE121Pkj3xMr_G','2.0.0');</script></footer></div></div></body></html>