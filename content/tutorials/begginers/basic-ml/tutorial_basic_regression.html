---
title: "Basic Regression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial: Basic Regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Regression"
    identifier: "keras-tutorial-basic-regression"
    parent: "tutorials-begginers-basic-ml-top"
    weight: 40
---



<p>In a regression problem, we aim to predict the output of a continuous value, like a price or a probability. Contrast this with a classification problem, where we aim to predict a discrete label (for example, where a picture contains an apple or an orange).</p>
<p>This notebook builds a model to predict the median price of homes in a Boston suburb during the mid-1970s. To do this, we’ll provide the model with some data points about the suburb, such as the crime rate and the local property tax rate.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(keras)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tfdatasets)</a></code></pre></div>
<div id="the-boston-housing-prices-dataset" class="section level2">
<h2>The Boston Housing Prices dataset</h2>
<p>The <a href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html">Boston Housing Prices dataset</a> is accessible directly from keras.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">boston_housing &lt;-<span class="st"> </span><span class="kw"><a href="../../../keras/reference/dataset_boston_housing.html">dataset_boston_housing</a></span>()</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(train_data, train_labels) <span class="op">%&lt;-%</span><span class="st"> </span>boston_housing<span class="op">$</span>train</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(test_data, test_labels) <span class="op">%&lt;-%</span><span class="st"> </span>boston_housing<span class="op">$</span>test</a></code></pre></div>
<div id="examples-and-features" class="section level3">
<h3>Examples and features</h3>
<p>This dataset is much smaller than the others we’ve worked with so far: it has 506 total examples that are split between 404 training examples and 102 test examples:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"Training entries: "</span>, <span class="kw"><a href="https://rdrr.io/r/base/length.html">length</a></span>(train_data), <span class="st">", labels: "</span>, <span class="kw"><a href="https://rdrr.io/r/base/length.html">length</a></span>(train_labels))</a></code></pre></div>
<pre><code>## [1] "Training entries: 5252, labels: 404"</code></pre>
<p>The dataset contains 13 different features:</p>
<ul>
<li>Per capita crime rate.</li>
<li>The proportion of residential land zoned for lots over 25,000 square feet.</li>
<li>The proportion of non-retail business acres per town.</li>
<li>Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).</li>
<li>Nitric oxides concentration (parts per 10 million).</li>
<li>The average number of rooms per dwelling.</li>
<li>The proportion of owner-occupied units built before 1940.</li>
<li>Weighted distances to five Boston employment centers.</li>
<li>Index of accessibility to radial highways.</li>
<li>Full-value property-tax rate per $10,000.</li>
<li>Pupil-teacher ratio by town.</li>
<li>1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.</li>
<li>Percentage lower status of the population.</li>
</ul>
<p>Each one of these input data features is stored using a different scale. Some features are represented by a proportion between 0 and 1, other features are ranges between 1 and 12, some are ranges between 0 and 100, and so on.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">train_data[<span class="dv">1</span>, ] <span class="co"># Display sample features, notice the different scales</span></a></code></pre></div>
<pre><code>##  [1]   1.23247   0.00000   8.14000   0.00000   0.53800   6.14200  91.70000
##  [8]   3.97690   4.00000 307.00000  21.00000 396.90000  18.72000</code></pre>
<p>Let’s add column names for better data inspection.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(dplyr)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"></a>
<a class="sourceLine" id="cb7-3" data-line-number="3">column_names &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">'CRIM'</span>, <span class="st">'ZN'</span>, <span class="st">'INDUS'</span>, <span class="st">'CHAS'</span>, <span class="st">'NOX'</span>, <span class="st">'RM'</span>, <span class="st">'AGE'</span>, </a>
<a class="sourceLine" id="cb7-4" data-line-number="4">                  <span class="st">'DIS'</span>, <span class="st">'RAD'</span>, <span class="st">'TAX'</span>, <span class="st">'PTRATIO'</span>, <span class="st">'B'</span>, <span class="st">'LSTAT'</span>)</a>
<a class="sourceLine" id="cb7-5" data-line-number="5"></a>
<a class="sourceLine" id="cb7-6" data-line-number="6">train_df &lt;-<span class="st"> </span>train_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-7" data-line-number="7"><span class="st">  </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/reexports.html">as_tibble</a></span>(<span class="dt">.name_repair =</span> <span class="st">"minimal"</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-8" data-line-number="8"><span class="st">  </span><span class="kw"><a href="https://rdrr.io/r/stats/setNames.html">setNames</a></span>(column_names) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-9" data-line-number="9"><span class="st">  </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span>(<span class="dt">label =</span> train_labels)</a>
<a class="sourceLine" id="cb7-10" data-line-number="10"></a>
<a class="sourceLine" id="cb7-11" data-line-number="11">test_df &lt;-<span class="st"> </span>test_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-12" data-line-number="12"><span class="st">  </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/reexports.html">as_tibble</a></span>(<span class="dt">.name_repair =</span> <span class="st">"minimal"</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-13" data-line-number="13"><span class="st">  </span><span class="kw"><a href="https://rdrr.io/r/stats/setNames.html">setNames</a></span>(column_names) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-14" data-line-number="14"><span class="st">  </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span>(<span class="dt">label =</span> test_labels)</a></code></pre></div>
</div>
<div id="labels" class="section level3">
<h3>Labels</h3>
<p>The labels are the house prices in thousands of dollars. (You may notice the mid-1970s prices.)</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">train_labels[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>] <span class="co"># Display first 10 entries</span></a></code></pre></div>
<pre><code>##  [1] 15.2 42.3 50.0 21.1 17.7 18.5 11.3 15.6 15.6 14.4</code></pre>
</div>
</div>
<div id="normalize-features" class="section level2">
<h2>Normalize features</h2>
<p>It’s recommended to normalize features that use different scales and ranges. Although the model might converge without feature normalization, it makes training more difficult, and it makes the resulting model more dependant on the choice of units used in the input.</p>
<p>We are going to use the <code>feature_spec</code> interface implemented in the <code>tfdatasets</code> package for the normalizzation. The <code>feature_columns</code> interface allows for other common pre-processing operations on tabular data.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">spec &lt;-<span class="st"> </span><span class="kw"><a href="../../../tools/tfdatasets/reference/feature_spec.html">feature_spec</a></span>(train_df, label <span class="op">~</span><span class="st"> </span>. ) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="st">  </span><span class="kw"><a href="../../../tools/tfdatasets/reference/step_numeric_column.html">step_numeric_column</a></span>(<span class="kw"><a href="../../../tools/tfdatasets/reference/all_numeric.html">all_numeric</a></span>(), <span class="dt">normalizer_fn =</span> <span class="kw"><a href="../../../tools/tfdatasets/reference/scaler_standard.html">scaler_standard</a></span>()) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-3" data-line-number="3"><span class="st">  </span><span class="kw"><a href="../../../keras/reference/reexports.html">fit</a></span>()</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"></a>
<a class="sourceLine" id="cb10-5" data-line-number="5">spec</a></code></pre></div>
<pre><code>## ── Feature Spec ─────────────────────────────────────────────────────────────────────────────── 
## A feature_spec with 13 steps.
## Fitted: TRUE 
## ── Steps ────────────────────────────────────────────────────────────────────────────────────── 
## The feature_spec has 1 dense features.
## StepNumericColumn: CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT 
## ── Dense features ─────────────────────────────────────────────────────────────────────────────</code></pre>
<p>The <code>spec</code> created with <code>tfdatasets</code> can be used together with <code>layer_dense_features</code> to make the pre-processing directly in the TensorFlow graph.</p>
<p>We can take a look at the output of a Dense Feature layer with this <code>spec</code>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">layer &lt;-<span class="st"> </span><span class="kw"><a href="../../../keras/reference/layer_dense_features.html">layer_dense_features</a></span>(</a>
<a class="sourceLine" id="cb12-2" data-line-number="2">  <span class="dt">feature_columns =</span> <span class="kw"><a href="../../../tools/tfdatasets/reference/dense_features.html">dense_features</a></span>(spec), </a>
<a class="sourceLine" id="cb12-3" data-line-number="3">  <span class="dt">dtype =</span> tf<span class="op">$</span>float32</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">)</a>
<a class="sourceLine" id="cb12-5" data-line-number="5"><span class="kw">layer</span>(train_df)</a></code></pre></div>
<pre><code>## tf.Tensor(
## [[ 0.81205493  0.44752213 -0.2565147  ... -0.1762239  -0.59443307
##   -0.48301655]
##  [-1.9079947   0.43137115 -0.2565147  ...  1.8920003  -0.34800112
##    2.9880793 ]
##  [ 1.1091131   0.2203439  -0.2565147  ... -1.8274226   1.563349
##   -0.48301655]
##  ...
##  [-1.6359899   0.07934052 -0.2565147  ... -0.3326088  -0.61246467
##    0.9895695 ]
##  [ 1.0554279  -0.98642045 -0.2565147  ... -0.7862657  -0.01742171
##   -0.48301655]
##  [-1.7970455   0.23288251 -0.2565147  ...  0.47467488 -0.84687555
##    2.0414166 ]], shape=(404, 13), dtype=float32)</code></pre>
<p>Note that this returns a matrix (in the sense it’s a 2-dimensional Tensor) with
scaled values.</p>
</div>
<div id="create-the-model" class="section level2">
<h2>Create the model</h2>
<p>Let’s build our model. Here we will use the Keras <strong>functional</strong> API - which is the recommend way when using the <code>feature_spec</code> API. Note that we only need to pass the <code>dense_features</code> from the <code>spec</code> we just created.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">input &lt;-<span class="st"> </span><span class="kw"><a href="../../../tools/tfdatasets/reference/layer_input_from_dataset.html">layer_input_from_dataset</a></span>(train_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>label))</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"></a>
<a class="sourceLine" id="cb14-3" data-line-number="3">output &lt;-<span class="st"> </span>input <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb14-4" data-line-number="4"><span class="st">  </span><span class="kw"><a href="../../../keras/reference/layer_dense_features.html">layer_dense_features</a></span>(<span class="kw"><a href="../../../tools/tfdatasets/reference/dense_features.html">dense_features</a></span>(spec)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb14-5" data-line-number="5"><span class="st">  </span><span class="kw"><a href="../../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6"><span class="st">  </span><span class="kw"><a href="../../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7"><span class="st">  </span><span class="kw"><a href="../../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">1</span>) </a>
<a class="sourceLine" id="cb14-8" data-line-number="8"></a>
<a class="sourceLine" id="cb14-9" data-line-number="9">model &lt;-<span class="st"> </span><span class="kw"><a href="../../../keras/reference/keras_model.html">keras_model</a></span>(input, output)</a>
<a class="sourceLine" id="cb14-10" data-line-number="10"></a>
<a class="sourceLine" id="cb14-11" data-line-number="11"><span class="kw"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(model)</a></code></pre></div>
<pre><code>## Model: "model"
## ___________________________________________________________________________
## Layer (type)            Output Shape     Param #  Connected to             
## ===========================================================================
## AGE (InputLayer)        [(None,)]        0                                 
## ___________________________________________________________________________
## B (InputLayer)          [(None,)]        0                                 
## ___________________________________________________________________________
## CHAS (InputLayer)       [(None,)]        0                                 
## ___________________________________________________________________________
## CRIM (InputLayer)       [(None,)]        0                                 
## ___________________________________________________________________________
## DIS (InputLayer)        [(None,)]        0                                 
## ___________________________________________________________________________
## INDUS (InputLayer)      [(None,)]        0                                 
## ___________________________________________________________________________
## LSTAT (InputLayer)      [(None,)]        0                                 
## ___________________________________________________________________________
## NOX (InputLayer)        [(None,)]        0                                 
## ___________________________________________________________________________
## PTRATIO (InputLayer)    [(None,)]        0                                 
## ___________________________________________________________________________
## RAD (InputLayer)        [(None,)]        0                                 
## ___________________________________________________________________________
## RM (InputLayer)         [(None,)]        0                                 
## ___________________________________________________________________________
## TAX (InputLayer)        [(None,)]        0                                 
## ___________________________________________________________________________
## ZN (InputLayer)         [(None,)]        0                                 
## ___________________________________________________________________________
## dense_features_1 (Dense (None, 13)       0        AGE[0][0]                
##                                                   B[0][0]                  
##                                                   CHAS[0][0]               
##                                                   CRIM[0][0]               
##                                                   DIS[0][0]                
##                                                   INDUS[0][0]              
##                                                   LSTAT[0][0]              
##                                                   NOX[0][0]                
##                                                   PTRATIO[0][0]            
##                                                   RAD[0][0]                
##                                                   RM[0][0]                 
##                                                   TAX[0][0]                
##                                                   ZN[0][0]                 
## ___________________________________________________________________________
## dense (Dense)           (None, 64)       896      dense_features_1[0][0]   
## ___________________________________________________________________________
## dense_1 (Dense)         (None, 64)       4160     dense[0][0]              
## ___________________________________________________________________________
## dense_2 (Dense)         (None, 1)        65       dense_1[0][0]            
## ===========================================================================
## Total params: 5,121
## Trainable params: 5,121
## Non-trainable params: 0
## ___________________________________________________________________________</code></pre>
<p>We then compile the model with:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">model <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="st">  </span><span class="kw"><a href="../../../keras/reference/reexports.html">compile</a></span>(</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">    <span class="dt">loss =</span> <span class="st">"mse"</span>,</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">    <span class="dt">optimizer =</span> <span class="kw"><a href="../../../keras/reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(),</a>
<a class="sourceLine" id="cb16-5" data-line-number="5">    <span class="dt">metrics =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="st">"mean_absolute_error"</span>)</a>
<a class="sourceLine" id="cb16-6" data-line-number="6">  )</a></code></pre></div>
<p>We will wrap the model building code into a functionin order to be able to reuse it for different experiments. Remember that Keras <code>fit</code> modifies the model in-place.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">build_model &lt;-<span class="st"> </span><span class="cf">function</span>() {</a>
<a class="sourceLine" id="cb17-2" data-line-number="2">  input &lt;-<span class="st"> </span><span class="kw"><a href="../../../tools/tfdatasets/reference/layer_input_from_dataset.html">layer_input_from_dataset</a></span>(train_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>label))</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">  </a>
<a class="sourceLine" id="cb17-4" data-line-number="4">  output &lt;-<span class="st"> </span>input <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="st">    </span><span class="kw"><a href="../../../keras/reference/layer_dense_features.html">layer_dense_features</a></span>(<span class="kw"><a href="../../../tools/tfdatasets/reference/dense_features.html">dense_features</a></span>(spec)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6"><span class="st">    </span><span class="kw"><a href="../../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-7" data-line-number="7"><span class="st">    </span><span class="kw"><a href="../../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-8" data-line-number="8"><span class="st">    </span><span class="kw"><a href="../../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">1</span>) </a>
<a class="sourceLine" id="cb17-9" data-line-number="9">  </a>
<a class="sourceLine" id="cb17-10" data-line-number="10">  model &lt;-<span class="st"> </span><span class="kw"><a href="../../../keras/reference/keras_model.html">keras_model</a></span>(input, output)</a>
<a class="sourceLine" id="cb17-11" data-line-number="11">  </a>
<a class="sourceLine" id="cb17-12" data-line-number="12">  model <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-13" data-line-number="13"><span class="st">    </span><span class="kw"><a href="../../../keras/reference/reexports.html">compile</a></span>(</a>
<a class="sourceLine" id="cb17-14" data-line-number="14">      <span class="dt">loss =</span> <span class="st">"mse"</span>,</a>
<a class="sourceLine" id="cb17-15" data-line-number="15">      <span class="dt">optimizer =</span> <span class="kw"><a href="../../../keras/reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(),</a>
<a class="sourceLine" id="cb17-16" data-line-number="16">      <span class="dt">metrics =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="st">"mean_absolute_error"</span>)</a>
<a class="sourceLine" id="cb17-17" data-line-number="17">    )</a>
<a class="sourceLine" id="cb17-18" data-line-number="18">  </a>
<a class="sourceLine" id="cb17-19" data-line-number="19">  model</a>
<a class="sourceLine" id="cb17-20" data-line-number="20">}</a></code></pre></div>
</div>
<div id="train-the-model" class="section level2">
<h2>Train the model</h2>
<p>The model is trained for 500 epochs, recording training and validation accuracy in a <code>keras_training_history</code> object.
We also show how to use a custom callback, replacing the default training output by a single dot per epoch.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="co"># Display training progress by printing a single dot for each completed epoch.</span></a>
<a class="sourceLine" id="cb18-2" data-line-number="2">print_dot_callback &lt;-<span class="st"> </span><span class="kw"><a href="../../../keras/reference/callback_lambda.html">callback_lambda</a></span>(</a>
<a class="sourceLine" id="cb18-3" data-line-number="3">  <span class="dt">on_epoch_end =</span> <span class="cf">function</span>(epoch, logs) {</a>
<a class="sourceLine" id="cb18-4" data-line-number="4">    <span class="cf">if</span> (epoch <span class="op">%%</span><span class="st"> </span><span class="dv">80</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="kw"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb18-5" data-line-number="5">    <span class="kw"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="st">"."</span>)</a>
<a class="sourceLine" id="cb18-6" data-line-number="6">  }</a>
<a class="sourceLine" id="cb18-7" data-line-number="7">)    </a>
<a class="sourceLine" id="cb18-8" data-line-number="8"></a>
<a class="sourceLine" id="cb18-9" data-line-number="9">model &lt;-<span class="st"> </span><span class="kw">build_model</span>()</a>
<a class="sourceLine" id="cb18-10" data-line-number="10"></a>
<a class="sourceLine" id="cb18-11" data-line-number="11">history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../../keras/reference/reexports.html">fit</a></span>(</a>
<a class="sourceLine" id="cb18-12" data-line-number="12">  <span class="dt">x =</span> train_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>label),</a>
<a class="sourceLine" id="cb18-13" data-line-number="13">  <span class="dt">y =</span> train_df<span class="op">$</span>label,</a>
<a class="sourceLine" id="cb18-14" data-line-number="14">  <span class="dt">epochs =</span> <span class="dv">500</span>,</a>
<a class="sourceLine" id="cb18-15" data-line-number="15">  <span class="dt">validation_split =</span> <span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb18-16" data-line-number="16">  <span class="dt">verbose =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb18-17" data-line-number="17">  <span class="dt">callbacks =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(print_dot_callback)</a>
<a class="sourceLine" id="cb18-18" data-line-number="18">)</a></code></pre></div>
<pre><code>## 
## ................................................................................
## ................................................................................
## ................................................................................
## ................................................................................
## ................................................................................
## ................................................................................
## ....................</code></pre>
<p>Now, we visualize the model’s training progress using the metrics stored in the <code>history</code> variable. We want to use this data to determine how long to train before the model stops making progress.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(ggplot2)</a></code></pre></div>
<pre><code>## 
## Attaching package: 'ggplot2'</code></pre>
<pre><code>## The following object is masked _by_ '.GlobalEnv':
## 
##     layer</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(history)</a></code></pre></div>
<p><img src="/tutorials/begginers/basic-ml/tutorial_basic_regression_files/figure-html/unnamed-chunk-13-1.png" width="672"></p>
<p>This graph shows little improvement in the model after about 200 epochs. Let’s update the <code>fit</code> method to automatically stop training when the validation score doesn’t improve. We’ll use a <a href="https://keras.rstudio.com/reference/callback_early_stopping.html">callback</a> that tests a training condition for every epoch. If a set amount of epochs elapses without showing improvement, it automatically stops the training.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># The patience parameter is the amount of epochs to check for improvement.</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2">early_stop &lt;-<span class="st"> </span><span class="kw"><a href="../../../keras/reference/callback_early_stopping.html">callback_early_stopping</a></span>(<span class="dt">monitor =</span> <span class="st">"val_loss"</span>, <span class="dt">patience =</span> <span class="dv">20</span>)</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"></a>
<a class="sourceLine" id="cb24-4" data-line-number="4">model &lt;-<span class="st"> </span><span class="kw">build_model</span>()</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"></a>
<a class="sourceLine" id="cb24-6" data-line-number="6">history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../../keras/reference/reexports.html">fit</a></span>(</a>
<a class="sourceLine" id="cb24-7" data-line-number="7">  <span class="dt">x =</span> train_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>label),</a>
<a class="sourceLine" id="cb24-8" data-line-number="8">  <span class="dt">y =</span> train_df<span class="op">$</span>label,</a>
<a class="sourceLine" id="cb24-9" data-line-number="9">  <span class="dt">epochs =</span> <span class="dv">500</span>,</a>
<a class="sourceLine" id="cb24-10" data-line-number="10">  <span class="dt">validation_split =</span> <span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb24-11" data-line-number="11">  <span class="dt">verbose =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb24-12" data-line-number="12">  <span class="dt">callbacks =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(early_stop)</a>
<a class="sourceLine" id="cb24-13" data-line-number="13">)</a>
<a class="sourceLine" id="cb24-14" data-line-number="14"></a>
<a class="sourceLine" id="cb24-15" data-line-number="15"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(history)</a></code></pre></div>
<p><img src="/tutorials/begginers/basic-ml/tutorial_basic_regression_files/figure-html/unnamed-chunk-14-1.png" width="672"></p>
<p>The graph shows the average error is about $2,500 dollars. Is this good? Well, $2,500 is not an insignificant amount when some of the labels are only $15,000.</p>
<p>Let’s see how did the model performs on the test set:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(loss, mae) <span class="op">%&lt;-%</span><span class="st"> </span>(model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../../keras/reference/reexports.html">evaluate</a></span>(test_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>label), test_df<span class="op">$</span>label, <span class="dt">verbose =</span> <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb25-2" data-line-number="2"></a>
<a class="sourceLine" id="cb25-3" data-line-number="3"><span class="kw"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"Mean absolute error on test set: $"</span>, <span class="kw"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span>(<span class="st">"%.2f"</span>, mae <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>))</a></code></pre></div>
<pre><code>## [1] "Mean absolute error on test set: $3198.34"</code></pre>
</div>
<div id="predict" class="section level2">
<h2>Predict</h2>
<p>Finally, predict some housing prices using data in the testing set:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">test_predictions &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(test_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>label))</a>
<a class="sourceLine" id="cb27-2" data-line-number="2">test_predictions[ , <span class="dv">1</span>]</a></code></pre></div>
<pre><code>##   [1]  8.313209 17.566935 20.598778 31.261530 24.999113 18.915787 26.706968
##   [8] 21.463493 19.077044 22.214228 21.006977 16.639135 14.516401 41.853142
##  [15] 19.648882 18.503626 27.029097 20.594465 19.556849 37.235291 12.048627
##  [22] 15.747840 20.656973 14.720628 19.948135 25.351406 31.418047 28.784756
##  [29] 10.445296 20.277281 19.189438 14.857674 32.741436 25.288258 17.786026
##  [36]  8.949254 15.691667 18.827656 19.194653 25.527187 27.607018 28.511127
##  [43] 14.357985 40.790352 29.735785 23.787636 26.189007 16.104458 23.577971
##  [50] 21.387493 33.781349 19.266973 12.746031 15.572680 34.161980 27.950607
##  [57] 12.604152 47.414593 34.264282 23.094900 24.373957 17.053846 14.789891
##  [64] 17.759920 23.234787 21.404305 13.404339 21.974499 14.939521  7.493078
##  [71] 36.999279 29.112703 26.042667 15.074617 24.627146 17.390221 19.364826
##  [78] 22.838552 34.291599 11.231264 20.133642 37.277409 15.295828 13.880612
##  [85] 17.439848 17.541855 20.812265 20.506054 22.454138 30.830711 18.257444
##  [92] 18.289457 24.501291 40.683392 34.282269 19.569807 35.508789 51.060753
##  [99] 26.705236 44.739986 33.279140 20.455276</code></pre>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>This notebook introduced a few techniques to handle a regression problem.</p>
<ul>
<li>Mean Squared Error (MSE) is a common loss function used for regression problems (different than classification problems).</li>
<li>Similarly, evaluation metrics used for regression differ from classification. A common regression metric is Mean Absolute Error (MAE).</li>
<li>When input data features have values with different ranges, each feature should be scaled independently.</li>
<li>If there is not much training data, prefer a small network with few hidden layers to avoid overfitting.</li>
<li>Early stopping is a useful technique to prevent overfitting.</li>
</ul>
</div>
