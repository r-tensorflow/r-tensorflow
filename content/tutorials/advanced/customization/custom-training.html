---
title: "Custom training: basics"
type: docs
menu:
  main:
    name: "Custom training"
    identifier: "tutorials-advanced-customization-custom-training"
    parent: "tutorials-advanced-customization-top"
    weight: 75
---



<p>In the previous tutorial, you covered the TensorFlow APIs for automatic differentiation—a basic building block for machine learning. In this tutorial, you will use the TensorFlow primitives introduced in the prior tutorials to do some simple machine learning.</p>
<p>TensorFlow also includes Keras —a high-level neural network API that provides useful abstractions to reduce boilerplate and makes TensorFlow easier to use without sacrificing flexibility and performance. We strongly recommend the Keras API for development. However, in this short tutorial you will learn how to train a neural network from first principles to establish a strong foundation.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tensorflow)</a></code></pre></div>
<div id="variables" class="section level2">
<h2>Variables</h2>
<p>Tensors in TensorFlow are immutable stateless objects. Machine learning models, however, must have changing state: as your model trains, the same code to compute predictions should behave differently over time (hopefully with a lower loss!).</p>
<p>TensorFlow has stateful operations built-in, and these are often easier than using low-level R representations for your state. Use <code>tf$Variable</code> to represent weights in a model.</p>
<p>A <code>tf$Variable</code> object stores a value and implicitly reads from this stored value. There are operations (<code>tf.assign_sub</code>, <code>tf.scatter_update</code>, etc.) that manipulate the value stored in a TensorFlow variable.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">v &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="co"># Use Python's `assert` as a debugging statement to test the condition</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(v) <span class="op">==</span><span class="st"> </span><span class="dv">1</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co"># Reassign the value `v`</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">v<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/assign.html">assign</a></span>(<span class="dv">3</span>)</a></code></pre></div>
<pre><code>## &lt;tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=3.0&gt;</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(v) <span class="op">==</span><span class="st"> </span><span class="dv">3</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co"># Use `v` in a TensorFlow `tf.square()` operation and reassign</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2">v<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/assign.html">assign</a></span>(tf<span class="op">$</span><span class="kw">square</span>(v))</a></code></pre></div>
<pre><code>## &lt;tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=9.0&gt;</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(v) <span class="op">==</span><span class="st"> </span><span class="dv">9</span></a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Computations using <code>tf$Variable</code> are automatically traced when computing gradients. For variables that represent embeddings, TensorFlow will do sparse updates by default, which are more computation and memory efficient.</p>
<p>A <code>tf$Variable</code> is also a way to show a reader of your code that a piece of state is mutable.</p>
</div>
<div id="fit-a-linear-model" class="section level2">
<h2>Fit a linear model</h2>
<p>Let’s use the concepts you have learned so far—<code>Tensor</code>, <code>Variable</code>, and <code>GradientTape</code>—to build and train a simple model. This typically involves a few steps:</p>
<ol style="list-style-type: decimal">
<li>Define the model.</li>
<li>Define a loss function.</li>
<li>Obtain training data.</li>
<li>Run through the training data and use an “optimizer” to adjust the variables to fit the data.</li>
</ol>
<p>Here, you’ll create a simple linear model, <code>f(x) = x * W + b</code>, which has two variables: <code>W</code> (weights) and <code>b</code> (bias). You’ll synthesize data such that a well trained model would have <code>W = 3.0</code> and <code>b = 2.0</code>.</p>
<div id="define-the-model" class="section level3">
<h3>Define the model</h3>
<p>You may organize your TensorFlow code to build models the way you prefer, here
we will suggest using an R6 class.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">Model &lt;-<span class="st"> </span>R6<span class="op">::</span><span class="kw"><a href="https://rdrr.io/pkg/R6/man/R6Class.html">R6Class</a></span>(</a>
<a class="sourceLine" id="cb12-2" data-line-number="2">  <span class="dt">classname =</span> <span class="st">"Model"</span>,</a>
<a class="sourceLine" id="cb12-3" data-line-number="3">  <span class="dt">public =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">    <span class="dt">W =</span> <span class="ot">NULL</span>,</a>
<a class="sourceLine" id="cb12-5" data-line-number="5">    <span class="dt">b =</span> <span class="ot">NULL</span>,</a>
<a class="sourceLine" id="cb12-6" data-line-number="6">    </a>
<a class="sourceLine" id="cb12-7" data-line-number="7">    <span class="dt">initialize =</span> <span class="cf">function</span>() {</a>
<a class="sourceLine" id="cb12-8" data-line-number="8">      self<span class="op">$</span>W &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(<span class="dv">5</span>)</a>
<a class="sourceLine" id="cb12-9" data-line-number="9">      self<span class="op">$</span>b &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb12-10" data-line-number="10">    },</a>
<a class="sourceLine" id="cb12-11" data-line-number="11">    </a>
<a class="sourceLine" id="cb12-12" data-line-number="12">    <span class="dt">call =</span> <span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb12-13" data-line-number="13">      self<span class="op">$</span>W<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>self<span class="op">$</span>b</a>
<a class="sourceLine" id="cb12-14" data-line-number="14">    }</a>
<a class="sourceLine" id="cb12-15" data-line-number="15">    </a>
<a class="sourceLine" id="cb12-16" data-line-number="16">  )</a>
<a class="sourceLine" id="cb12-17" data-line-number="17">)</a>
<a class="sourceLine" id="cb12-18" data-line-number="18"></a>
<a class="sourceLine" id="cb12-19" data-line-number="19">model &lt;-<span class="st"> </span>Model<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb12-20" data-line-number="20">model<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/call.html">call</a></span>(<span class="dv">3</span>)</a></code></pre></div>
<pre><code>## tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
</div>
<div id="define-the-loss-function" class="section level3">
<h3>Define the loss function</h3>
<p>A loss function measures how well the output of a model for a given input matches the target output. The goal is to minimize this difference during training. Let’s use the standard L2 loss, also known as the least square errors:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_pred, y_true) {</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">  tf<span class="op">$</span><span class="kw">reduce_mean</span>(tf<span class="op">$</span><span class="kw">square</span>(y_pred <span class="op">-</span><span class="st"> </span>y_true))</a>
<a class="sourceLine" id="cb14-3" data-line-number="3">}</a></code></pre></div>
</div>
<div id="obtain-training-data" class="section level3">
<h3>Obtain training data</h3>
<p>First, synthesize the training data by adding random Gaussian (Normal) noise to the inputs:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">TRUE_W =<span class="st"> </span><span class="fl">3.0</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2">TRUE_b =<span class="st"> </span><span class="fl">2.0</span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3">NUM_EXAMPLES =<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"></a>
<a class="sourceLine" id="cb15-5" data-line-number="5">inputs  &lt;-<span class="st"> </span>tf<span class="op">$</span>random<span class="op">$</span><span class="kw">normal</span>(<span class="dt">shape=</span><span class="kw"><a href="../../../tensorflow/reference/shape.html">shape</a></span>(NUM_EXAMPLES))</a>
<a class="sourceLine" id="cb15-6" data-line-number="6">noise   &lt;-<span class="st"> </span>tf<span class="op">$</span>random<span class="op">$</span><span class="kw">normal</span>(<span class="dt">shape=</span><span class="kw"><a href="../../../tensorflow/reference/shape.html">shape</a></span>(NUM_EXAMPLES))</a>
<a class="sourceLine" id="cb15-7" data-line-number="7">outputs &lt;-<span class="st"> </span>inputs <span class="op">*</span><span class="st"> </span>TRUE_W <span class="op">+</span><span class="st"> </span>TRUE_b <span class="op">+</span><span class="st"> </span>noise</a></code></pre></div>
<p>Before training the model, visualize the loss value by plotting the model’s predictions in red and the training data in blue:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tidyverse)</a></code></pre></div>
<pre><code>## ── Attaching packages ───────────────────────────────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.2.0     ✔ purrr   0.3.2
## ✔ tibble  2.1.3     ✔ dplyr   0.8.3
## ✔ tidyr   1.0.0     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ──────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb20-2" data-line-number="2">  <span class="dt">inputs =</span> <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(inputs), </a>
<a class="sourceLine" id="cb20-3" data-line-number="3">  <span class="dt">outputs =</span> <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(outputs),</a>
<a class="sourceLine" id="cb20-4" data-line-number="4">  <span class="dt">predicted =</span> <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(model<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/call.html">call</a></span>(inputs))</a>
<a class="sourceLine" id="cb20-5" data-line-number="5">) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> inputs)) <span class="op">+</span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> outputs)) <span class="op">+</span></a>
<a class="sourceLine" id="cb20-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> predicted), <span class="dt">color =</span> <span class="st">"blue"</span>)</a></code></pre></div>
<p><img src="/tutorials/advanced/customization/custom-training_files/figure-html/unnamed-chunk-6-1.png" width="672"></p>
</div>
<div id="define-a-training-loop" class="section level3">
<h3>Define a training loop</h3>
<p>With the network and training data, train the model using gradient descent to update the weights variable (W) and the bias variable (b) to reduce the loss.</p>
<p>There are many variants of the gradient descent scheme that are captured in <code>tf$train$Optimizer</code>—our recommended implementation. But in the spirit of building from first principles, here you will implement the basic math yourself with the help of <code>tf.GradientTape</code> for automatic differentiation and <code>tf.assign_sub</code> for decrementing a value (which combines <code>tf.assign</code> and <code>tf.sub</code>):</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">train &lt;-<span class="st"> </span><span class="cf">function</span>(model, inputs, outputs, learning_rate) {</a>
<a class="sourceLine" id="cb21-2" data-line-number="2">  <span class="kw"><a href="https://rdrr.io/r/base/with.html">with</a></span> (tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>t, {</a>
<a class="sourceLine" id="cb21-3" data-line-number="3">    current_loss =<span class="st"> </span><span class="kw">loss</span>(model<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/call.html">call</a></span>(inputs), outputs)</a>
<a class="sourceLine" id="cb21-4" data-line-number="4">  })</a>
<a class="sourceLine" id="cb21-5" data-line-number="5">  </a>
<a class="sourceLine" id="cb21-6" data-line-number="6">  d &lt;-<span class="st"> </span>t<span class="op">$</span><span class="kw">gradient</span>(current_loss, <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(model<span class="op">$</span>W, model<span class="op">$</span>b))</a>
<a class="sourceLine" id="cb21-7" data-line-number="7">  </a>
<a class="sourceLine" id="cb21-8" data-line-number="8">  model<span class="op">$</span>W<span class="op">$</span><span class="kw">assign_sub</span>(learning_rate <span class="op">*</span><span class="st"> </span>d[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb21-9" data-line-number="9">  model<span class="op">$</span>b<span class="op">$</span><span class="kw">assign_sub</span>(learning_rate <span class="op">*</span><span class="st"> </span>d[[<span class="dv">2</span>]])</a>
<a class="sourceLine" id="cb21-10" data-line-number="10">  current_loss</a>
<a class="sourceLine" id="cb21-11" data-line-number="11">}</a></code></pre></div>
<p>Finally, let’s repeatedly run through the training data and see how W and b evolve.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">model &lt;-<span class="st"> </span>Model<span class="op">$</span><span class="kw">new</span>()</a>
<a class="sourceLine" id="cb22-2" data-line-number="2"></a>
<a class="sourceLine" id="cb22-3" data-line-number="3">Ws &lt;-<span class="st"> </span>bs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>()</a>
<a class="sourceLine" id="cb22-4" data-line-number="4"></a>
<a class="sourceLine" id="cb22-5" data-line-number="5"><span class="cf">for</span> (epoch <span class="cf">in</span> <span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(<span class="dv">20</span>)) {</a>
<a class="sourceLine" id="cb22-6" data-line-number="6">  </a>
<a class="sourceLine" id="cb22-7" data-line-number="7">  Ws[epoch] &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(model<span class="op">$</span>W)</a>
<a class="sourceLine" id="cb22-8" data-line-number="8">  bs[epoch] &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(model<span class="op">$</span>b)</a>
<a class="sourceLine" id="cb22-9" data-line-number="9">  </a>
<a class="sourceLine" id="cb22-10" data-line-number="10">  current_loss &lt;-<span class="st"> </span><span class="kw"><a href="../../../tensorflow/reference/train.html">train</a></span>(model, inputs, outputs, <span class="dt">learning_rate =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb22-11" data-line-number="11">  <span class="kw"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(glue<span class="op">::</span><span class="kw"><a href="https://rdrr.io/pkg/glue/man/glue.html">glue</a></span>(<span class="st">"Epoch: {epoch}, Loss: {as.numeric(current_loss)}"</span>), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb22-12" data-line-number="12">} </a></code></pre></div>
<pre><code>## Epoch: 1, Loss: 9.22420692443848 
## Epoch: 2, Loss: 6.19532537460327 
## Epoch: 3, Loss: 4.27906942367554 
## Epoch: 4, Loss: 3.06672716140747 
## Epoch: 5, Loss: 2.29972267150879 
## Epoch: 6, Loss: 1.81446659564972 
## Epoch: 7, Loss: 1.50746238231659 
## Epoch: 8, Loss: 1.31323146820068 
## Epoch: 9, Loss: 1.19034790992737 
## Epoch: 10, Loss: 1.11260342597961 
## Epoch: 11, Loss: 1.06341695785522 
## Epoch: 12, Loss: 1.03229808807373 
## Epoch: 13, Loss: 1.01261019706726 
## Epoch: 14, Loss: 1.0001540184021 
## Epoch: 15, Loss: 0.992273688316345 
## Epoch: 16, Loss: 0.987287759780884 
## Epoch: 17, Loss: 0.984133422374725 
## Epoch: 18, Loss: 0.982137799263 
## Epoch: 19, Loss: 0.9808748960495 
## Epoch: 20, Loss: 0.980076193809509</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb24-2" data-line-number="2">  <span class="dt">epoch =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,</a>
<a class="sourceLine" id="cb24-3" data-line-number="3">  <span class="dt">Ws =</span> Ws,</a>
<a class="sourceLine" id="cb24-4" data-line-number="4">  <span class="dt">bs =</span> bs</a>
<a class="sourceLine" id="cb24-5" data-line-number="5">) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="st">  </span><span class="kw">pivot_longer</span>(</a>
<a class="sourceLine" id="cb24-7" data-line-number="7">    <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(Ws, bs),</a>
<a class="sourceLine" id="cb24-8" data-line-number="8">    <span class="dt">names_to =</span> <span class="st">"parameter"</span>, </a>
<a class="sourceLine" id="cb24-9" data-line-number="9">    <span class="dt">values_to =</span> <span class="st">"estimate"</span></a>
<a class="sourceLine" id="cb24-10" data-line-number="10">  ) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-11" data-line-number="11"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> epoch, <span class="dt">y =</span> estimate)) <span class="op">+</span></a>
<a class="sourceLine" id="cb24-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb24-13" data-line-number="13"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>parameter, <span class="dt">scales =</span> <span class="st">"free"</span>)</a></code></pre></div>
<p><img src="/tutorials/advanced/customization/custom-training_files/figure-html/unnamed-chunk-8-1.png" width="672"></p>
<p>This tutorial used <code>tf$Variable</code> to build and train a simple linear model.</p>
<p>In practice, the high-level APIs—such as Keras—are much more convenient to build neural networks. Keras provides higher level building blocks (called “layers”), utilities to save and restore state, a suite of loss functions, a suite of optimization strategies, and more.</p>
</div>
</div>
