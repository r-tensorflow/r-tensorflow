---
title: linear_regression_simple
type: docs
menu:
  main:
    parent: tensorflow-examples
---



<p>Simple model that learns W and b by minimizing mean squared errors via gradient descent.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(tensorflow)

<span class="co"># Create 100 phony x, y data points, y = x * 0.1 + 0.3</span>
x_data &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Uniform">runif</a></span>(<span class="dv">100</span>, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">1</span>)
y_data &lt;-<span class="st"> </span>x_data <span class="op">*</span><span class="st"> </span><span class="fl">0.1</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.3</span>

<span class="co"># Try to find values for W and b that compute y_data = W * x_data + b</span>
<span class="co"># (We know that W should be 0.1 and b 0.3, but TensorFlow will</span>
<span class="co"># figure that out for us.)</span>
W &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(tf<span class="op">$</span><span class="kw">random_uniform</span>(<span class="kw"><a href="../../../tensorflow/reference/shape.html">shape</a></span>(1L), <span class="fl">-1.0</span>, <span class="fl">1.0</span>))
b &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(tf<span class="op">$</span><span class="kw">zeros</span>(<span class="kw"><a href="../../../tensorflow/reference/shape.html">shape</a></span>(1L)))
y &lt;-<span class="st"> </span>W <span class="op">*</span><span class="st"> </span>x_data <span class="op">+</span><span class="st"> </span>b

<span class="co"># Minimize the mean squared errors.</span>
loss &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">reduce_mean</span>((y <span class="op">-</span><span class="st"> </span>y_data) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>)
optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">GradientDescentOptimizer</span>(<span class="fl">0.5</span>)
train &lt;-<span class="st"> </span>optimizer<span class="op">$</span><span class="kw">minimize</span>(loss)

<span class="co"># Launch the graph and initialize the variables.</span>
sess =<span class="st"> </span>tf<span class="op">$</span><span class="kw">Session</span>()
sess<span class="op">$</span><span class="kw">run</span>(tf<span class="op">$</span><span class="kw">global_variables_initializer</span>())

<span class="co"># Fit the line (Learns best fit is W: 0.1, b: 0.3)</span>
<span class="cf">for</span> (step <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">201</span>) {
  sess<span class="op">$</span><span class="kw">run</span>(train)
  <span class="cf">if</span> (step <span class="op">%%</span><span class="st"> </span><span class="dv">20</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)
    <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/cat">cat</a></span>(step, <span class="st">"-"</span>, sess<span class="op">$</span><span class="kw">run</span>(W), sess<span class="op">$</span><span class="kw">run</span>(b), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)
}</code></pre>
