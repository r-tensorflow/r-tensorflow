---
title: "Keras with Eager Execution"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Keras with eager execution}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Keras with Eager Execution"
    identifier: "keras-eager"
    parent: "keras-using-keras"
    weight: 15
    
---



<p>Eager execution is a way to train a Keras model without building a graph. Operations return values, not tensors.
Consequently, you can inspect what goes in and comes out of an operation simply by printing a variable’s contents.
This is an important advantage in model development and debugging.</p>
<p>You can use eager execution with Keras as long as you use the TensorFlow implementation. This guide gives an outline of the workflow by way of a simple regression example. Specifically, you will see how to:</p>
<ul>
<li>Set up your environment for eager execution</li>
<li>Define the main ingredients: a Keras model, an optimizer and a loss function</li>
<li>Feed data to the training routine</li>
<li>Write a simple training loop that does backprop on the model’s weights</li>
<li>Make predictions on the test set</li>
<li>Save the model’s weights</li>
</ul>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<p>To use eager execution with Keras, you need a current version of the R package <code>keras</code> with a TensorFlow backend of version at least 1.9.</p>
<p>The following preamble is required when using eager execution:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(keras)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="co"># make sure we use the tensorflow implementation of Keras</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="co"># this line has to be executed immediately after loading the library</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw"><a href="../../keras/reference/use_implementation.html">use_implementation</a></span>(<span class="st">"tensorflow"</span>)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tensorflow)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co"># enable eager execution</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co"># the argument device_policy is needed only when using a GPU</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="kw"><a href="../../tensorflow/reference/tfe_enable_eager_execution.html">tfe_enable_eager_execution</a></span>(<span class="dt">device_policy =</span> <span class="st">"silent"</span>)</a></code></pre></div>
<p>When in doubt, check if you are in fact using eager execution:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">tf<span class="op">$</span><span class="kw">executing_eagerly</span>()</a></code></pre></div>
</div>
<div id="define-a-model" class="section level2">
<h2>Define a model</h2>
<p>Models for use with eager execution are defined as Keras <a href="https://tensorflow.rstudio.com/keras/articles/custom_models.html">custom models</a>.</p>
<p>Custom models are usually made up of normal Keras layers, which you configure as usual. However, you are free to implement custom logic in the model’s (implicit) <em>call</em> function.</p>
<p>Our simple regression example will use <code>iris</code> to predict <code>Sepal.Width</code> from <code>Petal.Length</code>, <code>Sepal.Length</code> and <code>Petal.Width</code>.</p>
<p>Here is a model that can be used for that purpose:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># model instantiator </span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">iris_regression_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">  </a>
<a class="sourceLine" id="cb3-4" data-line-number="4">  <span class="kw"><a href="../../keras/reference/keras_model_custom.html">keras_model_custom</a></span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">    </a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    <span class="co"># define any number of layers here</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">32</span>)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">    self<span class="op">$</span>dropout &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/layer_dropout.html">layer_dropout</a></span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb3-9" data-line-number="9">    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-10" data-line-number="10">    </a>
<a class="sourceLine" id="cb3-11" data-line-number="11">    <span class="co"># this is the "call" function that defines what happens when the model is called</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12">    <span class="cf">function</span> (x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-13" data-line-number="13">      x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense1</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="st">        </span>self<span class="op">$</span><span class="kw">dropout</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-16" data-line-number="16"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>()</a>
<a class="sourceLine" id="cb3-17" data-line-number="17">    }</a>
<a class="sourceLine" id="cb3-18" data-line-number="18">  })</a>
<a class="sourceLine" id="cb3-19" data-line-number="19">}</a></code></pre></div>
<p>The model is created simply by instantiating it via its wrapper:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw">iris_regression_model</span>()</a></code></pre></div>
<p>At this point, the shapes of the model’s weights are still unknown (note how no <code>input_shape</code> has been defined for its first layer).
You can, however, already call the model on some dummy data:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">model</span>(<span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)))</a></code></pre></div>
<pre><code>tf.Tensor(
[[-1.1474639]
 [-1.0472134]], shape=(2, 1), dtype=float32)</code></pre>
<p>After that call, you can inspect the model’s weights using</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">model<span class="op">$</span>weights</a></code></pre></div>
<p>This will not just display the tensor shapes, but the actual weight values.</p>
</div>
<div id="losses-and-optimizers" class="section level2">
<h2>Losses and optimizers</h2>
<p>An appropriate loss function for a regression task like this is mean squared error:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">mse_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, x) {</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">  <span class="co"># it's required to use a TensorFlow function here, not loss_mean_squared_error() from Keras</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">  mse &lt;-<span class="st"> </span>tf<span class="op">$</span>losses<span class="op">$</span><span class="kw">mean_squared_error</span>(y_true, y_pred)</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">  <span class="co"># here you could compute and add other losses </span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5">  mse</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">}</a></code></pre></div>
<p>Note how we have to use loss functions from TensorFlow, not the Keras equivalents. In the same vein, we need to use an optimizer from the <code>tf$train</code> module.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># have to use an optimizer from tf$train, not Keras</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">AdamOptimizer</span>()</a></code></pre></div>
</div>
<div id="use-tfdatasets-to-feed-the-data" class="section level2">
<h2>Use tfdatasets to feed the data</h2>
<p>In eager execution, you use <a href="https://tensorflow.rstudio.com/tools/tfdatasets">tfdatasets</a> to stream input and target data to the model.
In our simple <code>iris</code> example, we use <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a> to directly create a dataset from the underlying R matrices <code>x_train</code> and <code>y_train</code>.</p>
<p>However, a wide variety of other <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-creating-datasets">dataset creation</a> functions is available.
Datasets also allow for a variety of pre-processing <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-transforming-datasets">transformations</a>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">x_train &lt;-</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">y_train &lt;-</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="co"># Convert to approriate tensor floating point type for backend</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">x_train &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(x_train)</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">y_train &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(y_train)</a>
<a class="sourceLine" id="cb10-9" data-line-number="9"></a>
<a class="sourceLine" id="cb10-10" data-line-number="10"><span class="co"># same for test set</span></a>
<a class="sourceLine" id="cb10-11" data-line-number="11">x_test &lt;-</a>
<a class="sourceLine" id="cb10-12" data-line-number="12"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb10-13" data-line-number="13">y_test &lt;-</a>
<a class="sourceLine" id="cb10-14" data-line-number="14"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb10-15" data-line-number="15">x_test &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(x_test)</a>
<a class="sourceLine" id="cb10-16" data-line-number="16">y_test &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(y_test)</a>
<a class="sourceLine" id="cb10-17" data-line-number="17"></a>
<a class="sourceLine" id="cb10-18" data-line-number="18"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tfdatasets)</a>
<a class="sourceLine" id="cb10-19" data-line-number="19">train_dataset &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span> (x_train, y_train)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-20" data-line-number="20"><span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb10-21" data-line-number="21">test_dataset &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span> (x_test, y_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb10-22" data-line-number="22"><span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">10</span>)</a></code></pre></div>
<p>Data is accessed from a dataset via <code>make_iterator_one_shot</code> (to create an iterator) and <code>iterator_get_next</code> (to obtain the next batch).</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">iter &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/make-iterator.html">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">batch &lt;-<span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/iterator_get_next.html">iterator_get_next</a></span>(iter)</a></code></pre></div>
<p>Datasets are available in non-eager (graph) execution as well. However, in eager mode, we can examine the actual values returned from the iterator:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">batch</a></code></pre></div>
<pre><code>[[1]]
tf.Tensor(
[[1.4 5.1 0.2]
 [1.4 4.9 0.2]
 [1.3 4.7 0.2]
 [1.5 4.6 0.2]
 [1.4 5.  0.2]
 [1.7 5.4 0.4]
 [1.4 4.6 0.3]
 [1.5 5.  0.2]
 [1.4 4.4 0.2]
 [1.5 4.9 0.1]], shape=(10, 3), dtype=float32)

[[2]]
tf.Tensor(
[[3.5]
 [3. ]
 [3.2]
 [3.1]
 [3.6]
 [3.9]
 [3.4]
 [3.4]
 [2.9]
 [3.1]], shape=(10, 1), dtype=float32)</code></pre>
</div>
<div id="training-loop" class="section level2">
<h2>Training loop</h2>
<p>With eager execution, you take full control over the training process.</p>
<p>In general, you will have at least two loops: an outer loop over epochs, and an inner loop over batches of data returned by the iterator (implemented implicitly by <code>until_out_of_range</code>).
The iterator is recreated at the start of each new epoch.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2"></a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(n_epochs)) {</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">  </a>
<a class="sourceLine" id="cb14-5" data-line-number="5">  iter &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/make-iterator.html">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb14-6" data-line-number="6">  total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7">  </a>
<a class="sourceLine" id="cb14-8" data-line-number="8">  <span class="kw"><a href="../../tools/tfdatasets/reference/until_out_of_range.html">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">    </a>
<a class="sourceLine" id="cb14-10" data-line-number="10">    <span class="co"># get a new batch and run forward pass on it </span></a>
<a class="sourceLine" id="cb14-11" data-line-number="11">    </a>
<a class="sourceLine" id="cb14-12" data-line-number="12">    <span class="co"># calculate loss </span></a>
<a class="sourceLine" id="cb14-13" data-line-number="13">    </a>
<a class="sourceLine" id="cb14-14" data-line-number="14">    <span class="co"># calculate gradients of loss w.r.t. model weights</span></a>
<a class="sourceLine" id="cb14-15" data-line-number="15">    </a>
<a class="sourceLine" id="cb14-16" data-line-number="16">    <span class="co"># update model weights</span></a>
<a class="sourceLine" id="cb14-17" data-line-number="17">    </a>
<a class="sourceLine" id="cb14-18" data-line-number="18">  })</a>
<a class="sourceLine" id="cb14-19" data-line-number="19">  </a>
<a class="sourceLine" id="cb14-20" data-line-number="20">  <span class="kw"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="st">"Total loss (epoch): "</span>, i, <span class="st">": "</span>, <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(total_loss), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb14-21" data-line-number="21">}</a></code></pre></div>
<p>Filling in the missing pieces in the above outline, we will see that</p>
<ul>
<li>Forward propagation is simply a call to <code>model()</code>.</li>
<li>This call has to happen inside the context of a <code>GradientTape</code> that records all operations.</li>
<li>Loss is calculated using the loss function defined before.</li>
<li>From the loss on the one hand and the model’s current weights on the other hand, <code>GradientTape</code> then determines the gradients.</li>
<li>Finally, the optimizer applies the gradients to the weights in its algorithm-specific way.</li>
</ul>
<p>Here is the complete code for the training loop:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2"></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="co"># loop over epochs</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(n_epochs)) {</a>
<a class="sourceLine" id="cb15-5" data-line-number="5">  </a>
<a class="sourceLine" id="cb15-6" data-line-number="6">  <span class="co"># create fresh iterator from dataset</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7">  iter &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/make-iterator.html">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb15-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb15-9" data-line-number="9">  <span class="co"># accumulate current epoch's loss (for display purposes only)</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10">  total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb15-11" data-line-number="11">  </a>
<a class="sourceLine" id="cb15-12" data-line-number="12">  <span class="co"># loop once through the dataset</span></a>
<a class="sourceLine" id="cb15-13" data-line-number="13">  <span class="kw"><a href="../../tools/tfdatasets/reference/until_out_of_range.html">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb15-14" data-line-number="14">    </a>
<a class="sourceLine" id="cb15-15" data-line-number="15">    <span class="co"># get next batch</span></a>
<a class="sourceLine" id="cb15-16" data-line-number="16">    batch &lt;-<span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/iterator_get_next.html">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb15-17" data-line-number="17">    x &lt;-<span class="st"> </span>batch[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb15-18" data-line-number="18">    y &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb15-19" data-line-number="19">    </a>
<a class="sourceLine" id="cb15-20" data-line-number="20">    <span class="co"># forward pass is recorded by tf$GradientTape</span></a>
<a class="sourceLine" id="cb15-21" data-line-number="21">    <span class="kw"><a href="https://rdrr.io/r/base/with.html">with</a></span>(tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>tape, {</a>
<a class="sourceLine" id="cb15-22" data-line-number="22">     </a>
<a class="sourceLine" id="cb15-23" data-line-number="23">      <span class="co"># run model on current batch</span></a>
<a class="sourceLine" id="cb15-24" data-line-number="24">      preds &lt;-<span class="st"> </span><span class="kw">model</span>(x)</a>
<a class="sourceLine" id="cb15-25" data-line-number="25">     </a>
<a class="sourceLine" id="cb15-26" data-line-number="26">      <span class="co"># compute the loss</span></a>
<a class="sourceLine" id="cb15-27" data-line-number="27">      loss &lt;-<span class="st"> </span><span class="kw">mse_loss</span>(y, preds, x)</a>
<a class="sourceLine" id="cb15-28" data-line-number="28">    })</a>
<a class="sourceLine" id="cb15-29" data-line-number="29">    </a>
<a class="sourceLine" id="cb15-30" data-line-number="30">    <span class="co"># update total loss</span></a>
<a class="sourceLine" id="cb15-31" data-line-number="31">    total_loss &lt;-<span class="st"> </span>total_loss <span class="op">+</span><span class="st"> </span>loss</a>
<a class="sourceLine" id="cb15-32" data-line-number="32">    </a>
<a class="sourceLine" id="cb15-33" data-line-number="33">    <span class="co"># get gradients of loss w.r.t. model weights</span></a>
<a class="sourceLine" id="cb15-34" data-line-number="34">    gradients &lt;-<span class="st"> </span>tape<span class="op">$</span><span class="kw">gradient</span>(loss, model<span class="op">$</span>variables)</a>
<a class="sourceLine" id="cb15-35" data-line-number="35">    </a>
<a class="sourceLine" id="cb15-36" data-line-number="36">    <span class="co"># update model weights</span></a>
<a class="sourceLine" id="cb15-37" data-line-number="37">    optimizer<span class="op">$</span><span class="kw">apply_gradients</span>(</a>
<a class="sourceLine" id="cb15-38" data-line-number="38">      purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/transpose.html">transpose</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(gradients, model<span class="op">$</span>variables)),</a>
<a class="sourceLine" id="cb15-39" data-line-number="39">      <span class="dt">global_step =</span> tf<span class="op">$</span>train<span class="op">$</span><span class="kw">get_or_create_global_step</span>()</a>
<a class="sourceLine" id="cb15-40" data-line-number="40">    )</a>
<a class="sourceLine" id="cb15-41" data-line-number="41"></a>
<a class="sourceLine" id="cb15-42" data-line-number="42">  })</a>
<a class="sourceLine" id="cb15-43" data-line-number="43">  </a>
<a class="sourceLine" id="cb15-44" data-line-number="44">  <span class="kw"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="st">"Total loss (epoch): "</span>, i, <span class="st">": "</span>, <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(total_loss), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb15-45" data-line-number="45">}</a></code></pre></div>
</div>
<div id="predictions-on-the-test-set" class="section level2">
<h2>Predictions on the test set</h2>
<p>Getting predictions on the test set is just a call to <code>model</code>, just like training has been.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">model</span>(x_test)</a></code></pre></div>
</div>
<div id="saving-and-restoring-model-weights" class="section level2">
<h2>Saving and restoring model weights</h2>
<p>To save model weights, create an instance of <code>tf$Checkpoint</code> and pass it the objects to be saved: in our case, the <code>model</code> and the <code>optimizer</code>.
This has to happen after the respective objects have been created, but before the training loop.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">checkpoint_dir &lt;-<span class="st"> "./checkpoints"</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2">checkpoint_prefix &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(checkpoint_dir, <span class="st">"ckpt"</span>)</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">checkpoint &lt;-</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="st">  </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Checkpoint</span>(</a>
<a class="sourceLine" id="cb17-5" data-line-number="5">    <span class="dt">optimizer =</span> optimizer,</a>
<a class="sourceLine" id="cb17-6" data-line-number="6">    <span class="dt">model =</span> model</a>
<a class="sourceLine" id="cb17-7" data-line-number="7">  )</a></code></pre></div>
<p>Then at the end of each epoch, you save the model’s current weights, like so:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">checkpoint<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/save.html">save</a></span>(<span class="dt">file_prefix =</span> checkpoint_prefix)</a></code></pre></div>
<p>This call saves model weights only, not the complete graph. Thus on restore, you re-create all components in the same way as above, and then load saved the model weights using e.g.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co"># restore from recent checkpoint, you can also use a different one</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2">checkpoint<span class="op">$</span><span class="kw">restore</span>(tf<span class="op">$</span>train<span class="op">$</span><span class="kw">latest_checkpoint</span>(checkpoint_dir))</a></code></pre></div>
<p>You can then obtain predictions from the restored model, on the test set as a whole or batch-wise, using an iterator.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">model</span>(x_test)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"></a>
<a class="sourceLine" id="cb20-3" data-line-number="3">iter &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/make-iterator.html">make_iterator_one_shot</a></span>(test_dataset)</a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="kw"><a href="../../tools/tfdatasets/reference/until_out_of_range.html">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb20-5" data-line-number="5">  batch &lt;-<span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/iterator_get_next.html">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb20-6" data-line-number="6">  preds &lt;-<span class="st"> </span><span class="kw">model</span>(batch[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb20-7" data-line-number="7">  <span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(preds)</a>
<a class="sourceLine" id="cb20-8" data-line-number="8">})</a></code></pre></div>
</div>
<div id="complete-example" class="section level2">
<h2>Complete example</h2>
<p>Here is the complete example.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(keras)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="kw"><a href="../../keras/reference/use_implementation.html">use_implementation</a></span>(<span class="st">"tensorflow"</span>)</a>
<a class="sourceLine" id="cb21-3" data-line-number="3"></a>
<a class="sourceLine" id="cb21-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tensorflow)</a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="kw"><a href="../../tensorflow/reference/tfe_enable_eager_execution.html">tfe_enable_eager_execution</a></span>(<span class="dt">device_policy =</span> <span class="st">"silent"</span>)</a>
<a class="sourceLine" id="cb21-6" data-line-number="6"></a>
<a class="sourceLine" id="cb21-7" data-line-number="7"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tfdatasets)</a>
<a class="sourceLine" id="cb21-8" data-line-number="8"></a>
<a class="sourceLine" id="cb21-9" data-line-number="9"></a>
<a class="sourceLine" id="cb21-10" data-line-number="10"><span class="co"># Prepare training and test sets ------------------------------------------</span></a>
<a class="sourceLine" id="cb21-11" data-line-number="11"></a>
<a class="sourceLine" id="cb21-12" data-line-number="12">x_train &lt;-</a>
<a class="sourceLine" id="cb21-13" data-line-number="13"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb21-14" data-line-number="14">x_train &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(x_train)</a>
<a class="sourceLine" id="cb21-15" data-line-number="15">y_train &lt;-</a>
<a class="sourceLine" id="cb21-16" data-line-number="16"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb21-17" data-line-number="17">y_train &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(y_train)</a>
<a class="sourceLine" id="cb21-18" data-line-number="18"></a>
<a class="sourceLine" id="cb21-19" data-line-number="19">x_test &lt;-</a>
<a class="sourceLine" id="cb21-20" data-line-number="20"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb21-21" data-line-number="21">x_test &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(x_test)</a>
<a class="sourceLine" id="cb21-22" data-line-number="22">y_test &lt;-</a>
<a class="sourceLine" id="cb21-23" data-line-number="23"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb21-24" data-line-number="24">y_test &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/k_constant.html">k_constant</a></span>(y_test)</a>
<a class="sourceLine" id="cb21-25" data-line-number="25"></a>
<a class="sourceLine" id="cb21-26" data-line-number="26"></a>
<a class="sourceLine" id="cb21-27" data-line-number="27"></a>
<a class="sourceLine" id="cb21-28" data-line-number="28"><span class="co"># Create datasets for training and testing --------------------------------</span></a>
<a class="sourceLine" id="cb21-29" data-line-number="29"></a>
<a class="sourceLine" id="cb21-30" data-line-number="30">train_dataset &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span> (x_train, y_train)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-31" data-line-number="31"><span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb21-32" data-line-number="32">test_dataset &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span> (x_test, y_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-33" data-line-number="33"><span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb21-34" data-line-number="34"></a>
<a class="sourceLine" id="cb21-35" data-line-number="35"></a>
<a class="sourceLine" id="cb21-36" data-line-number="36"><span class="co"># Create model ------------------------------------------------------------</span></a>
<a class="sourceLine" id="cb21-37" data-line-number="37"></a>
<a class="sourceLine" id="cb21-38" data-line-number="38">iris_regression_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb21-39" data-line-number="39">  <span class="kw"><a href="../../keras/reference/keras_model_custom.html">keras_model_custom</a></span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</a>
<a class="sourceLine" id="cb21-40" data-line-number="40">    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">input_shape =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb21-41" data-line-number="41">    self<span class="op">$</span>dropout &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/layer_dropout.html">layer_dropout</a></span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb21-42" data-line-number="42">    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw"><a href="../../keras/reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb21-43" data-line-number="43">    </a>
<a class="sourceLine" id="cb21-44" data-line-number="44">    <span class="cf">function</span> (x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb21-45" data-line-number="45">      self<span class="op">$</span><span class="kw">dense1</span>(x) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-46" data-line-number="46"><span class="st">        </span>self<span class="op">$</span><span class="kw">dropout</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-47" data-line-number="47"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>()</a>
<a class="sourceLine" id="cb21-48" data-line-number="48">    }</a>
<a class="sourceLine" id="cb21-49" data-line-number="49">  })</a>
<a class="sourceLine" id="cb21-50" data-line-number="50">}</a>
<a class="sourceLine" id="cb21-51" data-line-number="51"></a>
<a class="sourceLine" id="cb21-52" data-line-number="52">model &lt;-<span class="st"> </span><span class="kw">iris_regression_model</span>()</a>
<a class="sourceLine" id="cb21-53" data-line-number="53"></a>
<a class="sourceLine" id="cb21-54" data-line-number="54"></a>
<a class="sourceLine" id="cb21-55" data-line-number="55"><span class="co"># Define loss function and optimizer --------------------------------------</span></a>
<a class="sourceLine" id="cb21-56" data-line-number="56"></a>
<a class="sourceLine" id="cb21-57" data-line-number="57">mse_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, x) {</a>
<a class="sourceLine" id="cb21-58" data-line-number="58">  mse &lt;-<span class="st"> </span>tf<span class="op">$</span>losses<span class="op">$</span><span class="kw">mean_squared_error</span>(y_true, y_pred)</a>
<a class="sourceLine" id="cb21-59" data-line-number="59">  mse</a>
<a class="sourceLine" id="cb21-60" data-line-number="60">}</a>
<a class="sourceLine" id="cb21-61" data-line-number="61"></a>
<a class="sourceLine" id="cb21-62" data-line-number="62">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">AdamOptimizer</span>()</a>
<a class="sourceLine" id="cb21-63" data-line-number="63"></a>
<a class="sourceLine" id="cb21-64" data-line-number="64"></a>
<a class="sourceLine" id="cb21-65" data-line-number="65"><span class="co"># Set up checkpointing ----------------------------------------------------</span></a>
<a class="sourceLine" id="cb21-66" data-line-number="66"></a>
<a class="sourceLine" id="cb21-67" data-line-number="67">checkpoint_dir &lt;-<span class="st"> "./checkpoints"</span></a>
<a class="sourceLine" id="cb21-68" data-line-number="68">checkpoint_prefix &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(checkpoint_dir, <span class="st">"ckpt"</span>)</a>
<a class="sourceLine" id="cb21-69" data-line-number="69">checkpoint &lt;-</a>
<a class="sourceLine" id="cb21-70" data-line-number="70"><span class="st">  </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Checkpoint</span>(<span class="dt">optimizer =</span> optimizer,</a>
<a class="sourceLine" id="cb21-71" data-line-number="71">                      <span class="dt">model =</span> model)</a>
<a class="sourceLine" id="cb21-72" data-line-number="72"></a>
<a class="sourceLine" id="cb21-73" data-line-number="73">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb21-74" data-line-number="74"></a>
<a class="sourceLine" id="cb21-75" data-line-number="75"><span class="co"># change to TRUE if you want to restore weights</span></a>
<a class="sourceLine" id="cb21-76" data-line-number="76">restore &lt;-<span class="st"> </span><span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb21-77" data-line-number="77"></a>
<a class="sourceLine" id="cb21-78" data-line-number="78"><span class="cf">if</span> (<span class="op">!</span>restore) {</a>
<a class="sourceLine" id="cb21-79" data-line-number="79">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(n_epochs)) {</a>
<a class="sourceLine" id="cb21-80" data-line-number="80">    iter &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/make-iterator.html">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb21-81" data-line-number="81">    total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb21-82" data-line-number="82">    </a>
<a class="sourceLine" id="cb21-83" data-line-number="83">    <span class="kw"><a href="../../tools/tfdatasets/reference/until_out_of_range.html">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb21-84" data-line-number="84">      batch &lt;-<span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/iterator_get_next.html">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb21-85" data-line-number="85">      x &lt;-<span class="st"> </span>batch[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb21-86" data-line-number="86">      y &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb21-87" data-line-number="87">      </a>
<a class="sourceLine" id="cb21-88" data-line-number="88">      <span class="kw"><a href="https://rdrr.io/r/base/with.html">with</a></span>(tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>tape, {</a>
<a class="sourceLine" id="cb21-89" data-line-number="89">        preds &lt;-<span class="st"> </span><span class="kw">model</span>(x)</a>
<a class="sourceLine" id="cb21-90" data-line-number="90">        loss &lt;-<span class="st"> </span><span class="kw">mse_loss</span>(y, preds, x)</a>
<a class="sourceLine" id="cb21-91" data-line-number="91">      })</a>
<a class="sourceLine" id="cb21-92" data-line-number="92">      </a>
<a class="sourceLine" id="cb21-93" data-line-number="93">      total_loss &lt;-<span class="st"> </span>total_loss <span class="op">+</span><span class="st"> </span>loss</a>
<a class="sourceLine" id="cb21-94" data-line-number="94">      gradients &lt;-<span class="st"> </span>tape<span class="op">$</span><span class="kw">gradient</span>(loss, model<span class="op">$</span>variables)</a>
<a class="sourceLine" id="cb21-95" data-line-number="95">      </a>
<a class="sourceLine" id="cb21-96" data-line-number="96">      optimizer<span class="op">$</span><span class="kw">apply_gradients</span>(purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/transpose.html">transpose</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(gradients, model<span class="op">$</span>variables)),</a>
<a class="sourceLine" id="cb21-97" data-line-number="97">                                <span class="dt">global_step =</span> tf<span class="op">$</span>train<span class="op">$</span><span class="kw">get_or_create_global_step</span>())</a>
<a class="sourceLine" id="cb21-98" data-line-number="98">      </a>
<a class="sourceLine" id="cb21-99" data-line-number="99">    })</a>
<a class="sourceLine" id="cb21-100" data-line-number="100">    </a>
<a class="sourceLine" id="cb21-101" data-line-number="101">    <span class="kw"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="st">"Total loss (epoch): "</span>, i, <span class="st">": "</span>, <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(total_loss), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb21-102" data-line-number="102">    </a>
<a class="sourceLine" id="cb21-103" data-line-number="103">    checkpoint<span class="op">$</span><span class="kw"><a href="https://rdrr.io/r/base/save.html">save</a></span>(<span class="dt">file_prefix =</span> checkpoint_prefix)</a>
<a class="sourceLine" id="cb21-104" data-line-number="104">  }</a>
<a class="sourceLine" id="cb21-105" data-line-number="105">} <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb21-106" data-line-number="106">  checkpoint<span class="op">$</span><span class="kw">restore</span>(tf<span class="op">$</span>train<span class="op">$</span><span class="kw">latest_checkpoint</span>(checkpoint_dir))</a>
<a class="sourceLine" id="cb21-107" data-line-number="107">}</a>
<a class="sourceLine" id="cb21-108" data-line-number="108"></a>
<a class="sourceLine" id="cb21-109" data-line-number="109"></a>
<a class="sourceLine" id="cb21-110" data-line-number="110"><span class="co"># Get model predictions on test set ---------------------------------------</span></a>
<a class="sourceLine" id="cb21-111" data-line-number="111"></a>
<a class="sourceLine" id="cb21-112" data-line-number="112"><span class="kw">model</span>(x_test)</a>
<a class="sourceLine" id="cb21-113" data-line-number="113"></a>
<a class="sourceLine" id="cb21-114" data-line-number="114">iter &lt;-<span class="st"> </span><span class="kw"><a href="../../tools/tfdatasets/reference/make-iterator.html">make_iterator_one_shot</a></span>(test_dataset)</a>
<a class="sourceLine" id="cb21-115" data-line-number="115"><span class="kw"><a href="../../tools/tfdatasets/reference/until_out_of_range.html">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb21-116" data-line-number="116">  batch &lt;-<span class="st">  </span><span class="kw"><a href="../../tools/tfdatasets/reference/iterator_get_next.html">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb21-117" data-line-number="117">  preds &lt;-<span class="st"> </span><span class="kw">model</span>(batch[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb21-118" data-line-number="118">  <span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(preds)</a>
<a class="sourceLine" id="cb21-119" data-line-number="119">})</a></code></pre></div>
</div>
<div id="where-to-from-here" class="section level2">
<h2>Where to from here</h2>
<p>In this guide, the task - and consequently, the custom model, associated loss and training routine - have been chosen for their simplicity.
Visit the <a href="https://blogs.rstudio.com/tensorflow/">TensorFlow for R blog</a> for case studies and paper implementations that use more intricate custom logic.</p>
</div>
