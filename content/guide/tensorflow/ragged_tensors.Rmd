---
title: "Ragged tensors"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TensorFlow variables} 
  %\VignetteEngine{knitr::rmarkdown} 
  %\VignetteEncoding{UTF-8}
type: "docs"
menu:
  main:
    name: "Ragged tensors"
    identifier: "custom-advanced-ragged"
    parent: "custom-advanced-top"
    weight: 10
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE)
```

## Overview

Your data comes in many shapes; your tensors should too.
*Ragged tensors* are the TensorFlow equivalent of nested variable-length
lists. They make it easy to store and process data with non-uniform shapes,
including:

*   Variable-length features, such as the set of actors in a movie.
*   Batches of variable-length sequential inputs, such as sentences or video
    clips.
*   Hierarchical inputs, such as text documents that are subdivided into
    sections, paragraphs, sentences, and words.
*   Individual fields in structured inputs, such as protocol buffers.

### What you can do with a ragged tensor

Ragged tensors are supported by more than a hundred TensorFlow operations,
including math operations (such as `tf$add` and `tf$reduce_mean`), array operations
(such as `tf$concat` and `tf$tile`), string manipulation ops (such as
`tf$substr`), and many others:

```{r}
library(tensorflow)
digits <- tf$ragged$constant(
  list(list(3, 1, 4, 1), list(), list(5, 9, 2), list(6), list())
)
words = tf$ragged$constant(
  list(list("So", "long"), list("thanks", "for", "all", "the", "fish"))
)
tf$add(digits, 3)
tf$reduce_mean(digits, axis=1L)
tf$concat(list(digits, list(list(5, 3))), axis=0L)
tf$tile(digits, list(1L, 2L))
tf$strings$substr(words, 0L, 2L)
```

There are also a number of methods and operations that are
specific to ragged tensors, including factory methods, conversion methods,
and value-mapping operations.

As with normal tensors, you can use R-style indexing to access specific
slices of a ragged tensor. For more information, see the section on
**Indexing** below.

```{r}
digits[1,] # First row
```

```{r}
digits[, 1:2]   # First two values in each row.
```

```{r}
digits[, `-2:`]  # Last two values in each row.
```

And just like normal tensors, you can use Python arithmetic and comparison operators to perform 
elementwise operations. For more information, see the section on Overloaded Operators below.

```{r}
digits + 3
```

```{r}
digits + tf$ragged$constant(list(list(1, 2, 3, 4), list(), list(5, 6, 7), list(8), list()))
```

If you need to perform an elementwise transformation to the values of a RaggedTensor, you can use `tf$ragged$map_flat_values`, which takes a function plus one or more arguments, and applies the function to transform the RaggedTensor's values.

```{r}
times_two_plus_one <- function(x) {
  2*x + 1
}
tf$ragged$map_flat_values(times_two_plus_one, digits)
```

### Constructing a ragged tensor

The simplest way to construct a ragged tensor is using
`tf$ragged$constant`, which builds the
`RaggedTensor` corresponding to a given nested `list`:

```{r}
sentences <- tf$ragged$constant(list(
    list("Let's", "build", "some", "ragged", "tensors", "!"),
    list("We", "can", "use", "tf.ragged.constant", ".")))
```

```{r}
paragraphs <- tf$ragged$constant(list(
    list(list('I', 'have', 'a', 'cat'), list('His', 'name', 'is', 'Mat')),
    list(list('Do', 'you', 'want', 'to', 'come', 'visit'), list("I'm", 'free', 'tomorrow'))
))
paragraphs
```

Ragged tensors can also be constructed by pairing flat *values* tensors with
*row-partitioning* tensors indicating how those values should be divided into
rows, using factory classmethods such as `tf$RaggedTensor$from_value_rowids`,
`tf$RaggedTensor$from_row_lengths`, and
`tf$RaggedTensor$from_row_splits`.

#### `tf$RaggedTensor$from_value_rowids`

If you know which row each value belongs in, then you can build a `RaggedTensor` using a `value_rowids` row-partitioning tensor:

![](../images/value_rowids.png)

```{r}
tf$RaggedTensor$from_value_rowids(
    values=as.integer(c(3, 1, 4, 1, 5, 9, 2, 6)),
    value_rowids=as.integer(c(0, 0, 0, 0, 2, 2, 2, 3)))
```

#### `tf.RaggedTensor.from_row_lengths`

If you know how long each row is, then you can use a `row_lengths` row-partitioning tensor:

![](../images/row_lengths.png)

```{r}
tf$RaggedTensor$from_row_lengths(
    values=as.integer(c(3, 1, 4, 1, 5, 9, 2, 6)),
    row_lengths=as.integer(c(4, 0, 3, 1)))
```

#### `tf.RaggedTensor.from_row_splits`

If you know the index where each row starts and ends, then you can use a `row_splits` row-partitioning tensor:

![row_splits](../images/row_splits.png)

```{r}
tf$RaggedTensor$from_row_splits(
    values=as.integer(c(3, 1, 4, 1, 5, 9, 2, 6)),
    row_splits=as.integer(c(0, 4, 4, 7, 8)))
```

See the `tf.RaggedTensor` class documentation for a full list of factory methods.

### What you can store in a ragged tensor

As with normal `Tensor`s, the values in a `RaggedTensor` must all have the same
type; and the values must all be at the same nesting depth (the *rank* of the
tensor):

```{r}
tf$ragged$constant(list(list("Hi"), list("How", "are", "you"))) # ok: type=string, rank=2
```

```{r, eval=FALSE}
tf$ragged$constant(list(list("one", "two"), list(3, 4))) # bad: multiple types
```

```{r, eval = FALSE}
tf$ragged$constant(list("A", list("B", "C"))) # bad: multiple nesting depths
```

This is a small introduction to Ragged Tensors in TensorFlow. See the complete tutorial (in Python) [here](https://www.tensorflow.org/guide/ragged_tensor).