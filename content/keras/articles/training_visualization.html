---
title: "Training Visualization"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Training Visualization}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Training Visualization"
    identifier: "keras-training-visualization"
    parent: "keras-using-keras"
    weight: 50
---



<div id="overview" class="section level2">
<h2>Overview</h2>
<p>There are a number of tools available for visualizing the training of Keras models, including:</p>
<ol style="list-style-type: decimal">
<li><p>A <a href="https://keras.rstudio.com/reference/plot.keras_training_history.html">plot method</a> for the Keras training history returned from <code>fit()</code>.</p></li>
<li><p>Real time visualization of training metrics within the RStudio IDE.</p></li>
<li><p>Integration with the <a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard">TensorBoard</a> visualization tool included with TensorFlow. Beyond just training metrics, TensorBoard has a wide variety of other visualizations available including the underlying TensorFlow graph, gradient histograms, model weights, and more. TensorBoard also enables you to compare metrics across multiple training runs.</p></li>
</ol>
<p>Each of these tools is described in more detail below.</p>
</div>
<div id="plotting-history" class="section level2">
<h2>Plotting History</h2>
<p>The Keras <code>fit()</code> method returns an R object containing the training history, including the value of metrics at the end of each epoch . You can plot the training metrics by epoch using the <code><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot()</a></code> method.</p>
<p>For example, here we compile and fit a model with the “accuracy” metric:</p>
<pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(),
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'accuracy'</span>)
)

history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(
  x_train, y_train, 
  <span class="dt">epochs =</span> <span class="dv">30</span>, <span class="dt">batch_size =</span> <span class="dv">128</span>, 
  <span class="dt">validation_split =</span> <span class="fl">0.2</span>
)</code></pre>
<p>We can then plot the training history as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot</a></span>(history)</code></pre>
<p><img src="images/training_history_ggplot2.png" class="r-plot" width="757" height="489"></p>
<p>The history will be plotted using <a href="http://ggplot2.tidyverse.org/">ggplot2</a> if available (if not then base graphics will be used), include all specified metrics as well as the loss, and draw a smoothing line if there are 10 or more epochs. You can customize all of this behavior via various options of the <a href="https://keras.rstudio.com/reference/plot.keras_training_history.html">plot method</a>.</p>
<p>If you want to create a custom visualization you can call the <code><a href="https://www.rdocumentation.org/packages/base/topics/as.data.frame">as.data.frame()</a></code> method on the history to obtain a data frame with factors for each metric as well as training vs. validation:</p>
<pre class="sourceCode r"><code class="sourceCode r">history_df &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/as.data.frame">as.data.frame</a></span>(history)
<span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/str">str</a></span>(history_df)</code></pre>
<pre><code>'data.frame':   120 obs. of  4 variables:
 $ epoch : int  1 2 3 4 5 6 7 8 9 10 ...
 $ value : num  0.87 0.941 0.954 0.962 0.965 ...
 $ metric: Factor w/ 2 levels "acc","loss": 1 1 1 1 1 1 1 1 1 1 ...
 $ data  : Factor w/ 2 levels "training","validation": 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
</div>
<div id="rstudio-ide" class="section level2">
<h2>RStudio IDE</h2>
<p>If you are training your model within the RStudio IDE then real time metrics are available within the Viewer pane:</p>
<a id="rstudiohistory" href="https://rstudioblog.files.wordpress.com/2017/08/rstudio-training-metrics-full.gif"></a>
<script type="application/javascript">
function isMobilePhone() {
  try { return ! window.matchMedia("only screen and (min-width: 768px)").matches; }
  catch(e) { return false; }
}
var a = document.getElementById("rstudiohistory");
var img = document.createElement("IMG");
img.className = "r-plot";
img.width = 640;
img.height = 502;
if (!isMobilePhone()) {
  img.src = "https://i1.wp.com/rstudioblog.files.wordpress.com/2017/08/rstudio-training-metrics.gif";
} else {
  a.href = '';
  img.src = "https://i0.wp.com/rstudioblog.files.wordpress.com/2017/08/rstudio-training-metrics-mobile.png";
}
a.appendChild(img);
</script><p>The <code>view_metrics</code> argument of the <code>fit()</code> method controls whether real time metrics are displayed. By default metrics are automatically displayed if one or more metrics are specified in the call to <code>compile()</code> and there is more than one training epoch.</p>
<p>You can explicitly control whether metrics are displayed by specifying the <code>view_metrics</code> argument. You can also set a global session default using the <code>keras.view_metrics</code> option:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># don't show metrics during this run</span>
history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(
  x_train, y_train, 
  <span class="dt">epochs =</span> <span class="dv">30</span>, <span class="dt">batch_size =</span> <span class="dv">128</span>, 
  <span class="dt">view_metrics =</span> <span class="ot">FALSE</span>,
  <span class="dt">validation_split =</span> <span class="fl">0.2</span>
)

<span class="co"># set global default to never show metrics</span>
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/options">options</a></span>(<span class="dt">keras.view_metrics =</span> <span class="ot">FALSE</span>)</code></pre>
<p>Note that when <code>view_metrics</code> is <code>TRUE</code> metrics will be displayed even when not running within RStudio (in that case metrics will be displayed in an external web browser).</p>
</div>
<div id="tensorboard" class="section level2">
<h2>TensorBoard</h2>
<p>TensorBoard is a visualization tool included with TensorFlow that enables you to visualize dynamic graphs of your Keras training and test metrics, as well as activation histograms for the different layers in your model.</p>
<p>For example, here’s a TensorBoard display for Keras accuracy and loss metrics:</p>
<p><img src="images/tensorboard.png" class="screenshot" width="700" height="545"></p>
<div id="recording-data" class="section level3">
<h3>Recording Data</h3>
<p>To record data that can be visualized with TensorBoard, you add a TensorBoard callback to the <code>fit()</code> function. For example:</p>
<pre class="sourceCode r"><code class="sourceCode r">history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(
  x_train, y_train,
  <span class="dt">batch_size =</span> batch_size,
  <span class="dt">epochs =</span> epochs,
  <span class="dt">verbose =</span> <span class="dv">1</span>,
  <span class="dt">callbacks =</span> <span class="kw">callback_tensorboard</span>(<span class="st">"logs/run_a"</span>),
  <span class="dt">validation_split =</span> <span class="fl">0.2</span>
)</code></pre>
<p>See the documentation on the <code>callback_tensorboard()</code> function for the various available options. The most important option is the <code>log_dir</code>, which determines which directory logs are written to for a given training run.</p>
<p>You should either use a distinct log directory for each training run or remove the log directory between runs.</p>
</div>
<div id="viewing-data" class="section level3">
<h3>Viewing Data</h3>
<p>To view TensorBoard data for a given set of runs you use the <code>tensorboard()</code> function, pointing it to the previously specified <code>log_dir</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tensorboard</span>(<span class="st">"logs/run_a"</span>)</code></pre>
<p>It’s often useful to run TensorBoard while you are training a model. To do this, simply launch tensorboard within the training directory right before you begin training:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># launch TensorBoard (data won't show up until after the first epoch)</span>
<span class="kw">tensorboard</span>(<span class="st">"logs/run_a"</span>)

<span class="co"># fit the model with the TensorBoard callback</span>
history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(
  x_train, y_train,
  <span class="dt">batch_size =</span> batch_size,
  <span class="dt">epochs =</span> epochs,
  <span class="dt">verbose =</span> <span class="dv">1</span>,
  <span class="dt">callbacks =</span> <span class="kw">callback_tensorboard</span>(<span class="st">"logs/run_a"</span>),
  <span class="dt">validation_split =</span> <span class="fl">0.2</span>
)</code></pre>
<p>Keras writes TensorBoard data at the end of each epoch so you won’t see any data in TensorBoard until 10-20 seconds after the end of the first epoch (TensorBoard automatically refreshes it’s display every 30 seconds during training).</p>
</div>
<div id="comparing-runs" class="section level3">
<h3>Comparing Runs</h3>
<p>TensorBoard will automatically include all runs logged within the sub-directories of the specified <code>log_dir</code>, for example, if you logged another run using:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">callback_tensorboard</span>(<span class="dt">log_dir =</span> <span class="st">"logs/run_b"</span>)</code></pre>
<p>Then called tensorboard as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tensorboard</span>(<span class="st">"logs"</span>)</code></pre>
<p>The TensorBoard visualization would look like this:</p>
<p><img src="images/tensorboard_compare.png" class="screenshot" width="700" height="540"></p>
<p>You can also pass multiple log directories. For example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tensorboard</span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"logs/run_a"</span>, <span class="st">"logs/run_b"</span>))</code></pre>
</div>
<div id="customization" class="section level3">
<h3>Customization</h3>
<div id="metrics" class="section level4">
<h4>Metrics</h4>
<p>In the above examples TensorBoard metrics are logged for loss and accuracy. The TensorBoard callback will log data for any metrics which are specified in the <code>metrics</code> parameter of the <code>compile()</code> function. For example, in the following code:</p>
<pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(
  <span class="dt">loss =</span> <span class="st">'mean_squared_error'</span>,
  <span class="dt">optimizer =</span> <span class="st">'sgd'</span>,
  <span class="dt">metrics=</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'mae'</span>, <span class="st">'acc'</span>)
)</code></pre>
<p>TensorBoard data series will be created for the loss (mean squared error) as well as for the mean absolute error and accuracy metrics.</p>
</div>
<div id="options" class="section level4">
<h4>Options</h4>
<p>The <code>callback_tensorboard()</code> function includes a number of other options that control logging during training:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">callback_tensorboard</span>(<span class="dt">log_dir =</span> <span class="st">"logs"</span>, <span class="dt">histogram_freq =</span> <span class="dv">0</span>,
  <span class="dt">write_graph =</span> <span class="ot">TRUE</span>, <span class="dt">write_images =</span> <span class="ot">FALSE</span>, <span class="dt">embeddings_freq =</span> <span class="dv">0</span>,
  <span class="dt">embeddings_layer_names =</span> <span class="ot">NULL</span>, <span class="dt">embeddings_metadata =</span> <span class="ot">NULL</span>)</code></pre>
<table>
<colgroup>
<col width="20%">
<col width="79%">
</colgroup>
<thead><tr class="header">
<th>Name</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>log_dir</code></td>
<td>Path of the directory to save the log files to be parsed by Tensorboard.</td>
</tr>
<tr class="even">
<td><code>histogram_freq</code></td>
<td>Frequency (in epochs) at which to compute activation histograms for the layers of the model. If set to 0 (the default), histograms won’t be computed.</td>
</tr>
<tr class="odd">
<td><code>write_graph</code></td>
<td>Whether to visualize the graph in Tensorboard. The log file can become quite large when write_graph is set to <code>TRUE</code>
</td>
</tr>
<tr class="even">
<td><code>write_images</code></td>
<td>Whether to write model weights to visualize as image in Tensorboard.</td>
</tr>
<tr class="odd">
<td><code>embeddings_freq</code></td>
<td>Frequency (in epochs) at which selected embedding layers will be saved.</td>
</tr>
<tr class="even">
<td><code>embeddings_layer_names</code></td>
<td>A list of names of layers to keep eye on. If <code>NULL</code> or empty list all the embedding layers will be watched.</td>
</tr>
<tr class="odd">
<td><code>embeddings_metadata</code></td>
<td>A named list which maps layer name to a file name in which metadata for this embedding layer is saved. See the <a href="https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional">details</a> about the metadata file format. In case if the same metadata file is used for all embedding layers, string can be passed.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
