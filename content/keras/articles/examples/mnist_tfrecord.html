---
title: mnist_tfrecord
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    parent: keras-examples
---



<div class="source-ref">
<p><span class="caption">Source: </span><a href="https://github.com/rstudio/keras/blob/master/vignettes/examples/mnist_tfrecord.R" class="uri">https://github.com/rstudio/keras/blob/master/vignettes/examples/mnist_tfrecord.R</a></p>
</div>
<p>MNIST dataset with TFRecords, the standard TensorFlow data format.</p>
<p>TFRecord is a data format supported throughout TensorFlow. This example
demonstrates how to load TFRecord data using Input Tensors. Input Tensors
differ from the normal Keras workflow because instead of fitting to data
loaded into a a numpy array, data is supplied via a special tensor that reads
data from nodes that are wired directly into model graph with the
<code><a href="../../reference/layer_input.html">layer_input(tensor=input_tensor)</a></code> parameter.</p>
<p>There are several advantages to using Input Tensors. First, if a dataset is
already in TFRecord format you can load and train on that data directly in
Keras. Second, extended backend API capabilities such as TensorFlow data
augmentation is easy to integrate directly into your Keras training scripts
via input tensors. Third, TensorFlow implements several data APIs for
TFRecords, some of which provide significantly faster training performance
than numpy arrays can provide because they run via the C++ backend. Please
note that this example is tailored for brevity and clarity and not to
demonstrate performance or augmentation capabilities.</p>
<p>Input Tensors also have important disadvantages. In particular, Input Tensors
are fixed at model construction because rewiring networks is not yet
supported. For this reason, changing the data input source means model
weights must be saved and the model rebuilt from scratch to connect the new
input data. validation cannot currently be performed as training progresses,
and must be performed after training completes. This example demonstrates how
to train with input tensors, save the model weights, and then evaluate the
model using the standard Keras API.</p>
<p>Gets to ~99.1% validation accuracy after 5 epochs (there is still a lot of margin
for parameter tuning).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(keras)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(tensorflow)

<span class="cf">if</span> (<span class="kw"><a href="../../reference/k_backend.html">k_backend</a></span>() <span class="op">!=</span><span class="st"> 'tensorflow'</span>) {
  <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/stop">stop</a></span>(<span class="st">'This example can only run with the '</span>,
       <span class="st">'TensorFlow backend, '</span>,
       <span class="st">'because it requires TFRecords, which '</span>,
       <span class="st">'are not supported on other platforms.'</span>)
}

<span class="co"># Define Model -------------------------------------------------------------------</span>

cnn_layers &lt;-<span class="st"> </span><span class="cf">function</span>(x_train_input) {
  x_train_input <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">32</span>, <span class="dt">kernel_size =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">3</span>,<span class="dv">3</span>), 
                  <span class="dt">activation =</span> <span class="st">'relu'</span>, <span class="dt">padding =</span> <span class="st">'valid'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span>(<span class="dt">pool_size =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span>(<span class="dt">pool_size =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_flatten.html">layer_flatten</a></span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">512</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_dropout.html">layer_dropout</a></span>(<span class="dt">rate =</span> <span class="fl">0.5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> classes, <span class="dt">activation =</span> <span class="st">'softmax'</span>, <span class="dt">name =</span> <span class="st">'x_train_out'</span>)
}

sess &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/k_get_session.html">k_get_session</a></span>()

<span class="co"># Data Preparation --------------------------------------------------------------</span>

batch_size &lt;-<span class="st"> </span>128L
batch_shape =<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(batch_size, 28L, 28L, 1L)
steps_per_epoch &lt;-<span class="st"> </span>469L
epochs &lt;-<span class="st"> </span>5L
classes &lt;-<span class="st"> </span>10L

<span class="co"># The capacity variable controls the maximum queue size</span>
<span class="co"># allowed when prefetching data for training.</span>
capacity &lt;-<span class="st"> </span>10000L

<span class="co"># min_after_dequeue is the minimum number elements in the queue</span>
<span class="co"># after a dequeue, which ensures sufficient mixing of elements.</span>
min_after_dequeue &lt;-<span class="st"> </span>3000L

<span class="co"># If `enqueue_many` is `FALSE`, `tensors` is assumed to represent a</span>
<span class="co"># single example.  An input tensor with shape `(x, y, z)` will be output</span>
<span class="co"># as a tensor with shape `(batch_size, x, y, z)`.</span>
<span class="co">#</span>
<span class="co"># If `enqueue_many` is `TRUE`, `tensors` is assumed to represent a</span>
<span class="co"># batch of examples, where the first dimension is indexed by example,</span>
<span class="co"># and all members of `tensors` should have the same size in the</span>
<span class="co"># first dimension.  If an input tensor has shape `(*, x, y, z)`, the</span>
<span class="co"># output will have shape `(batch_size, x, y, z)`.</span>
enqueue_many &lt;-<span class="st"> </span><span class="ot">TRUE</span>

<span class="co"># mnist dataset from tf contrib</span>
mnist &lt;-<span class="st"> </span>tf<span class="op">$</span>contrib<span class="op">$</span>learn<span class="op">$</span>datasets<span class="op">$</span>mnist
data &lt;-<span class="st"> </span>mnist<span class="op">$</span><span class="kw">load_mnist</span>()

train_data &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">shuffle_batch</span>(
  <span class="dt">tensors =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(data<span class="op">$</span>train<span class="op">$</span>images, data<span class="op">$</span>train<span class="op">$</span>labels),
  <span class="dt">batch_size =</span> batch_size,
  <span class="dt">capacity =</span> capacity,
  <span class="dt">min_after_dequeue =</span> min_after_dequeue,
  <span class="dt">enqueue_many =</span> enqueue_many,
  <span class="dt">num_threads =</span> 8L
)
x_train_batch &lt;-<span class="st"> </span>train_data[[<span class="dv">1</span>]]
y_train_batch &lt;-<span class="st"> </span>train_data[[<span class="dv">2</span>]]

x_train_batch &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">cast</span>(x_train_batch, tf<span class="op">$</span>float32)
x_train_batch &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/reshape">reshape</a></span>(x_train_batch, <span class="dt">shape =</span> batch_shape)

y_train_batch &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">cast</span>(y_train_batch, tf<span class="op">$</span>int32)
y_train_batch &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">one_hot</span>(y_train_batch, classes)

x_batch_shape &lt;-<span class="st"> </span>x_train_batch<span class="op">$</span><span class="kw">get_shape</span>()<span class="op">$</span><span class="kw">as_list</span>()
y_batch_shape =<span class="st"> </span>y_train_batch<span class="op">$</span><span class="kw">get_shape</span>()<span class="op">$</span><span class="kw">as_list</span>()

x_train_input &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">tensor =</span> x_train_batch, <span class="dt">batch_shape =</span> x_batch_shape)
x_train_out &lt;-<span class="st"> </span><span class="kw">cnn_layers</span>(x_train_input)

<span class="co"># Training &amp; Evaluation ---------------------------------------------------------</span>

train_model =<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(<span class="dt">inputs =</span> x_train_input, <span class="dt">outputs =</span> x_train_out)

<span class="co"># Pass the target tensor `y_train_batch` to `compile`</span>
<span class="co"># via the `target_tensors` keyword argument:</span>
train_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="kw"><a href="../../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(<span class="dt">lr =</span> <span class="fl">2e-3</span>, <span class="dt">decay =</span> <span class="fl">1e-5</span>),
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'accuracy'</span>),
  <span class="dt">target_tensors =</span> y_train_batch
)

<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(train_model)

<span class="co"># Fit the model using data from the TFRecord data tensors.</span>
coord &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Coordinator</span>()
threads =<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">start_queue_runners</span>(sess, coord)

train_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/reexports.html">fit</a></span>(
  <span class="dt">epochs =</span> epochs,
  <span class="dt">steps_per_epoch =</span> steps_per_epoch
)

<span class="co"># Save the model weights.</span>
train_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/save_model_weights_hdf5.html">save_model_weights_hdf5</a></span>(<span class="st">'saved_wt.h5'</span>)

<span class="co"># Clean up the TF session.</span>
coord<span class="op">$</span><span class="kw">request_stop</span>()
coord<span class="op">$</span><span class="kw">join</span>(threads)
<span class="kw"><a href="../../reference/k_clear_session.html">k_clear_session</a></span>()

<span class="co"># Second Session to test loading trained model without tensors</span>
x_test &lt;-<span class="st"> </span>data<span class="op">$</span>validation<span class="op">$</span>images
x_test &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/reexports.html">array_reshape</a></span>(x_test, <span class="dt">dim =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(x_test), <span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))
y_test &lt;-<span class="st"> </span>data<span class="op">$</span>validation<span class="op">$</span>labels
x_test_inp &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/dim">dim</a></span>(x_test)[<span class="op">-</span><span class="dv">1</span>])
test_out &lt;-<span class="st"> </span><span class="kw">cnn_layers</span>(x_test_inp)
test_model &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(<span class="dt">inputs =</span> x_test_inp, <span class="dt">outputs =</span> test_out)
test_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/save_model_weights_hdf5.html">load_model_weights_hdf5</a></span>(<span class="st">'saved_wt.h5'</span>)
test_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="st">'rmsprop'</span>, 
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>, 
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'accuracy'</span>)
)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(test_model)

result &lt;-<span class="st"> </span>test_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/reexports.html">evaluate</a></span>(x_test, <span class="kw"><a href="../../reference/to_categorical.html">to_categorical</a></span>(y_test, classes))
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/cat">cat</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/sprintf">sprintf</a></span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Test accuracy: %f'</span>, result<span class="op">$</span>acc))</code></pre>
