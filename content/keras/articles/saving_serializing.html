---
title: "Saving and serializing models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Saving and serializing models} 
  %\VignetteEngine{knitr::rmarkdown} 
  %\VignetteEncoding{UTF-8}
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Saving and serializing models"
    identifier: "saving-serializing"
    parent: "keras-advanced"
    weight: 70
---



<blockquote>
<p>This tutorial is an R translation of <a href="https://www.tensorflow.org/alpha/guide/keras/saving_and_serializing">this page</a>
available in the official TensorFlow documentation.</p>
</blockquote>
<p>The first part of this guide covers saving and serialization for Sequential models and models built using the Functional API. The saving and serialization
APIs are the exact same for both of these types of models.</p>
<p>Saving for custom subclasses of Model is covered in the section “Saving Subclassed Models”.
The APIs in this case are slightly different than for Sequential or Functional models.</p>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>For Sequential Models and models built using the Functional API use:</p>
<ul>
<li><p><code><a href="../reference/save_model_hdf5.html">save_model_hdf5()</a></code>/<code><a href="../reference/save_model_hdf5.html">load_model_hdf5()</a></code> to save the entire model to disk, including the <code>optimizer</code> state.</p></li>
<li><p><code><a href="../reference/get_config.html">get_config()</a></code>/<code><a href="../reference/get_config.html">from_config()</a></code> to load only the model architecture into an R object.</p></li>
<li><p><code><a href="../reference/model_to_json.html">model_to_json()</a></code>/<code><a href="../reference/model_to_json.html">model_from_json()</a></code> to save only the architecture of the model to a single string - useful for saving the architecture to disk. You can also use <code><a href="../reference/model_to_yaml.html">model_to_yaml()</a></code>/<code><a href="../reference/model_to_yaml.html">model_from_yaml()</a></code> to save the architecture.</p></li>
<li><p><code><a href="../reference/save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code>/<code><a href="../reference/save_model_weights_hdf5.html">load_model_weights_hdf5()</a></code> if you want to save only the model weights to disk in the <code>hdf5</code> format. You can also use <code><a href="../reference/save_model_weights_tf.html">save_model_weights_tf()</a></code>/<code><a href="../reference/save_model_weights_tf.html">load_model_weights_tf()</a></code> to save the weights in the SavedModel format.</p></li>
</ul>
<p><strong>Note</strong> you can use a combination of <code><a href="../reference/model_to_json.html">model_to_json()</a></code> and <code><a href="../reference/save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code> to save both the architecture and the weights. In this case the optimizer state is not saved.</p>
<ul>
<li>
<code><a href="../reference/model_to_saved_model.html">model_to_saved_model()</a></code>/<code><a href="../reference/model_from_saved_model.html">model_from_saved_model()</a></code> to save both architecture and model weights to the SavedModel format. This is useful if you want to serve the model using TensorFlow Serving.</li>
</ul>
<p>For custom models use:</p>
<ul>
<li>
<code><a href="../reference/save_model_weights_tf.html">save_model_weights_tf()</a></code> or <code><a href="../reference/save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code> to save the model weights. Usually for custom models, the architecture must be recreated using code.</li>
</ul>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(keras)</code></pre>
</div>
<div id="saving-sequential-models-or-functional-models" class="section level2">
<h2>Saving Sequential Models or Functional models</h2>
<pre class="sourceCode r"><code class="sourceCode r">inputs &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> <span class="dv">784</span>, <span class="dt">name =</span> <span class="st">"digits"</span>)
outputs &lt;-<span class="st"> </span>inputs <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>, <span class="dt">name =</span> <span class="st">"dense_1"</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>, <span class="dt">name =</span> <span class="st">"dense_2"</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">"softmax"</span>, <span class="dt">name =</span> <span class="st">"predictions"</span>)
model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/keras_model.html">keras_model</a></span>(inputs, outputs) 
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(model)</code></pre>
<p>Optionally, let’s train this model, just so it has weight values to save,
as well as an an optimizer state. Of course, you can save models you’ve never
trained, too, but obviously that’s less interesting.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(x_train, y_train), <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(x_test, y_test)) <span class="op">%&lt;-%</span><span class="st"> </span><span class="kw"><a href="../reference/dataset_mnist.html">dataset_mnist</a></span>()
x_train &lt;-<span class="st"> </span>x_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">array_reshape</a></span>(<span class="dt">dim =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">60000</span>, <span class="dv">784</span>))<span class="op">/</span><span class="dv">255</span>
x_test &lt;-<span class="st"> </span>x_test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">array_reshape</a></span>(<span class="dt">dim =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">10000</span>, <span class="dv">784</span>))<span class="op">/</span><span class="dv">255</span>

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(<span class="dt">loss =</span> <span class="st">"sparse_categorical_crossentropy"</span>,
                  <span class="dt">optimizer =</span> <span class="kw"><a href="../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>())

history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(x_train, y_train, <span class="dt">batch_size =</span> <span class="dv">64</span>, <span class="dt">epochs =</span> <span class="dv">1</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Save predictions for future checks</span>
predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(model, x_test)</code></pre>
<div id="whole-model-saving" class="section level3">
<h3>Whole-model saving</h3>
<p>You can save a model built with the Functional API into a single file. You can
later recreate the same model from this file, even if you no longer have access
to the code that created the model.</p>
<p>This file includes:</p>
<ul>
<li>The model’s architecture</li>
<li>The model’s weight values (which were learned during training)</li>
<li>The model’s training config (what you passed to compile), if any</li>
<li>The optimizer and its state, if any (this enables you to restart training where you left off)</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Save the model</span>
<span class="kw"><a href="../reference/save_model_hdf5.html">save_model_hdf5</a></span>(model, <span class="st">"model.h5"</span>)

<span class="co"># Recreate the exact same model purely from the file</span>
new_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/save_model_hdf5.html">load_model_hdf5</a></span>(<span class="st">"model.h5"</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Check that the state is preserved</span>
new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(new_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)</code></pre>
<p>Note that the optimizer state is preserved as well so you can resume
training where you left off.</p>
</div>
<div id="export-to-savedmodel" class="section level3">
<h3>Export to SavedModel</h3>
<p>You can also export a whole model to the TensorFlow SavedModel format. SavedModel is
a standalone serialization format for Tensorflow objects, supported by TensorFlow
serving as well as TensorFlow implementations other than Python. Note that
<code>model_to_saved_model</code> is only available for TensorFlow version greater than 1.14.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Export the model to a SavedModel</span>
<span class="kw"><a href="../reference/model_to_saved_model.html">model_to_saved_model</a></span>(model, <span class="st">"model/"</span>)

<span class="co"># Recreate the exact same model</span>
new_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_from_saved_model.html">model_from_saved_model</a></span>(<span class="st">"model/"</span>)

<span class="co"># Check that the state is preserved</span>
new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(new_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)</code></pre>
<p>Note that the optimizer state is preserved as well so you can resume
training where you left off.</p>
<p>The <code>SavedModel</code> files that were created contain:</p>
<ul>
<li>A TensorFlow checkpoint containing the model weights.</li>
<li>A SavedModel proto containing the underlying Tensorflow graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model wasn’t compiled before, then only the inference graph gets exported.</li>
<li>The model’s architecture config, if available.</li>
</ul>
<p>You can also use the <code>export_savedmodel</code> function to export models but those
models can not be loaded as Keras models again. Models exported using
<code>exported_savedmodels</code> can be used for prediction though.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/reexports.html">export_savedmodel</a></span>(model, <span class="st">"savedmodel/"</span>)
new_predictions &lt;-<span class="st"> </span>tfdeploy<span class="op">::</span><span class="kw"><a href="../../tools/tfdeploy/reference/predict_savedmodel.html">predict_savedmodel</a></span>(x_test, <span class="st">"savedmodel/"</span>)</code></pre>
<p><strong>Note</strong> Exporting with <code>export_savedmodel</code> sets learning phase to 0 so you need to restart R and re-build the model before doing additional training.</p>
</div>
<div id="architecture-only-saving" class="section level3">
<h3>Architecture-only saving</h3>
<p>Sometimes, you are only interested in the architecture of the model, and you
don’t need to save the weight values or the optimizer. In this case, you can
retrieve the “config” of the model via the get_config() method. The config is
a named list that enables you to recreate the same model – initialized from
scratch, without any of the information learned previously during training.</p>
<pre class="sourceCode r"><code class="sourceCode r">config &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_config.html">get_config</a></span>(model)
reinitialized_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_config.html">from_config</a></span>(config)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Note that the model state is not preserved! We only saved the architecture.</span>
new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(reinitialized_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)</code></pre>
<p>You can alternatively use <code><a href="../reference/model_to_json.html">model_to_json()</a></code> and <code><a href="../reference/model_to_json.html">model_from_json()</a></code>, which uses a
JSON string to store the config instead of a named list. This is useful to save
the config to disk.</p>
<pre class="sourceCode r"><code class="sourceCode r">json_config &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_to_json.html">model_to_json</a></span>(model)
reinitialized_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_to_json.html">model_from_json</a></span>(json_config)</code></pre>
</div>
<div id="weights-only-saving" class="section level3">
<h3>Weights-only saving</h3>
<p>Sometimes, you are only interested in the state of the model – its weights values – and
not in the architecture. In this case, you can retrieve the weights values as a list of arrays
via <code><a href="../reference/get_weights.html">get_weights()</a></code>, and set the state of the model via <code>set_weights</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">weights &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_weights.html">get_weights</a></span>(model)
<span class="kw"><a href="../reference/get_weights.html">set_weights</a></span>(reinitialized_model, weights)

new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(reinitialized_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)</code></pre>
<p>You can combine <code><a href="../reference/get_config.html">get_config()</a></code>/<code><a href="../reference/get_config.html">from_config()</a></code> and <code><a href="../reference/get_weights.html">get_weights()</a></code>/<code><a href="../reference/get_weights.html">set_weights()</a></code> to
recreate your model in the same state. However, unlike <code>save_model_hdf5</code>, this will not
include the training config and the optimizer. You would have to call <code><a href="../reference/reexports.html">compile()</a></code> again
before using the model for training.</p>
<pre class="sourceCode r"><code class="sourceCode r">config &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_config.html">get_config</a></span>(model)
weights &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_weights.html">get_weights</a></span>(model)

new_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_config.html">from_config</a></span>(config)
<span class="kw"><a href="../reference/get_weights.html">set_weights</a></span>(new_model, weights)

<span class="co"># Check that the state is preserved</span>
new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(new_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)</code></pre>
<p>Note that the optimizer was not preserved, so the model should be compiled
anew before training (and the optimizer will start from a blank state).</p>
<p>The save-to-disk alternative to <code><a href="../reference/get_weights.html">get_weights()</a></code> and <code><a href="../reference/get_weights.html">set_weights(weights)</a></code> is <code>save_weights(fpath)</code> and <code>load_weights(fpath)</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Save JSON config to disk</span>
json_config &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_to_json.html">model_to_json</a></span>(model)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/writeLines">writeLines</a></span>(json_config, <span class="st">"model_config.json"</span>)

<span class="co"># Save weights to disk</span>
<span class="kw"><a href="../reference/save_model_weights_hdf5.html">save_model_weights_hdf5</a></span>(model, <span class="st">"model_weights.h5"</span>)

<span class="co"># Reload the model from the 2 files we saved</span>
json_config &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/readLines">readLines</a></span>(<span class="st">"model_config.json"</span>)
new_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_to_json.html">model_from_json</a></span>(json_config)
<span class="kw"><a href="../reference/save_model_weights_hdf5.html">load_model_weights_hdf5</a></span>(new_model, <span class="st">"model_weights.h5"</span>)

<span class="co"># Check that the state is preserved</span>
new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(new_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)</code></pre>
<p>Note that the optimizer was not preserved. But remember that the simplest,
recommended way is just this:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/save_model_hdf5.html">save_model_hdf5</a></span>(model, <span class="st">"model.h5"</span>)
new_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/save_model_hdf5.html">load_model_hdf5</a></span>(<span class="st">"model.h5"</span>)</code></pre>
</div>
<div id="weights-only-saving-in-savedmodel-format" class="section level3">
<h3>Weights-only saving in SavedModel format</h3>
<p>Note that save_weights can create files either in the Keras HDF5 format, or in
the TensorFlow SavedModel format.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/save_model_weights_tf.html">save_model_weights_tf</a></span>(model, <span class="st">"model_weights"</span>)</code></pre>
</div>
</div>
<div id="saving-subclassed-models" class="section level2">
<h2>Saving Subclassed Models</h2>
<p>Sequential models and Functional models are data structures that represent a
DAG of layers. As such, they can be safely serialized and deserialized.</p>
<p>A subclassed model differs in that it’s not a data structure, it’s
a piece of code. The architecture of the model is defined via the body of the
call method. This means that the architecture of the model cannot be safely
serialized. To load a model, you’ll need to have access to the code that
created it (the code of the model subclass). Alternatively, you could be
serializing this code as bytecode (e.g. via pickling), but that’s unsafe
and generally not portable.</p>
<p>For more information about these differences, see the article
<a href="https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021">“What are Symbolic and Imperative APIs in TensorFlow 2.0?”</a>.</p>
<p>Let’s consider the following subclassed model, which follows the same structure as the model from the first section:</p>
<pre class="sourceCode r"><code class="sourceCode r">keras_model_simple_mlp &lt;-<span class="st"> </span><span class="cf">function</span>(num_classes, 
                                   <span class="dt">use_bn =</span> <span class="ot">FALSE</span>, <span class="dt">use_dp =</span> <span class="ot">FALSE</span>, 
                                   <span class="dt">name =</span> <span class="ot">NULL</span>) {
  
  <span class="co"># define and return a custom model</span>
  <span class="kw"><a href="../reference/keras_model_custom.html">keras_model_custom</a></span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {
    
    <span class="co"># create layers we'll need for the call (this code executes once)</span>
    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>)
    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> num_classes, <span class="dt">activation =</span> <span class="st">"softmax"</span>)
    <span class="cf">if</span> (use_dp)
      self<span class="op">$</span>dp &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dropout.html">layer_dropout</a></span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)
    <span class="cf">if</span> (use_bn)
      self<span class="op">$</span>bn &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>(<span class="dt">axis =</span> <span class="dv">-1</span>)
    
    <span class="co"># implement call (this code executes during training &amp; inference)</span>
    <span class="cf">function</span>(inputs, <span class="dt">mask =</span> <span class="ot">NULL</span>) {
      x &lt;-<span class="st"> </span>self<span class="op">$</span><span class="kw">dense1</span>(inputs)
      <span class="cf">if</span> (use_dp)
        x &lt;-<span class="st"> </span>self<span class="op">$</span><span class="kw">dp</span>(x)
      <span class="cf">if</span> (use_bn)
        x &lt;-<span class="st"> </span>self<span class="op">$</span><span class="kw">bn</span>(x)
      self<span class="op">$</span><span class="kw">dense2</span>(x)
    }
  })
}

model &lt;-<span class="st"> </span><span class="kw">keras_model_simple_mlp</span>(<span class="dt">num_classes =</span> <span class="dv">10</span>)</code></pre>
<p>First of all, a subclassed model that has never been used cannot be saved.</p>
<p>That’s because a subclassed model needs to be called on some data in order to create its weights.</p>
<p>Until the model has been called, it does not know the <code>shape</code> and <code>dtype</code> of the input
data it should be expecting, and thus cannot create its weight variables. You
may remember that in the Functional model from the first section, the <code>shape</code> and
<code>dtype</code> of the inputs was specified in advance (via <code>layer_input</code>) – that’s
why Functional models have a state as soon as they’re instantiated.</p>
<p>Let’s train the model, so as to give it a state:</p>
<pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(<span class="dt">loss =</span> <span class="st">"sparse_categorical_crossentropy"</span>,
                  <span class="dt">optimizer =</span> <span class="kw"><a href="../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>())

history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(x_train, y_train, <span class="dt">batch_size =</span> <span class="dv">64</span>, <span class="dt">epochs =</span> <span class="dv">1</span>)</code></pre>
<p>The recommended way to save a subclassed model is to use <code>save_model_weights_tf</code> to
create a TensorFlow SavedModel checkpoint, which will contain the value of all variables
associated with the model: - The layers’ weights - The optimizer’s state - Any variables
associated with stateful model metrics (if any).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/save_model_weights_tf.html">save_model_weights_tf</a></span>(model, <span class="st">"my_weights"</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Save predictions for future checks</span>
predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(model, x_test)
<span class="co"># Also save the loss on the first batch</span>
<span class="co"># to later assert that the optimizer state was preserved</span>
first_batch_loss &lt;-<span class="st"> </span><span class="kw"><a href="../reference/train_on_batch.html">train_on_batch</a></span>(model, x_train[<span class="dv">1</span><span class="op">:</span><span class="dv">64</span>,], y_train[<span class="dv">1</span><span class="op">:</span><span class="dv">64</span>])</code></pre>
<p>To restore your model, you will need access to the code that created the model object.</p>
<p>Note that in order to restore the optimizer state and the state of any stateful
metric, you should compile the model (with the exact same arguments as before) and
call it on some data before calling load_weights:</p>
<pre class="sourceCode r"><code class="sourceCode r">new_model &lt;-<span class="st"> </span><span class="kw">keras_model_simple_mlp</span>(<span class="dt">num_classes =</span> <span class="dv">10</span>)
new_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(<span class="dt">loss =</span> <span class="st">"sparse_categorical_crossentropy"</span>,
                  <span class="dt">optimizer =</span> <span class="kw"><a href="../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>())

<span class="co"># This initializes the variables used by the optimizers,</span>
<span class="co"># as well as any stateful metric variables</span>
<span class="kw"><a href="../reference/train_on_batch.html">train_on_batch</a></span>(new_model, x_train[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,], y_train[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])

<span class="co"># Load the state of the old model</span>
<span class="kw"><a href="../reference/save_model_weights_tf.html">load_model_weights_tf</a></span>(new_model, <span class="st">"my_weights"</span>)

<span class="co"># Check that the model state has been preserved</span>
new_predictions &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(new_model, x_test)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/all.equal">all.equal</a></span>(predictions, new_predictions)

<span class="co"># The optimizer state is preserved as well,</span>
<span class="co"># so you can resume training where you left off</span>
new_first_batch_loss &lt;-<span class="st"> </span><span class="kw"><a href="../reference/train_on_batch.html">train_on_batch</a></span>(new_model, x_train[<span class="dv">1</span><span class="op">:</span><span class="dv">64</span>,], y_train[<span class="dv">1</span><span class="op">:</span><span class="dv">64</span>])
first_batch_loss <span class="op">==</span><span class="st"> </span>new_first_batch_loss</code></pre>
<p>You’ve reached the end of this guide! This covers everything you need to know about saving and serializing models with Keras in TensorFlow 2.0.</p>
</div>
