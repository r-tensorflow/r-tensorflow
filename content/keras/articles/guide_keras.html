---
title: "Guide to Keras Basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Guide to Keras Basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Guide to Keras Basics"
    identifier: "keras-keras-basics"
    parent: "keras-using-keras"
    weight: 10
    
---



<p>Keras is a high-level API to build and train deep learning models. It’s
used for fast prototyping, advanced research, and production, with three
key advantages:</p>
<ul>
<li>
<em>User friendly</em><br> Keras has a simple, consistent interface
optimized for common use cases. It provides clear and actionable
feedback for user errors.</li>
<li>
<em>Modular and composable</em><br> Keras models are made by connecting
configurable building blocks together, with few restrictions.</li>
<li>
<em>Easy to extend</em><br> Write custom building blocks to express new
ideas for research. Create new layers, loss functions, and develop
state-of-the-art models.</li>
</ul>
<div id="import-keras" class="section level2">
<h2>Import keras</h2>
<p>To get started, load the <code>keras</code> library:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(keras)</code></pre>
</div>
<div id="build-a-simple-model" class="section level2">
<h2>Build a simple model</h2>
<div id="sequential-model" class="section level3">
<h3>Sequential model</h3>
<p>In Keras, you assemble <em>layers</em> to build <em>models</em>. A model is (usually)
a graph of layers. The most common type of model is a stack of layers:
the <code>sequential</code> model.</p>
<p>To build a simple, fully-connected network (i.e., a multi-layer
perceptron):</p>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/keras_model_sequential.html">keras_model_sequential</a></span>()

model <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># Adds a densely-connected layer with 64 units to the model:</span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># Add another:</span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># Add a softmax layer with 10 output units:</span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">'softmax'</span>)</code></pre>
</div>
<div id="configure-the-layers" class="section level3">
<h3>Configure the layers</h3>
<p>There are many <code>layers</code> available with some common constructor
parameters:</p>
<ul>
<li>
<code>activation</code>: Set the <a href="https://tensorflow.rstudio.com/keras/reference/#section-activation-layers">activation function</a> for the layer. By default, no activation is applied.</li>
<li>
<code>kernel_initializer</code> and <code>bias_initializer</code>: The initialization
schemes that create the layer’s weights (kernel and bias). This defaults to the
<a href="https://tensorflow.rstudio.com/keras/reference/initializer_glorot_uniform.html"><code>Glorot uniform</code></a> initializer.</li>
<li>
<code>kernel_regularizer</code> and <code>bias_regularizer</code>: The regularization
schemes that apply to the layer’s weights (kernel and bias), such as L1
or L2 regularization. By default, no regularization is applied.</li>
</ul>
<p>The following instantiates <code>dense</code> layers using
constructor arguments:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create a sigmoid layer:</span>
<span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span><span class="st">'sigmoid'</span>)

<span class="co"># A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:</span>
<span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">kernel_regularizer =</span> <span class="kw"><a href="../reference/regularizer_l1.html">regularizer_l1</a></span>(<span class="fl">0.01</span>))

<span class="co"># A linear layer with L2 regularization of factor 0.01 applied to the bias vector:</span>
<span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">bias_regularizer =</span> <span class="kw"><a href="../reference/regularizer_l1.html">regularizer_l2</a></span>(<span class="fl">0.01</span>))

<span class="co"># A linear layer with a kernel initialized to a random orthogonal matrix:</span>
<span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">kernel_initializer =</span> <span class="st">'orthogonal'</span>)

<span class="co"># A linear layer with a bias vector initialized to 2.0:</span>
<span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">bias_initializer =</span> <span class="kw"><a href="../reference/initializer_constant.html">initializer_constant</a></span>(<span class="fl">2.0</span>))</code></pre>
</div>
</div>
<div id="train-and-evaluate" class="section level2">
<h2>Train and evaluate</h2>
<div id="set-up-training" class="section level3">
<h3>Set up training</h3>
<p>After the model is constructed, configure its learning process by
calling the <code>compile</code> method:</p>
<pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="st">'adam'</span>,
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(<span class="st">'accuracy'</span>)
)</code></pre>
<p><code>compile</code> takes three important arguments:</p>
<ul>
<li>
<code>optimizer</code>: This object specifies the training procedure. Commonly used optimizers are e.g.<br><a href="https://tensorflow.rstudio.com/keras/reference/optimizer_adam.html"><code>adam</code></a>,
<a href="https://tensorflow.rstudio.com/keras/reference/optimizer_rmsprop.html"><code>rmsprop</code></a>, or
<a href="https://tensorflow.rstudio.com/keras/reference/optimizer_sgd.html"><code>sgd</code></a>.</li>
<li>
<code>loss</code>: The function to minimize during optimization. Common choices
include mean square error (<code>mse</code>), <code>categorical_crossentropy</code>, and
<code>binary_crossentropy</code>.</li>
<li>
<code>metrics</code>: Used to monitor training. In classification, this usually is accuracy.</li>
</ul>
<p>The following shows a few examples of configuring a model for training:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Configure a model for mean-squared error regression.</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="st">'adam'</span>,
  <span class="dt">loss =</span> <span class="st">'mse'</span>,           <span class="co"># mean squared error</span>
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(<span class="st">'mae'</span>)   <span class="co"># mean absolute error</span>
)

<span class="co"># Configure a model for categorical classification.</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="kw"><a href="../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(<span class="dt">lr =</span> <span class="fl">0.01</span>),
  <span class="dt">loss =</span> <span class="st">"categorical_crossentropy"</span>,
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(<span class="st">"categorical_accuracy"</span>)
)</code></pre>
</div>
<div id="input-data" class="section level3">
<h3>Input data</h3>
<p>You can train keras models directly on R matrices and arrays (possibly created from R <code>data.frames</code>).
A model is fit to the training data using the <code>fit</code> method:</p>
<pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/matrix">matrix</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="dv">1000</span> <span class="op">*</span><span class="st"> </span><span class="dv">32</span>), <span class="dt">nrow =</span> <span class="dv">1000</span>, <span class="dt">ncol =</span> <span class="dv">32</span>)
labels &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/matrix">matrix</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="dv">1000</span> <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">nrow =</span> <span class="dv">1000</span>, <span class="dt">ncol =</span> <span class="dv">10</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(
  data,
  labels,
  <span class="dt">epochs =</span> <span class="dv">10</span>,
  <span class="dt">batch_size =</span> <span class="dv">32</span>
)</code></pre>
<p><code>fit</code> takes three important arguments:</p>
<ul>
<li>
<code>epochs</code>: Training is structured into <em>epochs</em>. An epoch is one
iteration over the entire input data (this is done in smaller
batches).</li>
<li>
<code>batch_size</code>: When passed matrix or array data, the model slices the data into
smaller batches and iterates over these batches during training.
This integer specifies the size of each batch. Be aware that the
last batch may be smaller if the total number of samples is not
divisible by the batch size.</li>
<li>
<code>validation_data</code>: When prototyping a model, you want to easily
monitor its performance on some validation data. Passing this
argument — a list of inputs and labels — allows the model to display
the loss and metrics in inference mode for the passed data, at the
end of each epoch.</li>
</ul>
<p>Here’s an example using <code>validation_data</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/matrix">matrix</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="dv">1000</span> <span class="op">*</span><span class="st"> </span><span class="dv">32</span>), <span class="dt">nrow =</span> <span class="dv">1000</span>, <span class="dt">ncol =</span> <span class="dv">32</span>)
labels &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/matrix">matrix</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="dv">1000</span> <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">nrow =</span> <span class="dv">1000</span>, <span class="dt">ncol =</span> <span class="dv">10</span>)

val_data &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/matrix">matrix</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="dv">1000</span> <span class="op">*</span><span class="st"> </span><span class="dv">32</span>), <span class="dt">nrow =</span> <span class="dv">100</span>, <span class="dt">ncol =</span> <span class="dv">32</span>)
val_labels &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/matrix">matrix</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Normal">rnorm</a></span>(<span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">nrow =</span> <span class="dv">100</span>, <span class="dt">ncol =</span> <span class="dv">10</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(
  data,
  labels,
  <span class="dt">epochs =</span> <span class="dv">10</span>,
  <span class="dt">batch_size =</span> <span class="dv">32</span>,
  <span class="dt">validation_data =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(val_data, val_labels)
)</code></pre>
</div>
<div id="evaluate-and-predict" class="section level3">
<h3>Evaluate and predict</h3>
<p>Same as <code>fit</code>, the <code>evaluate</code> and <code>predict</code> methods can
use raw R data as well as a <code>dataset</code>.</p>
<p>To <em>evaluate</em> the inference-mode loss and metrics for the data provided:</p>
<pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">evaluate</a></span>(test_data, test_labels, <span class="dt">batch_size =</span> <span class="dv">32</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">evaluate</a></span>(test_dataset, <span class="dt">steps =</span> <span class="dv">30</span>)</code></pre>
<p>And to <em>predict</em> the output of the last layer in inference for the data
provided, again as R data as well as a <code>dataset</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(test_data, <span class="dt">batch_size =</span> <span class="dv">32</span>)
    
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/predict">predict</a></span>(test_dataset, <span class="dt">steps =</span> <span class="dv">30</span>)</code></pre>
</div>
</div>
<div id="build-advanced-models" class="section level2">
<h2>Build advanced models</h2>
<div id="functional-api" class="section level3">
<h3>Functional API</h3>
<p>The <code>sequential</code> model is a simple stack of layers that cannot
represent arbitrary models. Use the <a href="functional_api.html">Keras functional
API</a>
to build complex model topologies such as:</p>
<ul>
<li>multi-input models,</li>
<li>multi-output models,</li>
<li>models with shared layers (the same layer called several times),</li>
<li>models with non-sequential data flows (e.g., residual connections).</li>
</ul>
<p>Building a model with the functional API works like this:</p>
<ol style="list-style-type: decimal">
<li>A layer instance is callable and returns a tensor.</li>
<li>Input tensors and output tensors are used to define a
<code>keras_model</code> instance.</li>
<li>This model is trained just like the <code>sequential</code> model.</li>
</ol>
<p>The following example uses the functional API to build a simple,
fully-connected network:</p>
<pre class="sourceCode r"><code class="sourceCode r">inputs &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> (<span class="dv">32</span>))  <span class="co"># Returns a placeholder tensor</span>

predictions &lt;-<span class="st"> </span>inputs <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">'softmax'</span>)

<span class="co"># Instantiate the model given inputs and outputs.</span>
model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/keras_model.html">keras_model</a></span>(<span class="dt">inputs =</span> inputs, <span class="dt">outputs =</span> predictions)

<span class="co"># The compile step specifies the training configuration.</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="kw"><a href="../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(<span class="dt">lr =</span> <span class="fl">0.001</span>),
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(<span class="st">'accuracy'</span>)
)

<span class="co"># Trains for 5 epochs</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(
  data,
  labels,
  <span class="dt">batch_size =</span> <span class="dv">32</span>,
  <span class="dt">epochs =</span> <span class="dv">5</span>
)</code></pre>
</div>
<div id="custom-layers" class="section level3">
<h3>Custom layers</h3>
<p>To create a custom Keras layer, you create an R6 class derived from <code>KerasLayer</code>. There are three methods to implement (only one of which, <code><a href="https://www.rdocumentation.org/packages/base/topics/call">call()</a></code>, is required for all types of layer):</p>
<ul>
<li>
<code><a href="https://www.rdocumentation.org/packages/utils/topics/PkgUtils">build(input_shape)</a></code>: This is where you will define your weights. Note that if your layer doesn’t define trainable weights then you need not implement this method.</li>
<li>
<code><a href="https://www.rdocumentation.org/packages/base/topics/call">call(x)</a></code>: This is where the layer’s logic lives. Unless you want your layer to support masking, you only have to care about the first argument passed to call: the input tensor.</li>
<li>
<code>compute_output_shape(input_shape)</code>: In case your layer modifies the shape of its input, you should specify here the shape transformation logic. This allows Keras to do automatic shape inference. If you don’t modify the shape of the input then you need not implement this method.</li>
</ul>
<p>Here is an example custom layer that performs a matrix multiplication:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(keras)

CustomLayer &lt;-<span class="st"> </span>R6<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/R6/topics/R6Class">R6Class</a></span>(<span class="st">"CustomLayer"</span>,
                                  
  <span class="dt">inherit =</span> KerasLayer,
  
  <span class="dt">public =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(
    
    <span class="dt">output_dim =</span> <span class="ot">NULL</span>,
    
    <span class="dt">kernel =</span> <span class="ot">NULL</span>,
    
    <span class="dt">initialize =</span> <span class="cf">function</span>(output_dim) {
      self<span class="op">$</span>output_dim &lt;-<span class="st"> </span>output_dim
    },
    
    <span class="dt">build =</span> <span class="cf">function</span>(input_shape) {
      self<span class="op">$</span>kernel &lt;-<span class="st"> </span>self<span class="op">$</span><span class="kw">add_weight</span>(
        <span class="dt">name =</span> <span class="st">'kernel'</span>, 
        <span class="dt">shape =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(input_shape[[<span class="dv">2</span>]], self<span class="op">$</span>output_dim),
        <span class="dt">initializer =</span> <span class="kw"><a href="../reference/initializer_random_normal.html">initializer_random_normal</a></span>(),
        <span class="dt">trainable =</span> <span class="ot">TRUE</span>
      )
    },
    
    <span class="dt">call =</span> <span class="cf">function</span>(x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {
      <span class="kw"><a href="../reference/k_dot.html">k_dot</a></span>(x, self<span class="op">$</span>kernel)
    },
    
    <span class="dt">compute_output_shape =</span> <span class="cf">function</span>(input_shape) {
      <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(input_shape[[<span class="dv">1</span>]], self<span class="op">$</span>output_dim)
    }
  )
)</code></pre>
<p>In order to use the custom layer within a Keras model you also need to create a wrapper function which instantiates the layer using the <code><a href="../reference/create_layer.html">create_layer()</a></code> function. For example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define layer wrapper function</span>
layer_custom &lt;-<span class="st"> </span><span class="cf">function</span>(object, output_dim, <span class="dt">name =</span> <span class="ot">NULL</span>, <span class="dt">trainable =</span> <span class="ot">TRUE</span>) {
  <span class="kw"><a href="../reference/create_layer.html">create_layer</a></span>(CustomLayer, object, <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(
    <span class="dt">output_dim =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/integer">as.integer</a></span>(output_dim),
    <span class="dt">name =</span> name,
    <span class="dt">trainable =</span> trainable
  ))
}</code></pre>
<p>You can now use the layer in a model as usual:</p>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/keras_model_sequential.html">keras_model_sequential</a></span>()
model <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">input_shape =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">32</span>,<span class="dv">32</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_custom</span>(<span class="dt">output_dim =</span> <span class="dv">32</span>)</code></pre>
</div>
<div id="custom-models" class="section level3">
<h3>Custom models</h3>
<p>In addition to creating custom layers, you can also create a custom model.
This might be necessary if you wanted to use TensorFlow eager execution in combination with an imperatively written forward pass.</p>
<p>In cases where this is not needed, but flexibility in building the architecture is required, it is recommended to just stick with the functional API.</p>
<p>A custom model is defined by calling <code><a href="../reference/keras_model_custom.html">keras_model_custom()</a></code> passing a function that specifies the layers to be created and the operations to be executed on forward pass.</p>
<pre class="sourceCode r"><code class="sourceCode r">my_model &lt;-<span class="st"> </span><span class="cf">function</span>(input_dim, output_dim, <span class="dt">name =</span> <span class="ot">NULL</span>) {
  
  <span class="co"># define and return a custom model</span>
  <span class="kw"><a href="../reference/keras_model_custom.html">keras_model_custom</a></span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {
    
    <span class="co"># create layers we'll need for the call (this code executes once)</span>
    <span class="co"># note: the layers have to be created on the self object!</span>
    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>, <span class="dt">input_shape =</span> input_dim)
    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>)
    self<span class="op">$</span>dense3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">'softmax'</span>)
    
    <span class="co"># implement call (this code executes during training &amp; inference)</span>
    <span class="cf">function</span>(inputs, <span class="dt">mask =</span> <span class="ot">NULL</span>) {
      x &lt;-<span class="st"> </span>inputs <span class="op">%&gt;%</span>
<span class="st">        </span>self<span class="op">$</span><span class="kw">dense1</span>() <span class="op">%&gt;%</span>
<span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>self<span class="op">$</span><span class="kw">dense3</span>()
      x
    }
  })
}

model &lt;-<span class="st"> </span><span class="kw">my_model</span>(<span class="dt">input_dim =</span> <span class="dv">32</span>, <span class="dt">output_dim =</span> <span class="dv">10</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">compile</a></span>(
  <span class="dt">optimizer =</span> <span class="kw"><a href="../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(<span class="dt">lr =</span> <span class="fl">0.001</span>),
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">metrics =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(<span class="st">'accuracy'</span>)
)

<span class="co"># Trains for 5 epochs</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(
  data,
  labels,
  <span class="dt">batch_size =</span> <span class="dv">32</span>,
  <span class="dt">epochs =</span> <span class="dv">5</span>
)</code></pre>
</div>
</div>
<div id="callbacks" class="section level2">
<h2>Callbacks</h2>
<p>A callback is an object passed to a model to customize and extend its
behavior during training. You can write your own custom callback, or use
the built-in <code>callbacks</code> that include:</p>
<ul>
<li>
<code>callback_model_checkpoint</code>: Save checkpoints of your model
at regular intervals.</li>
<li>
<code>callback_learning_rate_scheduler</code>: Dynamically change the
learning rate.</li>
<li>
<code>callback_early_stopping</code>: Interrupt training when
validation performance has stopped improving.</li>
<li>
<code>callbacks_tensorboard</code>: Monitor the model’s behavior using
<a href="training_visualization.html#tensorboard">TensorBoard</a>.</li>
</ul>
<p>To use a <code>callback</code>, pass it to the model’s <code>fit</code>
method:</p>
<pre class="sourceCode r"><code class="sourceCode r">callbacks &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(
  <span class="kw"><a href="../reference/callback_early_stopping.html">callback_early_stopping</a></span>(<span class="dt">patience =</span> <span class="dv">2</span>, <span class="dt">monitor =</span> <span class="st">'val_loss'</span>),
  <span class="kw"><a href="../reference/callback_tensorboard.html">callback_tensorboard</a></span>(<span class="dt">log_dir =</span> <span class="st">'./logs'</span>)
)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/reexports.html">fit</a></span>(
  data,
  labels,
  <span class="dt">batch_size =</span> <span class="dv">32</span>,
  <span class="dt">epochs =</span> <span class="dv">5</span>,
  <span class="dt">callbacks =</span> callbacks,
  <span class="dt">validation_data =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/list">list</a></span>(val_data, val_labels)
)</code></pre>
</div>
<div id="save-and-restore" class="section level2">
<h2>Save and restore</h2>
<div id="weights-only" class="section level3">
<h3>Weights only</h3>
<p>Save and load the weights of a model using <code>save_model_weights_hdf5</code> and <code>load_model_weights_hdf5</code>, respectively:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># save in HDF5 format</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/save_model_weights_hdf5.html">save_model_weights_hdf5</a></span>(<span class="st">'my_model.h5'</span>)

<span class="co"># Restore the model's state,</span>
<span class="co"># this requires a model with the same architecture.</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/save_model_weights_hdf5.html">load_model_weights_hdf5</a></span>(<span class="st">'my_model.h5'</span>)</code></pre>
</div>
<div id="configuration-only" class="section level3">
<h3>Configuration only</h3>
<p>A model’s configuration can be saved - this serializes the model
architecture without any weights. A saved configuration can recreate and
initialize the same model, even without the code that defined the
original model. Keras supports JSON and YAML serialization formats:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Serialize a model to JSON format</span>
json_string &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/model_to_json.html">model_to_json</a></span>()

<span class="co"># Recreate the model (freshly initialized)</span>
fresh_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_to_json.html">model_from_json</a></span>(json_string)

<span class="co"># Serializes a model to YAML format</span>
yaml_string &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/model_to_yaml.html">model_to_yaml</a></span>()

<span class="co"># Recreate the model</span>
fresh_model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_to_yaml.html">model_from_yaml</a></span>(yaml_string)</code></pre>
<p>Caution: Custom models are not serializable because their
architecture is defined by the R code in the function passed to <code>keras_model_custom</code>.</p>
</div>
<div id="entire-model" class="section level3">
<h3>Entire model</h3>
<p>The entire model can be saved to a file that contains the weight values,
the model’s configuration, and even the optimizer’s configuration. This
allows you to checkpoint a model and resume training later —from the
exact same state —without access to the original code.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Save entire model to a HDF5 file</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/save_model_hdf5.html">save_model_hdf5</a></span>(<span class="st">'my_model.h5'</span>)

<span class="co"># Recreate the exact same model, including weights and optimizer.</span>
model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/save_model_hdf5.html">load_model_hdf5</a></span>(<span class="st">'my_model.h5'</span>)</code></pre>
</div>
</div>
<div id="eager-execution" class="section level2">
<h2>Eager execution</h2>
<p><a href="eager_guide.Rmd">Eager execution</a> is an imperative programming environment that evaluates operations immediately. This is not required for Keras,
but is supported by the TensorFlow backend and useful for inspecting your program
and debugging.</p>
<p>To use eager execution from R, you need to tell Keras to use the TensorFlow implementation of Keras (as opposed to native Keras):</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(keras)
<span class="kw"><a href="../reference/use_implementation.html">use_implementation</a></span>(<span class="st">"tensorflow"</span>)</code></pre>
<p>When using the TensorFlow implementation, all model-building APIs are compatible with eager
execution.</p>
</div>
<div id="distribution" class="section level2">
<h2>Distribution</h2>
<div id="estimators" class="section level3">
<h3>Estimators</h3>
<p>The <a href="https://tensorflow.rstudio.com/tfestimators/">Estimators</a> API is used for training models for distributed environments. This targets industry use cases such as
distributed training on large datasets that can export a model for
production.</p>
<p>To use <code>tfestimators</code>, you need to install separately:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/install.packages">install.packages</a></span>(<span class="st">"tfestimators"</span>)</code></pre>
<p>A <code>model</code> can be trained with the <code>tfestimators</code> API by
converting the model to an <code>estimator</code> object with
<code>keras_model_to_estimator</code>.
Note: As of today this only works with the TensorFlow implementation of Keras.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(keras)
<span class="kw"><a href="../reference/use_implementation.html">use_implementation</a></span>(<span class="st">"tensorflow"</span>)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(tfestimators)

estimator &lt;-<span class="st"> </span><span class="kw"><a href="../../tfestimators/reference/keras_model_to_estimator.html">keras_model_to_estimator</a></span>(model)</code></pre>
<p>Note: You can enable eager execution for debugging <a href="https://tensorflow.rstudio.com/tfestimators/articles/estimator_basics.html">estimator
input functions</a> and inspecting data.</p>
</div>
</div>
