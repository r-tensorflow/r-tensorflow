---
title: Model loss functions
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: Model loss functions - keras
    parent: keras-reference
aliases:
- /reference/keras/loss_mean_squared_error.html
- /keras/reference/loss_mean_squared_error.html
---
    
    <p>Model loss functions</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>loss_mean_squared_error</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_mean_absolute_error</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_mean_absolute_percentage_error</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_mean_squared_logarithmic_error</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_squared_hinge</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_hinge</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_categorical_hinge</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_logcosh</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_categorical_crossentropy</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_sparse_categorical_crossentropy</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_binary_crossentropy</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_kullback_leibler_divergence</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_poisson</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_cosine_proximity</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)

<span class='fu'>loss_cosine_similarity</span>(<span class='no'>y_true</span>, <span class='no'>y_pred</span>)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">
    
    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>  
      
    <tr>
      <td>y_true</td>
      <td><p>True labels (Tensor)</p></td>
    </tr>
    <tr>
      <td>y_pred</td>
      <td><p>Predictions (Tensor of the same shape as <code>y_true</code>)</p></td>
    </tr>
    </table>

    <h2 id="details">Details</h2>

    <p>Loss functions are to be supplied in the <code>loss</code> parameter of the
<code><a href='../compile.keras.engine.training.Model.html'>compile.keras.engine.training.Model()</a></code> function.</p>
<p>Loss functions can be specified either using the name of a built in loss
function (e.g. 'loss = binary_crossentropy'), a reference to a built in loss
function (e.g. 'loss = loss_binary_crossentropy()') or by passing an
artitrary function that returns a scalar for each data-point and takes the
following two arguments:</p><ul>
<li><p><code>y_true</code> True labels (Tensor)</p></li>
<li><p><code>y_pred</code> Predictions (Tensor of the same shape as <code>y_true</code>)</p></li>
</ul>

<p>The actual optimized objective is the mean of the output array across all
datapoints.</p>
    <h2 id="categorical-crossentropy">Categorical Crossentropy</h2>

    


<p>When using the categorical_crossentropy loss, your targets should be in
categorical format (e.g. if you have 10 classes, the target for each sample
should be a 10-dimensional vector that is all-zeros except for a 1 at the
index corresponding to the class of the sample). In order to convert
integer targets into categorical targets, you can use the Keras utility
function <code><a href='../to_categorical.html'>to_categorical()</a></code>:</p>
<p><code>categorical_labels &lt;- to_categorical(int_labels, num_classes = NULL)</code></p>
    <h2 id="loss-logcosh">loss_logcosh</h2>

    


<p><code><a href='https://rdrr.io/r/base/Log.html'>log(cosh(x))</a></code> is approximately equal to <code>(x ** 2) / 2</code> for small <code>x</code> and
to <code>abs(x) - log(2)</code> for large <code>x</code>. This means that 'logcosh' works mostly
like the mean squared error, but will not be so strongly affected by the
occasional wildly incorrect prediction. However, it may return NaNs if the
intermediate value <code><a href='https://rdrr.io/r/base/Hyperbolic.html'>cosh(y_pred - y_true)</a></code> is too large to be represented
in the chosen precision.</p>
    <h2 id="see-also">See also</h2>

    <div class='dont-index'><p><code><a href='../compile.keras.engine.training.Model.html'>compile.keras.engine.training.Model()</a></code></p></div>




