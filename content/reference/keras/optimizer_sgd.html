---
title: "Stochastic gradient descent optimizer"
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Stochastic gradient descent optimizer - keras"
    parent: keras-reference
aliases: '/reference/keras/optimizer_sgd.html'
---
    
    <p>Stochastic gradient descent optimizer with support for momentum, learning
rate decay, and Nesterov momentum.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>optimizer_sgd</span>(<span class='kw'>lr</span> <span class='kw'>=</span> <span class='fl'>0.01</span>, <span class='kw'>momentum</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>decay</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>nesterov</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>clipnorm</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>clipvalue</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">
    
    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>  
      
    <tr>
      <td>lr</td>
      <td><p>float &gt;= 0. Learning rate.</p></td>
    </tr>
    <tr>
      <td>momentum</td>
      <td><p>float &gt;= 0. Parameter that accelerates SGD in the relevant
direction and dampens oscillations.</p></td>
    </tr>
    <tr>
      <td>decay</td>
      <td><p>float &gt;= 0. Learning rate decay over each update.</p></td>
    </tr>
    <tr>
      <td>nesterov</td>
      <td><p>boolean. Whether to apply Nesterov momentum.</p></td>
    </tr>
    <tr>
      <td>clipnorm</td>
      <td><p>Gradients will be clipped when their L2 norm exceeds this
value.</p></td>
    </tr>
    <tr>
      <td>clipvalue</td>
      <td><p>Gradients will be clipped when their absolute value exceeds
this value.</p></td>
    </tr>
    </table>

    <h2 id="value">Value</h2>

    <p>Optimizer for use with <code><a href='compile.keras.engine.training.Model.html'>compile.keras.engine.training.Model</a></code>.</p>
    <h2 id="see-also">See also</h2>

    <div class='dont-index'><p>Other optimizers: <code><a href='optimizer_adadelta.html'>optimizer_adadelta</a></code>,
  <code><a href='optimizer_adagrad.html'>optimizer_adagrad</a></code>,
  <code><a href='optimizer_adamax.html'>optimizer_adamax</a></code>,
  <code><a href='optimizer_adam.html'>optimizer_adam</a></code>,
  <code><a href='optimizer_nadam.html'>optimizer_nadam</a></code>,
  <code><a href='optimizer_rmsprop.html'>optimizer_rmsprop</a></code></p></div>




