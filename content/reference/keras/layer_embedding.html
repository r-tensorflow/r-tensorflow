---
title: "Turns positive integers (indexes) into dense vectors of fixed size."
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Turns positive integers (indexes) into dense vectors of fixed size. - keras"
    parent: keras-reference
aliases: '/reference/keras/layer_embedding.html'
---
    
    <p>For example, <code>list(4L, 20L) -&gt; list(c(0.25, 0.1), c(0.6, -0.2))</code> This layer
can only be used as the first layer in a model.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>layer_embedding</span>(
  <span class='no'>object</span>,
  <span class='no'>input_dim</span>,
  <span class='no'>output_dim</span>,
  <span class='kw'>embeddings_initializer</span> <span class='kw'>=</span> <span class='st'>"uniform"</span>,
  <span class='kw'>embeddings_regularizer</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>activity_regularizer</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>embeddings_constraint</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>mask_zero</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>input_length</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>batch_size</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>name</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>trainable</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>weights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>
)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">
    
    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>  
      
    <tr>
      <td>object</td>
      <td><p>Model or layer object</p></td>
    </tr>
    <tr>
      <td>input_dim</td>
      <td><p>int &gt; 0. Size of the vocabulary, i.e. maximum integer
index + 1.</p></td>
    </tr>
    <tr>
      <td>output_dim</td>
      <td><p>int &gt;= 0. Dimension of the dense embedding.</p></td>
    </tr>
    <tr>
      <td>embeddings_initializer</td>
      <td><p>Initializer for the <code>embeddings</code> matrix.</p></td>
    </tr>
    <tr>
      <td>embeddings_regularizer</td>
      <td><p>Regularizer function applied to the
<code>embeddings</code> matrix.</p></td>
    </tr>
    <tr>
      <td>activity_regularizer</td>
      <td><p>activity_regularizer</p></td>
    </tr>
    <tr>
      <td>embeddings_constraint</td>
      <td><p>Constraint function applied to the <code>embeddings</code>
matrix.</p></td>
    </tr>
    <tr>
      <td>mask_zero</td>
      <td><p>Whether or not the input value 0 is a special "padding"
value that should be masked out. This is useful when using recurrent
layers, which may take variable length inputs. If this is <code>TRUE</code> then all
subsequent layers in the model need to support masking or an exception will
be raised. If mask_zero is set to TRUE, as a consequence, index 0 cannot be
used in the vocabulary (input_dim should equal size of vocabulary + 1).</p></td>
    </tr>
    <tr>
      <td>input_length</td>
      <td><p>Length of input sequences, when it is constant. This
argument is required if you are going to connect <code>Flatten</code> then <code>Dense</code>
layers upstream (without it, the shape of the dense outputs cannot be
computed).</p></td>
    </tr>
    <tr>
      <td>batch_size</td>
      <td><p>Fixed batch size for layer</p></td>
    </tr>
    <tr>
      <td>name</td>
      <td><p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p></td>
    </tr>
    <tr>
      <td>trainable</td>
      <td><p>Whether the layer weights will be updated during training.</p></td>
    </tr>
    <tr>
      <td>weights</td>
      <td><p>Initial weights for layer.</p></td>
    </tr>
    </table>

    <h2 id="input-shape">Input shape</h2>

    <p>2D tensor with shape: <code>(batch_size, sequence_length)</code>.</p>
    <h2 id="output-shape">Output shape</h2>

    <p>3D tensor with shape: <code>(batch_size, sequence_length,  output_dim)</code>.</p>
    <h2 id="references">References</h2>

    

<ul>
<li><p><a href='http://arxiv.org/abs/1512.05287'>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a></p></li>
</ul>





