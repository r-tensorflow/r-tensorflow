---
title: Leaky version of a Rectified Linear Unit.
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: Leaky version of a Rectified Linear Unit. - keras
    parent: keras-reference
aliases:
- /reference/keras/layer_activation_leaky_relu.html
- /keras/reference/layer_activation_leaky_relu.html
- /guide/keras/reference/layer_activation_leaky_relu.html
- /tools/tools/keras/reference/layer_activation_leaky_relu.html
- /installation/keras/reference/layer_activation_leaky_relu.html
- /tutorials/keras/reference/layer_activation_leaky_relu.html
- /guide/tools/keras/reference/layer_activation_leaky_relu.html
- /deploy/keras/reference/layer_activation_leaky_relu.html
- /tools/keras/reference/layer_activation_leaky_relu.html
---
    
    <p>Allows a small gradient when the unit is not active: <code>f(x) = alpha * x</code> for
<code>x &lt; 0</code>, <code>f(x) = x</code> for <code>x &gt;= 0</code>.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>layer_activation_leaky_relu</span>(
  <span class='no'>object</span>,
  <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0.3</span>,
  <span class='kw'>input_shape</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>batch_input_shape</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>batch_size</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>dtype</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>name</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>trainable</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>weights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>
)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">
    
    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>  
      
    <tr>
      <td>object</td>
      <td><p>Model or layer object</p></td>
    </tr>
    <tr>
      <td>alpha</td>
      <td><p>float &gt;= 0. Negative slope coefficient.</p></td>
    </tr>
    <tr>
      <td>input_shape</td>
      <td><p>Input shape (list of integers, does not include the
samples axis) which is required when using this layer as the first layer in
a model.</p></td>
    </tr>
    <tr>
      <td>batch_input_shape</td>
      <td><p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p></td>
    </tr>
    <tr>
      <td>batch_size</td>
      <td><p>Fixed batch size for layer</p></td>
    </tr>
    <tr>
      <td>dtype</td>
      <td><p>The data type expected by the input, as a string (<code>float32</code>,
<code>float64</code>, <code>int32</code>...)</p></td>
    </tr>
    <tr>
      <td>name</td>
      <td><p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p></td>
    </tr>
    <tr>
      <td>trainable</td>
      <td><p>Whether the layer weights will be updated during training.</p></td>
    </tr>
    <tr>
      <td>weights</td>
      <td><p>Initial weights for layer.</p></td>
    </tr>
    </table>

    <h2 id="see-also">See also</h2>

    <div class='dont-index'><p><a href='https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf'>Rectifier Nonlinearities Improve Neural Network Acoustic Models</a>.</p>
<p>Other activation layers: 
<code><a href='../layer_activation_elu.html'>layer_activation_elu</a>()</code>,
<code><a href='../layer_activation_parametric_relu.html'>layer_activation_parametric_relu</a>()</code>,
<code><a href='../layer_activation_relu.html'>layer_activation_relu</a>()</code>,
<code><a href='../layer_activation_selu.html'>layer_activation_selu</a>()</code>,
<code><a href='../layer_activation_softmax.html'>layer_activation_softmax</a>()</code>,
<code><a href='../layer_activation_thresholded_relu.html'>layer_activation_thresholded_relu</a>()</code>,
<code><a href='../layer_activation.html'>layer_activation</a>()</code></p></div>




