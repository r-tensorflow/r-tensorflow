---
title: Xception V1 model for Keras.
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: Xception V1 model for Keras. - keras
    parent: keras-reference
aliases:
- /reference/keras/application_xception.html
- /keras/reference/application_xception.html
- /guide/keras/reference/application_xception.html
- /tools/tools/keras/reference/application_xception.html
- /installation/keras/reference/application_xception.html
- /tutorials/keras/reference/application_xception.html
- /guide/tools/keras/reference/application_xception.html
- /deploy/keras/reference/application_xception.html
- /tools/keras/reference/application_xception.html
- /tutorials/tools/keras/reference/application_xception.html
---
    
    <p>Xception V1 model for Keras.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>application_xception</span>(
  <span class='kw'>include_top</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>weights</span> <span class='kw'>=</span> <span class='st'>"imagenet"</span>,
  <span class='kw'>input_tensor</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>input_shape</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>pooling</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>classes</span> <span class='kw'>=</span> <span class='fl'>1000</span>
)

<span class='fu'>xception_preprocess_input</span>(<span class='no'>x</span>)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">
    
    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>  
      
    <tr>
      <td>include_top</td>
      <td><p>whether to include the fully-connected layer at the top of
the network.</p></td>
    </tr>
    <tr>
      <td>weights</td>
      <td><p><code>NULL</code> (random initialization), <code>imagenet</code> (ImageNet
weights), or the path to the weights file to be loaded.</p></td>
    </tr>
    <tr>
      <td>input_tensor</td>
      <td><p>optional Keras tensor to use as image input for the
model.</p></td>
    </tr>
    <tr>
      <td>input_shape</td>
      <td><p>optional shape list, only to be specified if <code>include_top</code>
is FALSE (otherwise the input shape has to be <code>(299, 299, 3)</code>. It should
have exactly 3 inputs channels, and width and height should be no smaller
than 75. E.g. <code>(150, 150, 3)</code> would be one valid value.</p></td>
    </tr>
    <tr>
      <td>pooling</td>
      <td><p>Optional pooling mode for feature extraction when
<code>include_top</code> is <code>FALSE</code>.</p><ul>
<li><p><code>NULL</code> means that the output of the model will be the 4D tensor output
of the last convolutional layer.</p></li>
<li><p><code>avg</code> means that global average pooling will be applied to the output of
the last convolutional layer, and thus the output of the model will be
a 2D tensor.</p></li>
<li><p><code>max</code> means that global max pooling will be applied.</p></li>
</ul></td>
    </tr>
    <tr>
      <td>classes</td>
      <td><p>optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified.</p></td>
    </tr>
    <tr>
      <td>x</td>
      <td><p>Input tensor for preprocessing</p></td>
    </tr>
    </table>

    <h2 id="value">Value</h2>

    <p>A Keras model instance.</p>
    <h2 id="details">Details</h2>

    <p>On ImageNet, this model gets to a top-1 validation accuracy of 0.790
and a top-5 validation accuracy of 0.945.</p>
<p>Do note that the input image format for this model is different than for
the VGG16 and ResNet models (299x299 instead of 224x224).</p>
<p>The <code>xception_preprocess_input()</code> function should be used for image
preprocessing.</p>
<p>This application is only available when using the TensorFlow back-end.</p>
    <h2 id="reference">Reference</h2>

    

<ul>
<li><p><a href='https://arxiv.org/abs/1610.02357'>Xception: Deep Learning with Depthwise Separable Convolutions</a></p></li>
</ul>





