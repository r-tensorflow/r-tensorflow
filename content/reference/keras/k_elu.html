---
title: Exponential linear unit.
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: Exponential linear unit. - keras
    parent: keras-reference
aliases:
- /reference/keras/k_elu.html
- /keras/reference/k_elu.html
---
    
    <p>Exponential linear unit.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>k_elu</span>(<span class='no'>x</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>1</span>)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">
    
    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>  
      
    <tr>
      <td>x</td>
      <td><p>A tensor or variable to compute the activation function for.</p></td>
    </tr>
    <tr>
      <td>alpha</td>
      <td><p>A scalar, slope of negative section.</p></td>
    </tr>
    </table>

    <h2 id="value">Value</h2>

    <p>A tensor.</p>
    <h2 id="keras-backend">Keras Backend</h2>

    


<p>This function is part of a set of Keras backend functions that enable
lower level access to the core operations of the backend tensor engine
(e.g. TensorFlow, CNTK, Theano, etc.).</p>
<p>You can see a list of all available backend functions here:
<a href='https://keras.rstudio.com/articles/backend.html#backend-functions'>https://keras.rstudio.com/articles/backend.html#backend-functions</a>.</p>




