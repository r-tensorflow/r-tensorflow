<!doctype html><html><head><meta charset=utf-8><meta name=generator content=pandoc><meta http-equiv=x-ua-compatible content="IE=EDGE"><meta name=viewport content="width=device-width,initial-scale=1"><title>Distributed training with Keras</title><script src=data:application/javascript;base64,ZG9jdW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignRE9NQ29udGVudExvYWRlZCcsZnVuY3Rpb24oZSl7dmFyIGhzPWRvY3VtZW50LnF1ZXJ5U2VsZWN0b3JBbGwoImRpdi5zZWN0aW9uW2NsYXNzKj0nbGV2ZWwnXSA+IDpmaXJzdC1jaGlsZCIpO3ZhciBpLGgsYTtmb3IoaT0wO2k8aHMubGVuZ3RoO2krKyl7aD1oc1tpXTtpZighL15oWzEtNl0kL2kudGVzdChoLnRhZ05hbWUpKWNvbnRpbnVlO2E9aC5hdHRyaWJ1dGVzO3doaWxlKGEubGVuZ3RoPjApaC5yZW1vdmVBdHRyaWJ1dGUoYVswXS5uYW1lKTt9fSk7></script><link href=data:text/css;base64,YS5hbmNob3Itc2VjdGlvbnttYXJnaW4tbGVmdDoxMHB4O3Zpc2liaWxpdHk6aGlkZGVuO2NvbG9yOmluaGVyaXR9YS5hbmNob3Itc2VjdGlvbjo6YmVmb3Jle2NvbnRlbnQ6JyMnfS5oYXNBbmNob3I6aG92ZXIgYS5hbmNob3Itc2VjdGlvbnt2aXNpYmlsaXR5OnZpc2libGV9 rel=stylesheet><script src="data:application/javascript;base64,ZG9jdW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignRE9NQ29udGVudExvYWRlZCcsZnVuY3Rpb24oKXtpZih0eXBlb2Ygd2luZG93LmFuY2hvcnM9PT0nb2JqZWN0JyYmYW5jaG9ycy5oYXNPd25Qcm9wZXJ0eSgnaGFzQW5jaG9ySlNMaW5rJykpe3JldHVybjt9CmNvbnN0IGg9ZG9jdW1lbnQucXVlcnlTZWxlY3RvckFsbCgnaDEsIGgyLCBoMywgaDQsIGg1LCBoNicpO2lmKEFycmF5LmZyb20oaCkuc29tZSh4PT54LmNsYXNzTGlzdC5jb250YWlucygnaGFzQW5jaG9yJykpKXtyZXR1cm4gbnVsbDt9CmNvbnN0IHNlY3Rpb25faWQ9ZnVuY3Rpb24oeCl7cmV0dXJuKCh4LmNsYXNzTGlzdC5jb250YWlucygnc2VjdGlvbicpfHwoeC50YWdOYW1lPT09J1NFQ1RJT04nKSk/eC5pZDonJyk7fTtoLmZvckVhY2goZnVuY3Rpb24oeCl7Y29uc3QgaWQ9eC5pZHx8c2VjdGlvbl9pZCh4LnBhcmVudEVsZW1lbnQpO2lmKGlkPT09Jycpe3JldHVybiBudWxsO30KbGV0IGFuY2hvcj1kb2N1bWVudC5jcmVhdGVFbGVtZW50KCdhJyk7YW5jaG9yLmhyZWY9JyMnK2lkO2FuY2hvci5jbGFzc0xpc3Q9WydhbmNob3Itc2VjdGlvbiddO3guY2xhc3NMaXN0LmFkZCgnaGFzQW5jaG9yJyk7eC5hcHBlbmRDaGlsZChhbmNob3IpO30pO30pOw=="></script><style type=text/css>code{white-space:pre-wrap}span.smallcaps{font-variant:small-caps}span.underline{text-decoration:underline}div.column{display:inline-block;vertical-align:top;width:50%}div.hanging-indent{margin-left:1.5em;text-indent:-1.5em}ul.task-list{list-style:none}</style><style type=text/css>code{white-space:pre}</style><style type=text/css data-origin=pandoc>pre>code.sourceCode{white-space:pre;position:relative}pre>code.sourceCode>span{display:inline-block;line-height:1.25}pre>code.sourceCode>span:empty{height:1.2em}code.sourceCode>span{color:inherit;text-decoration:inherit}div.sourceCode{margin:1em 0}pre.sourceCode{margin:0}@media screen{div.sourceCode{overflow:auto}}@media print{pre>code.sourceCode{white-space:pre-wrap}pre>code.sourceCode>span{text-indent:-5em;padding-left:5em}}pre.numberSource code{counter-reset:source-line 0}pre.numberSource code>span{position:relative;left:-4em;counter-increment:source-line}pre.numberSource code>span>a:first-child::before{content:counter(source-line);position:relative;left:-1em;text-align:right;vertical-align:baseline;border:none;display:inline-block;-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;padding:0 4px;width:4em;color:#aaa}pre.numberSource{margin-left:3em;border-left:1px solid #aaa;padding-left:4px}div.sourceCode{}@media screen{pre>code.sourceCode>span>a:first-child::before{text-decoration:underline}}code span.al{color:red;font-weight:700}code span.an{color:#60a0b0;font-weight:700;font-style:italic}code span.at{color:#7d9029}code span.bn{color:#40a070}code span.bu{}code span.cf{color:#007020;font-weight:700}code span.ch{color:#4070a0}code span.cn{color:#800}code span.co{color:#60a0b0;font-style:italic}code span.cv{color:#60a0b0;font-weight:700;font-style:italic}code span.do{color:#ba2121;font-style:italic}code span.dt{color:#902000}code span.dv{color:#40a070}code span.er{color:red;font-weight:700}code span.ex{}code span.fl{color:#40a070}code span.fu{color:#06287e}code span.im{}code span.in{color:#60a0b0;font-weight:700;font-style:italic}code span.kw{color:#007020;font-weight:700}code span.op{color:#666}code span.ot{color:#007020}code span.pp{color:#bc7a00}code span.sc{color:#4070a0}code span.ss{color:#b68}code span.st{color:#4070a0}code span.va{color:#19177c}code span.vs{color:#4070a0}code span.wa{color:#60a0b0;font-weight:700;font-style:italic}</style><script>(function(){var sheets=document.styleSheets;for(var i=0;i<sheets.length;i++){if(sheets[i].ownerNode.dataset["origin"]!=="pandoc")continue;try{var rules=sheets[i].cssRules;}catch(e){continue;}
for(var j=0;j<rules.length;j++){var rule=rules[j];if(rule.type!==rule.STYLE_RULE||rule.selectorText!=="div.sourceCode")continue;var style=rule.style.cssText;if(rule.style.color===''&&rule.style.backgroundColor==='')continue;sheets[i].deleteRule(j);sheets[i].insertRule('pre.sourceCode{'+style+'}',j);}}})();</script><link rel=stylesheet href="data:text/css;base64,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" type=text/css></head><body><h1 class="title toc-ignore">Distributed training with Keras</h1><div id=overview class="section level2"><h2>Overview</h2><p>The <code>tf$distribute$Strategy</code> API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.</p><p>This tutorial uses the <code>tf$distribute$MirroredStrategy</code>, which does in-graph replication with synchronous training on many GPUs on one machine. Essentially, it copies all of the modelâ€™s variables to each processor. Then, it uses <a href=http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/>all-reduce</a> to combine the gradients from all processors and applies the combined value to all copies of the model.</p><p><code>MirroredStategy</code> is one of several distribution strategy available in TensorFlow core. You can read about more strategies in the <a href=TBD%20guide>distribution strategy guide</a>.</p><div id=keras-api class="section level3"><h3>Keras API</h3><p>This example uses the <code>keras</code> API to build the model and training loop. For custom training loops, see the <a href=TBD%20tutorial>Custom training loops</a> tutorial.</p><div class=sourceCode id=cb1><pre class="sourceCode r"><code class="sourceCode r"><span id=cb1-1><a href=#cb1-1 aria-hidden=true tabindex=-1></a><span class=fu>library</span>(tensorflow)</span>
<span id=cb1-2><a href=#cb1-2 aria-hidden=true tabindex=-1></a><span class=fu>library</span>(keras)</span>
<span id=cb1-3><a href=#cb1-3 aria-hidden=true tabindex=-1></a><span class=fu>library</span>(tfdatasets)</span>
<span id=cb1-4><a href=#cb1-4 aria-hidden=true tabindex=-1></a><span class=co># used to load the MNIST dataset</span></span>
<span id=cb1-5><a href=#cb1-5 aria-hidden=true tabindex=-1></a><span class=fu>library</span>(tfds)</span>
<span id=cb1-6><a href=#cb1-6 aria-hidden=true tabindex=-1></a></span>
<span id=cb1-7><a href=#cb1-7 aria-hidden=true tabindex=-1></a><span class=fu>library</span>(purrr)</span>
<span id=cb1-8><a href=#cb1-8 aria-hidden=true tabindex=-1></a><span class=fu>library</span>(glue)</span></code></pre></div></div><div id=download-the-dataset class="section level3"><h3>Download the dataset</h3><p>Download the MNIST dataset and load it using <a href=https://github.com/rstudio/tfds>tfds</a>. This returns a dataset in <code>tfdatasets</code> format.</p><div class=sourceCode id=cb2><pre class="sourceCode r"><code class="sourceCode r"><span id=cb2-1><a href=#cb2-1 aria-hidden=true tabindex=-1></a><span class=co># if you haven&#39;t done it yet:</span></span>
<span id=cb2-2><a href=#cb2-2 aria-hidden=true tabindex=-1></a><span class=co># tfds::install_tfds()</span></span>
<span id=cb2-3><a href=#cb2-3 aria-hidden=true tabindex=-1></a>mnist <span class=ot>&lt;-</span> <span class=fu>tfds_load</span>(<span class=st>&quot;mnist&quot;</span>)</span>
<span id=cb2-4><a href=#cb2-4 aria-hidden=true tabindex=-1></a>info <span class=ot>&lt;-</span> <span class=fu>summary</span>(mnist)</span></code></pre></div></div><div id=define-distribution-strategy class="section level3"><h3>Define distribution strategy</h3><p>Create a <code>MirroredStrategy</code> object. This will handle distribution, and provides a context manager (<code>tf$distribute$MirroredStrategy$scope</code>) to build your model inside.</p><div class=sourceCode id=cb3><pre class="sourceCode r"><code class="sourceCode r"><span id=cb3-1><a href=#cb3-1 aria-hidden=true tabindex=-1></a>strategy <span class=ot>&lt;-</span> tf<span class=sc>$</span>distribute<span class=sc>$</span><span class=fu>MirroredStrategy</span>()</span>
<span id=cb3-2><a href=#cb3-2 aria-hidden=true tabindex=-1></a>strategy<span class=sc>$</span>num_replicas_in_sync</span></code></pre></div></div><div id=setup-input-pipeline class="section level3"><h3>Setup input pipeline</h3><p>When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly.</p><div class=sourceCode id=cb4><pre class="sourceCode r"><code class="sourceCode r"><span id=cb4-1><a href=#cb4-1 aria-hidden=true tabindex=-1></a>num_train_examples <span class=ot>&lt;-</span> <span class=fu>as.integer</span>(info<span class=sc>$</span>splits[[<span class=dv>2</span>]]<span class=sc>$</span>statistics<span class=sc>$</span>numExamples)</span>
<span id=cb4-2><a href=#cb4-2 aria-hidden=true tabindex=-1></a>num_test_examples <span class=ot>&lt;-</span> <span class=fu>as.integer</span>(info<span class=sc>$</span>splits[[<span class=dv>1</span>]]<span class=sc>$</span>statistics<span class=sc>$</span>numExamples)</span>
<span id=cb4-3><a href=#cb4-3 aria-hidden=true tabindex=-1></a></span>
<span id=cb4-4><a href=#cb4-4 aria-hidden=true tabindex=-1></a>BUFFER_SIZE <span class=ot>&lt;-</span> <span class=dv>10000</span></span>
<span id=cb4-5><a href=#cb4-5 aria-hidden=true tabindex=-1></a></span>
<span id=cb4-6><a href=#cb4-6 aria-hidden=true tabindex=-1></a>BATCH_SIZE_PER_REPLICA <span class=ot>&lt;-</span> <span class=dv>64</span></span>
<span id=cb4-7><a href=#cb4-7 aria-hidden=true tabindex=-1></a>BATCH_SIZE <span class=ot>&lt;-</span> BATCH_SIZE_PER_REPLICA <span class=sc>*</span> strategy<span class=sc>$</span>num_replicas_in_sync</span></code></pre></div><p>Pixel values, which are 0-255, have to be normalized to the 0-1 range. Furthermore, we shuffle and batch the train and test datasets. Notice we are also keeping an in-memory cache of the training data to improve performance.</p><div class=sourceCode id=cb5><pre class="sourceCode r"><code class="sourceCode r"><span id=cb5-1><a href=#cb5-1 aria-hidden=true tabindex=-1></a>train_dataset <span class=ot>&lt;-</span> mnist<span class=sc>$</span>train <span class=sc>%&gt;%</span> </span>
<span id=cb5-2><a href=#cb5-2 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_map</span>(<span class=cf>function</span>(record) {</span>
<span id=cb5-3><a href=#cb5-3 aria-hidden=true tabindex=-1></a>    record<span class=sc>$</span>image <span class=ot>&lt;-</span> tf<span class=sc>$</span><span class=fu>cast</span>(record<span class=sc>$</span>image, tf<span class=sc>$</span>float32) <span class=sc>/</span> <span class=dv>255</span></span>
<span id=cb5-4><a href=#cb5-4 aria-hidden=true tabindex=-1></a>    record}) <span class=sc>%&gt;%</span></span>
<span id=cb5-5><a href=#cb5-5 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_cache</span>() <span class=sc>%&gt;%</span></span>
<span id=cb5-6><a href=#cb5-6 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_shuffle</span>(BUFFER_SIZE) <span class=sc>%&gt;%</span> </span>
<span id=cb5-7><a href=#cb5-7 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_batch</span>(BATCH_SIZE) <span class=sc>%&gt;%</span> </span>
<span id=cb5-8><a href=#cb5-8 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_map</span>(unname)</span>
<span id=cb5-9><a href=#cb5-9 aria-hidden=true tabindex=-1></a></span>
<span id=cb5-10><a href=#cb5-10 aria-hidden=true tabindex=-1></a>test_dataset <span class=ot>&lt;-</span> mnist<span class=sc>$</span>test <span class=sc>%&gt;%</span> </span>
<span id=cb5-11><a href=#cb5-11 aria-hidden=true tabindex=-1></a> <span class=fu>dataset_map</span>(<span class=cf>function</span>(record) {</span>
<span id=cb5-12><a href=#cb5-12 aria-hidden=true tabindex=-1></a>    record<span class=sc>$</span>image <span class=ot>&lt;-</span> tf<span class=sc>$</span><span class=fu>cast</span>(record<span class=sc>$</span>image, tf<span class=sc>$</span>float32) <span class=sc>/</span> <span class=dv>255</span></span>
<span id=cb5-13><a href=#cb5-13 aria-hidden=true tabindex=-1></a>    record}) <span class=sc>%&gt;%</span></span>
<span id=cb5-14><a href=#cb5-14 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_batch</span>(BATCH_SIZE) <span class=sc>%&gt;%</span> </span>
<span id=cb5-15><a href=#cb5-15 aria-hidden=true tabindex=-1></a>  <span class=fu>dataset_map</span>(unname)</span></code></pre></div></div><div id=create-the-model class="section level3"><h3>Create the model</h3><p>Create and compile the Keras model in the context of <code>strategy$scope</code>.</p><div class=sourceCode id=cb6><pre class="sourceCode r"><code class="sourceCode r"><span id=cb6-1><a href=#cb6-1 aria-hidden=true tabindex=-1></a><span class=fu>with</span> (strategy<span class=sc>$</span><span class=fu>scope</span>(), {</span>
<span id=cb6-2><a href=#cb6-2 aria-hidden=true tabindex=-1></a>   model <span class=ot>&lt;-</span> <span class=fu>keras_model_sequential</span>() <span class=sc>%&gt;%</span></span>
<span id=cb6-3><a href=#cb6-3 aria-hidden=true tabindex=-1></a>     <span class=fu>layer_conv_2d</span>(</span>
<span id=cb6-4><a href=#cb6-4 aria-hidden=true tabindex=-1></a>       <span class=at>filters =</span> <span class=dv>32</span>,</span>
<span id=cb6-5><a href=#cb6-5 aria-hidden=true tabindex=-1></a>       <span class=at>kernel_size =</span> <span class=dv>3</span>,</span>
<span id=cb6-6><a href=#cb6-6 aria-hidden=true tabindex=-1></a>       <span class=at>activation =</span> <span class=st>&#39;relu&#39;</span>,</span>
<span id=cb6-7><a href=#cb6-7 aria-hidden=true tabindex=-1></a>       <span class=at>input_shape =</span> <span class=fu>c</span>(<span class=dv>28</span>, <span class=dv>28</span>, <span class=dv>1</span>)</span>
<span id=cb6-8><a href=#cb6-8 aria-hidden=true tabindex=-1></a>       ) <span class=sc>%&gt;%</span></span>
<span id=cb6-9><a href=#cb6-9 aria-hidden=true tabindex=-1></a>     <span class=fu>layer_max_pooling_2d</span>() <span class=sc>%&gt;%</span></span>
<span id=cb6-10><a href=#cb6-10 aria-hidden=true tabindex=-1></a>     <span class=fu>layer_flatten</span>() <span class=sc>%&gt;%</span></span>
<span id=cb6-11><a href=#cb6-11 aria-hidden=true tabindex=-1></a>     <span class=fu>layer_dense</span>(<span class=at>units =</span> <span class=dv>64</span>, <span class=at>activation =</span> <span class=st>&#39;relu&#39;</span>) <span class=sc>%&gt;%</span></span>
<span id=cb6-12><a href=#cb6-12 aria-hidden=true tabindex=-1></a>     <span class=fu>layer_dense</span>(<span class=at>units =</span> <span class=dv>10</span>, <span class=at>activation =</span> <span class=st>&#39;softmax&#39;</span>)</span>
<span id=cb6-13><a href=#cb6-13 aria-hidden=true tabindex=-1></a>   </span>
<span id=cb6-14><a href=#cb6-14 aria-hidden=true tabindex=-1></a>  model <span class=sc>%&gt;%</span> <span class=fu>compile</span>(</span>
<span id=cb6-15><a href=#cb6-15 aria-hidden=true tabindex=-1></a>    <span class=at>loss =</span> <span class=st>&#39;sparse_categorical_crossentropy&#39;</span>,</span>
<span id=cb6-16><a href=#cb6-16 aria-hidden=true tabindex=-1></a>    <span class=at>optimizer =</span> <span class=st>&#39;adam&#39;</span>,</span>
<span id=cb6-17><a href=#cb6-17 aria-hidden=true tabindex=-1></a>    <span class=at>metrics =</span> <span class=st>&#39;accuracy&#39;</span>)</span>
<span id=cb6-18><a href=#cb6-18 aria-hidden=true tabindex=-1></a>})</span></code></pre></div></div><div id=define-the-callbacks class="section level3"><h3>Define the callbacks</h3><p>The callbacks used here are:</p><ul><li>TensorBoard: This callback writes a log for TensorBoard which allows you to visualize the graphs.</li><li>Model Checkpoint: This callback saves the model after every epoch.</li><li>Learning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.</li></ul><p>For illustrative purposes, add a print callback to display the learning rate.</p><div class=sourceCode id=cb7><pre class="sourceCode r"><code class="sourceCode r"><span id=cb7-1><a href=#cb7-1 aria-hidden=true tabindex=-1></a><span class=co># Define the checkpoint directory to store the checkpoints</span></span>
<span id=cb7-2><a href=#cb7-2 aria-hidden=true tabindex=-1></a>checkpoint_dir <span class=ot>&lt;-</span> <span class=st>&#39;./training_checkpoints&#39;</span></span>
<span id=cb7-3><a href=#cb7-3 aria-hidden=true tabindex=-1></a><span class=co># Name of the checkpoint files</span></span>
<span id=cb7-4><a href=#cb7-4 aria-hidden=true tabindex=-1></a>checkpoint_prefix <span class=ot>&lt;-</span> <span class=fu>file.path</span>(checkpoint_dir, <span class=st>&quot;ckpt_{epoch}&quot;</span>)</span></code></pre></div><div class=sourceCode id=cb8><pre class="sourceCode r"><code class="sourceCode r"><span id=cb8-1><a href=#cb8-1 aria-hidden=true tabindex=-1></a><span class=co># Function for decaying the learning rate.</span></span>
<span id=cb8-2><a href=#cb8-2 aria-hidden=true tabindex=-1></a><span class=co># You can define any decay function you need.</span></span>
<span id=cb8-3><a href=#cb8-3 aria-hidden=true tabindex=-1></a>decay <span class=ot>&lt;-</span> <span class=cf>function</span>(epoch, lr) {</span>
<span id=cb8-4><a href=#cb8-4 aria-hidden=true tabindex=-1></a>  <span class=cf>if</span> (epoch <span class=sc>&lt;</span> <span class=dv>3</span>) <span class=fl>1e-3</span></span>
<span id=cb8-5><a href=#cb8-5 aria-hidden=true tabindex=-1></a>    <span class=cf>else</span> <span class=cf>if</span> (epoch <span class=sc>&gt;=</span> <span class=dv>3</span> <span class=sc>&amp;&amp;</span> epoch <span class=sc>&lt;</span> <span class=dv>7</span>) <span class=fl>1e-4</span></span>
<span id=cb8-6><a href=#cb8-6 aria-hidden=true tabindex=-1></a>      <span class=cf>else</span> <span class=fl>1e-5</span></span>
<span id=cb8-7><a href=#cb8-7 aria-hidden=true tabindex=-1></a>}</span></code></pre></div><div class=sourceCode id=cb9><pre class="sourceCode r"><code class="sourceCode r"><span id=cb9-1><a href=#cb9-1 aria-hidden=true tabindex=-1></a><span class=co># Callback for printing the LR at the end of each epoch.</span></span>
<span id=cb9-2><a href=#cb9-2 aria-hidden=true tabindex=-1></a>PrintLR <span class=ot>&lt;-</span> R6<span class=sc>::</span><span class=fu>R6Class</span>(<span class=st>&quot;PrintLR&quot;</span>,</span>
<span id=cb9-3><a href=#cb9-3 aria-hidden=true tabindex=-1></a>  <span class=at>inherit =</span> KerasCallback,</span>
<span id=cb9-4><a href=#cb9-4 aria-hidden=true tabindex=-1></a>  </span>
<span id=cb9-5><a href=#cb9-5 aria-hidden=true tabindex=-1></a>  <span class=at>public =</span> <span class=fu>list</span>(</span>
<span id=cb9-6><a href=#cb9-6 aria-hidden=true tabindex=-1></a>    </span>
<span id=cb9-7><a href=#cb9-7 aria-hidden=true tabindex=-1></a>    <span class=at>losses =</span> <span class=cn>NULL</span>,</span>
<span id=cb9-8><a href=#cb9-8 aria-hidden=true tabindex=-1></a>     </span>
<span id=cb9-9><a href=#cb9-9 aria-hidden=true tabindex=-1></a>    <span class=at>on_epoch_end =</span> <span class=cf>function</span>(epoch, <span class=at>logs =</span> <span class=fu>list</span>()) {</span>
<span id=cb9-10><a href=#cb9-10 aria-hidden=true tabindex=-1></a>      tf<span class=sc>$</span><span class=fu>print</span>(<span class=fu>glue</span>(<span class=st>&#39;</span><span class=sc>\n</span><span class=st>Learning rate for epoch {epoch} is {as.numeric(model$optimizer$lr)}</span><span class=sc>\n</span><span class=st>&#39;</span>))</span>
<span id=cb9-11><a href=#cb9-11 aria-hidden=true tabindex=-1></a>    }</span>
<span id=cb9-12><a href=#cb9-12 aria-hidden=true tabindex=-1></a>))</span>
<span id=cb9-13><a href=#cb9-13 aria-hidden=true tabindex=-1></a></span>
<span id=cb9-14><a href=#cb9-14 aria-hidden=true tabindex=-1></a>print_lr <span class=ot>&lt;-</span> PrintLR<span class=sc>$</span><span class=fu>new</span>()</span></code></pre></div><div class=sourceCode id=cb10><pre class="sourceCode r"><code class="sourceCode r"><span id=cb10-1><a href=#cb10-1 aria-hidden=true tabindex=-1></a>callbacks <span class=ot>&lt;-</span> <span class=fu>list</span>(</span>
<span id=cb10-2><a href=#cb10-2 aria-hidden=true tabindex=-1></a>    <span class=fu>callback_tensorboard</span>(<span class=at>log_dir =</span> <span class=st>&#39;/tmp/logs&#39;</span>),</span>
<span id=cb10-3><a href=#cb10-3 aria-hidden=true tabindex=-1></a>    <span class=fu>callback_model_checkpoint</span>(<span class=at>filepath =</span> checkpoint_prefix, <span class=at>save_weights_only =</span> <span class=cn>TRUE</span>),</span>
<span id=cb10-4><a href=#cb10-4 aria-hidden=true tabindex=-1></a>    <span class=fu>callback_learning_rate_scheduler</span>(decay),</span>
<span id=cb10-5><a href=#cb10-5 aria-hidden=true tabindex=-1></a>    print_lr</span>
<span id=cb10-6><a href=#cb10-6 aria-hidden=true tabindex=-1></a>)</span></code></pre></div></div><div id=train-and-evaluate class="section level3"><h3>Train and evaluate</h3><p>Now, train the model in the usual way, calling fit on the model and passing in the dataset created at the beginning of the tutorial. This step is the same whether you are distributing the training or not.</p><div class=sourceCode id=cb11><pre class="sourceCode r"><code class="sourceCode r"><span id=cb11-1><a href=#cb11-1 aria-hidden=true tabindex=-1></a>model <span class=sc>%&gt;%</span> <span class=fu>fit</span>(train_dataset, <span class=at>epochs =</span> <span class=dv>12</span>, <span class=at>callbacks =</span> callbacks)</span></code></pre></div><p>As you can see below, the checkpoints are getting saved.</p><div class=sourceCode id=cb12><pre class="sourceCode r"><code class="sourceCode r"><span id=cb12-1><a href=#cb12-1 aria-hidden=true tabindex=-1></a><span class=fu>list.files</span>(checkpoint_dir)</span></code></pre></div><p>To see how the model performs, load the latest checkpoint and call evaluate on the test data.</p><div class=sourceCode id=cb13><pre class="sourceCode r"><code class="sourceCode r"><span id=cb13-1><a href=#cb13-1 aria-hidden=true tabindex=-1></a>model <span class=sc>%&gt;%</span> <span class=fu>load_model_weights_tf</span>(tf<span class=sc>$</span>train<span class=sc>$</span><span class=fu>latest_checkpoint</span>(checkpoint_dir))</span>
<span id=cb13-2><a href=#cb13-2 aria-hidden=true tabindex=-1></a></span>
<span id=cb13-3><a href=#cb13-3 aria-hidden=true tabindex=-1></a>model <span class=sc>%&gt;%</span> <span class=fu>evaluate</span>(test_dataset)</span></code></pre></div><div class=sourceCode id=cb14><pre class="sourceCode r"><code class="sourceCode r"><span id=cb14-1><a href=#cb14-1 aria-hidden=true tabindex=-1></a><span class=fu>tensorboard</span>(<span class=at>log_dir =</span> <span class=st>&quot;/tmp/logs&quot;</span>)</span></code></pre></div></div></div><div id=export-to-savedmodel class="section level2"><h2>Export to SavedModel</h2><p>Export the graph and the variables to the platform-agnostic SavedModel format. After your model is saved, you can load it with or without the scope.</p><div class=sourceCode id=cb15><pre class="sourceCode r"><code class="sourceCode r"><span id=cb15-1><a href=#cb15-1 aria-hidden=true tabindex=-1></a>path <span class=ot>&lt;-</span> <span class=st>&#39;saved_model/&#39;</span></span>
<span id=cb15-2><a href=#cb15-2 aria-hidden=true tabindex=-1></a>model <span class=sc>%&gt;%</span> <span class=fu>save_model_tf</span>(path)</span></code></pre></div><p>Load the model without <code>strategy$scope</code>.</p><div class=sourceCode id=cb16><pre class="sourceCode r"><code class="sourceCode r"><span id=cb16-1><a href=#cb16-1 aria-hidden=true tabindex=-1></a>unreplicated_model <span class=ot>&lt;-</span> <span class=fu>load_model_tf</span>(path)</span>
<span id=cb16-2><a href=#cb16-2 aria-hidden=true tabindex=-1></a></span>
<span id=cb16-3><a href=#cb16-3 aria-hidden=true tabindex=-1></a>unreplicated_model <span class=sc>%&gt;%</span> <span class=fu>compile</span>(</span>
<span id=cb16-4><a href=#cb16-4 aria-hidden=true tabindex=-1></a>    <span class=at>loss =</span> <span class=st>&#39;sparse_categorical_crossentropy&#39;</span>,</span>
<span id=cb16-5><a href=#cb16-5 aria-hidden=true tabindex=-1></a>    <span class=at>optimizer =</span> <span class=st>&#39;adam&#39;</span>,</span>
<span id=cb16-6><a href=#cb16-6 aria-hidden=true tabindex=-1></a>    <span class=at>metrics =</span> <span class=st>&#39;accuracy&#39;</span>)</span>
<span id=cb16-7><a href=#cb16-7 aria-hidden=true tabindex=-1></a></span>
<span id=cb16-8><a href=#cb16-8 aria-hidden=true tabindex=-1></a>unreplicated_model <span class=sc>%&gt;%</span> <span class=fu>evaluate</span>(test_dataset)</span></code></pre></div><p>Load the model with <code>strategy$scope</code>.</p><div class=sourceCode id=cb17><pre class="sourceCode r"><code class="sourceCode r"><span id=cb17-1><a href=#cb17-1 aria-hidden=true tabindex=-1></a><span class=fu>with</span> (strategy<span class=sc>$</span><span class=fu>scope</span>(), {</span>
<span id=cb17-2><a href=#cb17-2 aria-hidden=true tabindex=-1></a>  replicated_model <span class=ot>&lt;-</span> <span class=fu>load_model_tf</span>(path)</span>
<span id=cb17-3><a href=#cb17-3 aria-hidden=true tabindex=-1></a></span>
<span id=cb17-4><a href=#cb17-4 aria-hidden=true tabindex=-1></a>  replicated_model <span class=sc>%&gt;%</span> <span class=fu>compile</span>(</span>
<span id=cb17-5><a href=#cb17-5 aria-hidden=true tabindex=-1></a>    <span class=at>loss =</span> <span class=st>&#39;sparse_categorical_crossentropy&#39;</span>,</span>
<span id=cb17-6><a href=#cb17-6 aria-hidden=true tabindex=-1></a>    <span class=at>optimizer =</span> <span class=st>&#39;adam&#39;</span>,</span>
<span id=cb17-7><a href=#cb17-7 aria-hidden=true tabindex=-1></a>    <span class=at>metrics =</span> <span class=st>&#39;accuracy&#39;</span>)</span>
<span id=cb17-8><a href=#cb17-8 aria-hidden=true tabindex=-1></a></span>
<span id=cb17-9><a href=#cb17-9 aria-hidden=true tabindex=-1></a>  replicated_model <span class=sc>%&gt;%</span> <span class=fu>evaluate</span>(test_dataset)</span>
<span id=cb17-10><a href=#cb17-10 aria-hidden=true tabindex=-1></a>})</span></code></pre></div></div><script>(function(){var script=document.createElement("script");script.type="text/javascript";script.src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";document.getElementsByTagName("head")[0].appendChild(script);})();</script></body></html>