<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Overview on TensorFlow for R</title><link>/tutorials/beginners/basic-ml/</link><description>Recent content in Overview on TensorFlow for R</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="/tutorials/beginners/basic-ml/index.xml" rel="self" type="application/rss+xml"/><item><title>Basic Image Classification</title><link>/tutorials/beginners/basic-ml/tutorial_basic_classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/beginners/basic-ml/tutorial_basic_classification/</guid><description>In this guide, we will train a neural network model to classify images of clothing, like sneakers and shirts. It’s fine if you don’t understand all the details, this is a fast-paced overview of a complete Keras program with the details explained as we go.
library(keras) Import the Fashion MNIST dataset This guide uses the Fashion MNIST dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:</description></item><item><title>Basic Regression</title><link>/tutorials/beginners/basic-ml/tutorial_basic_regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/beginners/basic-ml/tutorial_basic_regression/</guid><description>In a regression problem, we aim to predict the output of a continuous value, like a price or a probability. Contrast this with a classification problem, where we aim to predict a discrete label (for example, where a picture contains an apple or an orange).
This notebook builds a model to predict the median price of homes in a Boston suburb during the mid-1970s. To do this, we’ll provide the model with some data points about the suburb, such as the crime rate and the local property tax rate.</description></item><item><title>Text Classification</title><link>/tutorials/beginners/basic-ml/tutorial_basic_text_classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/beginners/basic-ml/tutorial_basic_text_classification/</guid><description>Note: This tutorial requires TensorFlow version &amp;gt;= 2.1
This tutorial classifies movie reviews as positive or negative using the text of the review. This is an example of binary — or two-class — classification, an important and widely applicable kind of machine learning problem.
We’ll use the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing.</description></item><item><title>Transfer learning with tfhub</title><link>/tutorials/beginners/basic-ml/tutorial_basic_text_classification_with_tfhub/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/beginners/basic-ml/tutorial_basic_text_classification_with_tfhub/</guid><description>This tutorial classifies movie reviews as positive or negative using the text of the review. This is an example of binary — or two-class — classification, an important and widely applicable kind of machine learning problem.
We’ll use the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews.</description></item><item><title>Tutorial: Overfitting and Underfitting</title><link>/tutorials/beginners/basic-ml/tutorial_overfit_underfit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/beginners/basic-ml/tutorial_overfit_underfit/</guid><description>In two of the previous tutorails — classifying movie reviews, and predicting housing prices — we saw that the accuracy of our model on the validation data would peak after training for a number of epochs, and would then start decreasing.
In other words, our model would overfit to the training data. Learning how to deal with overfitting is important. Although it’s often possible to achieve high accuracy on the training set, what we really want is to develop models that generalize well to testing data (or data they haven’t seen before).</description></item><item><title>Tutorial: Save and Restore Models</title><link>/tutorials/beginners/basic-ml/tutorial_save_and_restore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/tutorials/beginners/basic-ml/tutorial_save_and_restore/</guid><description>Model progress can be saved after as well as during training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:
code to create the model, and the trained weights, or parameters, for the model Sharing this data helps others understand how the model works and try it themselves with new data.</description></item></channel></rss>